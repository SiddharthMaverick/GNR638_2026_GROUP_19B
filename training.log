Global seed set to 42
Loading dataset from data_1...
Found 10 classes: ['0', '1', '2', '3', '4'] ...
Global seed set to 42
Loading dataset from data_2...
Found 100 classes: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver'] ...
Dataset loaded: 50000 images in 64.94 seconds.
Dataset loaded: 60000 images in 87.46 seconds.
Training on 48000, Validating on 12000
Training on 40000, Validating on 10000

Epoch 1/100 | Time: 169.8s | Loss: 4.5697 | Train Acc: 1.72%
--- Evaluating on Epoch 1 Val ---

Epoch 1/100 | Time: 223.6s | Loss: 0.8032 | Train Acc: 73.70%
--- Evaluating on Epoch 1 Val ---

Overall Accuracy: 3.55% (355/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.1690     0.1348     0.1500
1          0.0000     0.0000     0.0000
2          0.0153     0.0215     0.0179
3          0.0000     0.0000     0.0000
4          0.0000     0.0000     0.0000
5          0.0000     0.0000     0.0000
6          0.0000     0.0000     0.0000
7          0.0175     0.0104     0.0131
8          0.0000     0.0000     0.0000
9          0.0000     0.0000     0.0000
10         0.0000     0.0000     0.0000
11         0.0000     0.0000     0.0000
12         0.0435     0.0097     0.0159
13         0.0000     0.0000     0.0000
14         0.0000     0.0000     0.0000
15         0.0000     0.0000     0.0000
16         0.0000     0.0000     0.0000
17         0.0000     0.0000     0.0000
18         0.0000     0.0000     0.0000
19         0.0000     0.0000     0.0000
20         0.0225     0.1942     0.0403
21         0.0169     0.0103     0.0128
22         0.0000     0.0000     0.0000
23         0.0000     0.0000     0.0000
24         0.0400     0.0225     0.0288
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0000     0.0000     0.0000
28         0.0000     0.0000     0.0000
29         0.0000     0.0000     0.0000
30         0.0000     0.0000     0.0000
31         0.0000     0.0000     0.0000
32         0.0000     0.0000     0.0000
33         0.0909     0.0127     0.0222
34         0.0215     0.0952     0.0350
35         0.0000     0.0000     0.0000
36         0.0000     0.0000     0.0000
37         0.1481     0.0360     0.0580
38         0.0000     0.0000     0.0000
39         0.0000     0.0000     0.0000
40         0.0164     0.0233     0.0192
41         0.0000     0.0000     0.0000
42         0.0000     0.0000     0.0000
43         0.0000     0.0000     0.0000
44         0.0000     0.0000     0.0000
45         0.0000     0.0000     0.0000
46         0.0833     0.0112     0.0198
47         0.0000     0.0000     0.0000
48         0.0000     0.0000     0.0000
49         0.0000     0.0000     0.0000
50         0.0294     0.0098     0.0147
51         0.0239     0.1158     0.0396
52         0.0714     0.0208     0.0323
53         0.0589     0.9688     0.1110
54         0.3333     0.0088     0.0171
55         0.0000     0.0000     0.0000
56         0.0000     0.0000     0.0000
57         0.0000     0.0000     0.0000
58         0.0000     0.0000     0.0000
59         0.0455     0.0796     0.0579
60         0.1875     0.1101     0.1387
61         0.0000     0.0000     0.0000
62         0.1000     0.0194     0.0325
63         0.0000     0.0000     0.0000
64         0.0000     0.0000     0.0000
65         0.0000     0.0000     0.0000
66         0.0000     0.0000     0.0000
67         0.0000     0.0000     0.0000
68         0.0000     0.0000     0.0000
69         0.0000     0.0000     0.0000
70         0.0000     0.0000     0.0000
71         0.0489     0.5435     0.0898
72         0.0870     0.0185     0.0305
73         0.0000     0.0000     0.0000
74         0.0000     0.0000     0.0000
75         0.0556     0.0090     0.0155
76         0.0000     0.0000     0.0000
77         0.0000     0.0000     0.0000
78         0.0000     0.0000     0.0000
79         0.0000     0.0000     0.0000
80         0.0000     0.0000     0.0000
81         0.0000     0.0000     0.0000
82         0.0000     0.0000     0.0000
83         0.0000     0.0000     0.0000
84         0.0000     0.0000     0.0000
85         0.0000     0.0000     0.0000
86         0.0516     0.3514     0.0900
87         0.0180     0.0233     0.0203
88         0.0000     0.0000     0.0000
89         0.0541     0.0189     0.0280
90         0.0242     0.0268     0.0254
91         0.0213     0.6413     0.0412
92         0.0000     0.0000     0.0000
93         0.0180     0.0198     0.0189
94         0.0000     0.0000     0.0000
95         0.0000     0.0000     0.0000
96         0.0000     0.0000     0.0000
97         0.0000     0.0000     0.0000
98         0.0338     0.0805     0.0476
99         0.0000     0.0000     0.0000
----------------------------------------
Macro Avg  0.0195     0.0365     0.0128

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Overall Accuracy: 86.12% (10334/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9475     0.8373     0.8890
1          0.9666     0.9567     0.9617
2          0.8647     0.8815     0.8730
3          0.9145     0.7451     0.8211
4          0.8390     0.8909     0.8642
5          0.9150     0.7974     0.8521
6          0.8312     0.9706     0.8955
7          0.9464     0.8165     0.8767
8          0.6502     0.9095     0.7583
9          0.8454     0.7910     0.8173
----------------------------------------
Macro Avg  0.8721     0.8596     0.8609

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 2/100 | Time: 337.1s | Loss: 4.2852 | Train Acc: 5.41%
--- Evaluating on Epoch 2 Val ---

Overall Accuracy: 8.55% (855/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.1302     0.2472     0.1705
1          0.0435     0.0538     0.0481
2          0.0114     0.0108     0.0110
3          0.0496     0.0787     0.0609
4          0.0000     0.0000     0.0000
5          0.0000     0.0000     0.0000
6          0.0950     0.2079     0.1304
7          0.0244     0.0417     0.0308
8          0.0000     0.0000     0.0000
9          0.1507     0.1222     0.1350
10         0.0000     0.0000     0.0000
11         0.0000     0.0000     0.0000
12         0.0388     0.0388     0.0388
13         0.0270     0.0294     0.0282
14         0.0000     0.0000     0.0000
15         0.0769     0.0088     0.0159
16         0.0000     0.0000     0.0000
17         0.1188     0.6195     0.1994
18         0.0000     0.0000     0.0000
19         0.3333     0.0099     0.0192
20         0.1748     0.2427     0.2033
21         0.0303     0.0103     0.0154
22         0.0000     0.0000     0.0000
23         0.2096     0.3398     0.2593
24         0.1813     0.3483     0.2385
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0108     0.0337     0.0163
28         0.0645     0.0208     0.0315
29         0.0000     0.0000     0.0000
30         0.1272     0.4356     0.1969
31         0.0000     0.0000     0.0000
32         0.0000     0.0000     0.0000
33         0.0000     0.0000     0.0000
34         0.0000     0.0000     0.0000
35         0.0000     0.0000     0.0000
36         0.0000     0.0000     0.0000
37         0.0000     0.0000     0.0000
38         0.0000     0.0000     0.0000
39         0.0000     0.0000     0.0000
40         0.0398     0.1163     0.0593
41         0.3571     0.0481     0.0847
42         0.0000     0.0000     0.0000
43         0.0635     0.0851     0.0727
44         0.1111     0.0101     0.0185
45         0.0000     0.0000     0.0000
46         0.2000     0.0225     0.0404
47         0.0886     0.0642     0.0745
48         0.0000     0.0000     0.0000
49         0.1506     0.2427     0.1859
50         0.0909     0.0098     0.0177
51         0.0435     0.0105     0.0169
52         0.2006     0.7500     0.3165
53         0.1483     0.4479     0.2228
54         0.1149     0.1754     0.1389
55         0.0000     0.0000     0.0000
56         0.0769     0.0556     0.0645
57         0.0471     0.1275     0.0688
58         0.0377     0.0748     0.0502
59         0.0500     0.0442     0.0469
60         0.1875     0.0275     0.0480
61         0.0857     0.0674     0.0755
62         0.2632     0.1942     0.2235
63         0.0000     0.0000     0.0000
64         0.0667     0.0093     0.0163
65         0.0833     0.0101     0.0180
66         0.0000     0.0000     0.0000
67         0.0588     0.0449     0.0510
68         0.2048     0.1574     0.1780
69         0.3333     0.0215     0.0404
70         0.2333     0.0631     0.0993
71         0.1176     0.0435     0.0635
72         0.0667     0.0093     0.0163
73         0.2738     0.1983     0.2300
74         0.0000     0.0000     0.0000
75         0.0277     0.2072     0.0489
76         0.0972     0.0745     0.0843
77         0.0388     0.1500     0.0616
78         0.0000     0.0000     0.0000
79         0.0256     0.0204     0.0227
80         0.0000     0.0000     0.0000
81         0.0000     0.0000     0.0000
82         0.1579     0.5806     0.2483
83         0.0755     0.1111     0.0899
84         0.0000     0.0000     0.0000
85         0.0000     0.0000     0.0000
86         0.0896     0.5495     0.1540
87         0.0135     0.0116     0.0125
88         0.0000     0.0000     0.0000
89         0.0556     0.0189     0.0282
90         0.0449     0.0357     0.0398
91         0.0250     0.0109     0.0152
92         0.1185     0.1524     0.1333
93         0.1176     0.0198     0.0339
94         0.0000     0.0000     0.0000
95         0.1346     0.1443     0.1393
96         0.0000     0.0000     0.0000
97         0.0000     0.0000     0.0000
98         0.0324     0.3908     0.0598
99         0.0357     0.0095     0.0150
----------------------------------------
Macro Avg  0.0678     0.0852     0.0558

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 2/100 | Time: 377.8s | Loss: 0.2974 | Train Acc: 90.67%
--- Evaluating on Epoch 2 Val ---

Overall Accuracy: 92.03% (11043/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.8870     0.9755     0.9292
1          0.9747     0.9611     0.9679
2          0.9077     0.9213     0.9144
3          0.9018     0.9180     0.9098
4          0.9493     0.9027     0.9254
5          0.9401     0.8977     0.9184
6          0.9755     0.9436     0.9593
7          0.8841     0.9371     0.9098
8          0.8660     0.9052     0.8852
9          0.9247     0.8308     0.8752
----------------------------------------
Macro Avg  0.9211     0.9193     0.9195

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 3/100 | Time: 262.1s | Loss: 4.0002 | Train Acc: 9.17%
--- Evaluating on Epoch 3 Val ---

Overall Accuracy: 10.04% (1004/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.1020     0.3933     0.1620
1          0.1154     0.1935     0.1446
2          0.0000     0.0000     0.0000
3          0.0291     0.0674     0.0407
4          0.0526     0.0101     0.0169
5          0.0000     0.0000     0.0000
6          0.1000     0.1683     0.1255
7          0.0571     0.3750     0.0992
8          0.0000     0.0000     0.0000
9          0.3333     0.0222     0.0417
10         0.0000     0.0000     0.0000
11         0.0000     0.0000     0.0000
12         0.1111     0.0097     0.0179
13         0.1176     0.0196     0.0336
14         0.0185     0.0098     0.0128
15         0.0000     0.0000     0.0000
16         0.0909     0.0115     0.0204
17         0.2105     0.1062     0.1412
18         0.0542     0.3524     0.0939
19         0.1429     0.0198     0.0348
20         0.1774     0.3204     0.2284
21         0.0000     0.0000     0.0000
22         0.0000     0.0000     0.0000
23         0.2759     0.0777     0.1212
24         0.3548     0.2472     0.2914
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0000     0.0000     0.0000
28         0.0367     0.0417     0.0390
29         0.0874     0.1000     0.0933
30         0.0625     0.0099     0.0171
31         0.0000     0.0000     0.0000
32         0.0000     0.0000     0.0000
33         0.0000     0.0000     0.0000
34         0.0682     0.0286     0.0403
35         0.1667     0.0099     0.0187
36         0.2154     0.1373     0.1677
37         0.0885     0.1532     0.1122
38         0.0000     0.0000     0.0000
39         0.0000     0.0000     0.0000
40         0.0000     0.0000     0.0000
41         0.6667     0.1923     0.2985
42         0.0000     0.0000     0.0000
43         0.0657     0.2447     0.1036
44         0.0421     0.0404     0.0412
45         0.0000     0.0000     0.0000
46         0.0952     0.0225     0.0364
47         0.0741     0.0917     0.0820
48         0.1905     0.0400     0.0661
49         0.3000     0.0874     0.1353
50         0.0000     0.0000     0.0000
51         0.0352     0.0842     0.0497
52         0.2548     0.6979     0.3733
53         0.2298     0.3854     0.2879
54         0.3333     0.2105     0.2581
55         0.0341     0.0323     0.0331
56         0.1023     0.2444     0.1443
57         0.0769     0.0196     0.0312
58         0.2857     0.0187     0.0351
59         0.0733     0.1239     0.0921
60         0.3684     0.2569     0.3027
61         0.0972     0.0787     0.0870
62         0.2500     0.0485     0.0813
63         0.0000     0.0000     0.0000
64         0.0408     0.0370     0.0388
65         0.0000     0.0000     0.0000
66         0.0135     0.0110     0.0121
67         0.0690     0.0225     0.0339
68         0.1975     0.4352     0.2717
69         0.2632     0.1613     0.2000
70         0.3000     0.0270     0.0496
71         0.3077     0.0435     0.0762
72         0.0435     0.0463     0.0448
73         0.4103     0.1379     0.2065
74         0.0625     0.0093     0.0163
75         0.0637     0.2973     0.1049
76         0.0952     0.0213     0.0348
77         0.0491     0.1100     0.0679
78         0.0303     0.0208     0.0247
79         0.0000     0.0000     0.0000
80         0.0000     0.0000     0.0000
81         0.0862     0.1020     0.0935
82         0.1507     0.6774     0.2466
83         0.0783     0.1204     0.0949
84         0.0000     0.0000     0.0000
85         0.1579     0.1698     0.1636
86         0.2828     0.2523     0.2667
87         0.0000     0.0000     0.0000
88         0.0328     0.0381     0.0352
89         0.1250     0.1226     0.1238
90         0.1081     0.0357     0.0537
91         0.0952     0.1304     0.1101
92         0.1600     0.1143     0.1333
93         0.0704     0.0495     0.0581
94         0.0000     0.0000     0.0000
95         0.0906     0.6392     0.1588
96         0.0429     0.0875     0.0576
97         0.0709     0.1776     0.1013
98         0.1316     0.0575     0.0800
99         0.0542     0.0857     0.0664
----------------------------------------
Macro Avg  0.1033     0.1005     0.0768

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 3/100 | Time: 291.8s | Loss: 0.2162 | Train Acc: 93.17%
--- Evaluating on Epoch 3 Val ---

Overall Accuracy: 93.54% (11225/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9424     0.9598     0.9510
1          0.9509     0.9802     0.9653
2          0.9305     0.9231     0.9268
3          0.9146     0.9393     0.9268
4          0.9530     0.9255     0.9391
5          0.9143     0.9409     0.9274
6          0.9700     0.9526     0.9612
7          0.9558     0.9181     0.9366
8          0.9129     0.9044     0.9086
9          0.9045     0.9052     0.9049
----------------------------------------
Macro Avg  0.9349     0.9349     0.9348

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 4/100 | Time: 197.8s | Loss: 3.8412 | Train Acc: 11.65%
--- Evaluating on Epoch 4 Val ---

Overall Accuracy: 13.30% (1330/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3056     0.2472     0.2733
1          0.1560     0.1828     0.1683
2          0.0388     0.0430     0.0408
3          0.0535     0.1124     0.0725
4          0.0000     0.0000     0.0000
5          0.0769     0.0094     0.0168
6          0.1576     0.2574     0.1955
7          0.1058     0.1146     0.1100
8          0.0000     0.0000     0.0000
9          0.3469     0.1889     0.2446
10         0.0000     0.0000     0.0000
11         0.0000     0.0000     0.0000
12         0.1923     0.0485     0.0775
13         0.1379     0.0392     0.0611
14         0.0714     0.0098     0.0172
15         0.0735     0.0442     0.0552
16         0.0588     0.0575     0.0581
17         0.1947     0.1947     0.1947
18         0.1200     0.1714     0.1412
19         0.1304     0.0594     0.0816
20         0.1313     0.4272     0.2009
21         0.0886     0.0722     0.0795
22         0.0000     0.0000     0.0000
23         0.1452     0.5243     0.2274
24         0.2174     0.3933     0.2800
25         0.0000     0.0000     0.0000
26         0.0526     0.0286     0.0370
27         0.0216     0.0899     0.0348
28         0.0526     0.0208     0.0299
29         0.0423     0.0667     0.0517
30         0.1333     0.0990     0.1136
31         0.0000     0.0000     0.0000
32         0.1000     0.0101     0.0183
33         0.0909     0.0253     0.0396
34         0.0435     0.0476     0.0455
35         0.1017     0.0594     0.0750
36         0.1050     0.4510     0.1704
37         0.1319     0.1712     0.1490
38         0.0357     0.0105     0.0163
39         0.1000     0.0161     0.0278
40         0.1667     0.0465     0.0727
41         0.4615     0.3462     0.3956
42         0.0000     0.0000     0.0000
43         0.0484     0.0319     0.0385
44         0.0732     0.0606     0.0663
45         0.0000     0.0000     0.0000
46         0.0870     0.1124     0.0980
47         0.4375     0.0642     0.1120
48         0.1500     0.0600     0.0857
49         0.4091     0.0874     0.1440
50         0.0400     0.0098     0.0157
51         0.0541     0.1263     0.0757
52         0.2528     0.6979     0.3712
53         0.2491     0.7500     0.3740
54         0.2439     0.2632     0.2532
55         0.0000     0.0000     0.0000
56         0.1223     0.1889     0.1485
57         0.1628     0.0686     0.0966
58         0.2500     0.0187     0.0348
59         0.0870     0.0708     0.0780
60         0.2545     0.6422     0.3646
61         0.0857     0.1685     0.1136
62         0.2063     0.1262     0.1566
63         0.0000     0.0000     0.0000
64         0.0698     0.0556     0.0619
65         0.0211     0.0202     0.0206
66         0.0617     0.0549     0.0581
67         0.1250     0.1461     0.1347
68         0.3100     0.2870     0.2981
69         0.0805     0.2258     0.1186
70         0.1479     0.3784     0.2127
71         0.1523     0.2500     0.1893
72         0.0682     0.0278     0.0395
73         0.2424     0.6207     0.3487
74         0.0000     0.0000     0.0000
75         0.1281     0.3243     0.1837
76         0.1354     0.1383     0.1368
77         0.0575     0.1000     0.0730
78         0.0000     0.0000     0.0000
79         0.0000     0.0000     0.0000
80         0.0000     0.0000     0.0000
81         0.0584     0.0918     0.0714
82         0.3333     0.4409     0.3796
83         0.1923     0.0463     0.0746
84         0.0690     0.0370     0.0482
85         0.2000     0.1321     0.1591
86         0.1250     0.4505     0.1957
87         0.0000     0.0000     0.0000
88         0.0439     0.0476     0.0457
89         0.1507     0.2075     0.1746
90         0.0877     0.0446     0.0592
91         0.1410     0.1196     0.1294
92         0.0808     0.0762     0.0784
93         0.0909     0.0396     0.0552
94         0.2923     0.1667     0.2123
95         0.2055     0.1546     0.1765
96         0.1111     0.1000     0.1053
97         0.0619     0.0654     0.0636
98         0.0750     0.0690     0.0719
99         0.0000     0.0000     0.0000
----------------------------------------
Macro Avg  0.1157     0.1315     0.1048

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 4/100 | Time: 243.7s | Loss: 0.1791 | Train Acc: 94.36%
--- Evaluating on Epoch 4 Val ---

Overall Accuracy: 94.11% (11293/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9653     0.9501     0.9577
1          0.9778     0.9707     0.9742
2          0.9177     0.9469     0.9321
3          0.9294     0.9492     0.9392
4          0.9663     0.9205     0.9428
5          0.9488     0.9381     0.9434
6          0.9680     0.9657     0.9668
7          0.9094     0.9515     0.9300
8          0.9335     0.8984     0.9156
9          0.8977     0.9129     0.9052
----------------------------------------
Macro Avg  0.9414     0.9404     0.9407

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 5/100 | Time: 213.0s | Loss: 3.7300 | Train Acc: 13.42%
--- Evaluating on Epoch 5 Val ---

Overall Accuracy: 14.71% (1471/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2245     0.2472     0.2353
1          0.1513     0.1935     0.1698
2          0.1111     0.0645     0.0816
3          0.0330     0.0337     0.0333
4          0.0000     0.0000     0.0000
5          0.0833     0.0472     0.0602
6          0.1124     0.2970     0.1630
7          0.1910     0.1771     0.1838
8          0.1667     0.0968     0.1224
9          0.3400     0.1889     0.2429
10         0.0000     0.0000     0.0000
11         0.2500     0.0083     0.0161
12         0.1923     0.0971     0.1290
13         0.0625     0.0098     0.0169
14         0.0625     0.0098     0.0169
15         0.1008     0.1150     0.1074
16         0.1667     0.0115     0.0215
17         0.2583     0.2743     0.2661
18         0.1166     0.2476     0.1585
19         0.1562     0.0495     0.0752
20         0.3455     0.1845     0.2405
21         0.0840     0.2062     0.1194
22         0.1250     0.0211     0.0360
23         0.2805     0.2233     0.2486
24         0.2339     0.4494     0.3077
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0149     0.0337     0.0206
28         0.0000     0.0000     0.0000
29         0.0926     0.1111     0.1010
30         0.3333     0.0396     0.0708
31         0.0962     0.0521     0.0676
32         0.0588     0.0101     0.0172
33         0.0505     0.1266     0.0722
34         0.1196     0.1048     0.1117
35         0.0843     0.0693     0.0761
36         0.2794     0.1863     0.2235
37         0.1698     0.0811     0.1098
38         0.0633     0.0526     0.0575
39         0.1739     0.0323     0.0544
40         0.1493     0.1163     0.1307
41         0.3534     0.3942     0.3727
42         0.0000     0.0000     0.0000
43         0.1163     0.1064     0.1111
44         0.0719     0.1111     0.0873
45         0.0625     0.0116     0.0196
46         0.0870     0.0899     0.0884
47         0.5152     0.1560     0.2394
48         0.1600     0.0800     0.1067
49         0.3506     0.2621     0.3000
50         0.0000     0.0000     0.0000
51         0.0800     0.2316     0.1189
52         0.2731     0.7396     0.3989
53         0.2978     0.5521     0.3869
54         0.2931     0.2982     0.2957
55         0.0000     0.0000     0.0000
56         0.1449     0.3444     0.2039
57         0.0957     0.2647     0.1406
58         0.1173     0.1963     0.1469
59         0.0889     0.0354     0.0506
60         0.4267     0.5872     0.4942
61         0.0980     0.2247     0.1365
62         0.2982     0.1650     0.2125
63         0.0714     0.0096     0.0169
64         0.0500     0.0463     0.0481
65         0.0909     0.0101     0.0182
66         0.0341     0.1319     0.0542
67         0.2000     0.1011     0.1343
68         0.1496     0.6204     0.2410
69         0.2044     0.3978     0.2701
70         0.2137     0.2523     0.2314
71         0.3500     0.0761     0.1250
72         0.1176     0.0185     0.0320
73         0.2480     0.5431     0.3405
74         0.0000     0.0000     0.0000
75         0.1513     0.3243     0.2063
76         0.1944     0.0745     0.1077
77         0.0505     0.0500     0.0503
78         0.0000     0.0000     0.0000
79         0.0741     0.0204     0.0320
80         0.0000     0.0000     0.0000
81         0.1111     0.0612     0.0789
82         0.3046     0.5699     0.3970
83         0.1353     0.2130     0.1655
84         0.1000     0.0093     0.0169
85         0.1538     0.3208     0.2080
86         0.2703     0.0901     0.1351
87         0.2857     0.0698     0.1121
88         0.0629     0.0857     0.0726
89         0.1607     0.0849     0.1111
90         0.0674     0.1161     0.0852
91         0.2683     0.1196     0.1654
92         0.0816     0.0381     0.0519
93         0.1765     0.0297     0.0508
94         0.2000     0.0175     0.0323
95         0.2320     0.2990     0.2613
96         0.1545     0.2125     0.1789
97         0.0527     0.3458     0.0915
98         0.1133     0.1954     0.1435
99         0.0000     0.0000     0.0000
----------------------------------------
Macro Avg  0.1460     0.1467     0.1234

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 5/100 | Time: 255.2s | Loss: 0.1546 | Train Acc: 95.13%
--- Evaluating on Epoch 5 Val ---

Overall Accuracy: 94.64% (11357/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9711     0.9396     0.9551
1          0.9653     0.9795     0.9723
2          0.9376     0.9434     0.9405
3          0.9541     0.9361     0.9450
4          0.9565     0.9484     0.9524
5          0.9568     0.9343     0.9454
6          0.9420     0.9820     0.9616
7          0.9699     0.9280     0.9485
8          0.8856     0.9522     0.9177
9          0.9272     0.9154     0.9212
----------------------------------------
Macro Avg  0.9466     0.9459     0.9460

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 6/100 | Time: 199.2s | Loss: 3.6313 | Train Acc: 15.13%
--- Evaluating on Epoch 6 Val ---

Overall Accuracy: 16.52% (1652/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.1084     0.5056     0.1786
1          0.1048     0.2796     0.1525
2          0.1412     0.1290     0.1348
3          0.0938     0.0337     0.0496
4          0.0270     0.0101     0.0147
5          0.1818     0.0189     0.0342
6          0.1829     0.1485     0.1639
7          0.0963     0.3021     0.1461
8          0.0000     0.0000     0.0000
9          0.3590     0.3111     0.3333
10         0.0000     0.0000     0.0000
11         0.0000     0.0000     0.0000
12         0.1139     0.0874     0.0989
13         0.0746     0.1961     0.1081
14         0.0748     0.1078     0.0884
15         0.2500     0.0177     0.0331
16         0.0714     0.0690     0.0702
17         0.2792     0.3805     0.3221
18         0.1033     0.2381     0.1441
19         0.1628     0.0693     0.0972
20         0.1964     0.4272     0.2691
21         0.1683     0.1753     0.1717
22         0.0885     0.1053     0.0962
23         0.2957     0.3301     0.3119
24         0.3725     0.2135     0.2714
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0467     0.0562     0.0510
28         0.2308     0.0312     0.0550
29         0.0851     0.0444     0.0584
30         0.1613     0.0495     0.0758
31         0.2105     0.0417     0.0696
32         0.0000     0.0000     0.0000
33         0.0690     0.1013     0.0821
34         0.2432     0.0857     0.1268
35         0.1040     0.1287     0.1150
36         0.2571     0.2647     0.2609
37         0.1855     0.2072     0.1957
38         0.0707     0.1368     0.0932
39         0.1667     0.0242     0.0423
40         0.1429     0.1860     0.1616
41         0.5333     0.3846     0.4469
42         0.0656     0.0377     0.0479
43         0.1064     0.2128     0.1418
44         0.0625     0.0101     0.0174
45         0.0000     0.0000     0.0000
46         0.0923     0.0674     0.0779
47         0.2054     0.4220     0.2763
48         0.1827     0.1900     0.1863
49         0.2617     0.3786     0.3095
50         0.0000     0.0000     0.0000
51         0.1029     0.1895     0.1333
52         0.4167     0.6771     0.5159
53         0.3485     0.4792     0.4035
54         0.2454     0.3509     0.2888
55         0.0000     0.0000     0.0000
56         0.1552     0.2000     0.1748
57         0.2500     0.0294     0.0526
58         0.1587     0.0935     0.1176
59         0.1667     0.0796     0.1078
60         0.4021     0.6972     0.5101
61         0.1123     0.2360     0.1522
62         0.2683     0.2136     0.2378
63         0.1875     0.0288     0.0500
64         0.0806     0.0463     0.0588
65         0.0312     0.0101     0.0153
66         0.0741     0.0220     0.0339
67         0.1613     0.1685     0.1648
68         0.3571     0.2778     0.3125
69         0.3205     0.2688     0.2924
70         0.2895     0.0991     0.1477
71         0.2778     0.4348     0.3390
72         0.0000     0.0000     0.0000
73         0.2605     0.5345     0.3503
74         0.0000     0.0000     0.0000
75         0.1244     0.4324     0.1932
76         0.1512     0.1383     0.1444
77         0.0654     0.0700     0.0676
78         0.0556     0.0104     0.0175
79         0.0000     0.0000     0.0000
80         0.2727     0.0268     0.0488
81         0.2500     0.0408     0.0702
82         0.3692     0.5161     0.4305
83         0.1308     0.1574     0.1429
84         0.0556     0.0185     0.0278
85         0.2138     0.3208     0.2566
86         0.2108     0.3153     0.2527
87         0.1556     0.0814     0.1069
88         0.0606     0.0381     0.0468
89         0.1429     0.1509     0.1468
90         0.0769     0.0089     0.0160
91         0.0756     0.2935     0.1203
92         0.0779     0.1810     0.1089
93         0.1099     0.0990     0.1042
94         0.4355     0.2368     0.3068
95         0.2464     0.3505     0.2894
96         0.1463     0.2250     0.1773
97         0.0858     0.2430     0.1268
98         0.1215     0.1494     0.1340
99         0.0000     0.0000     0.0000
----------------------------------------
Macro Avg  0.1533     0.1646     0.1398

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 7/100 | Time: 269.7s | Loss: 3.5435 | Train Acc: 16.54%
--- Evaluating on Epoch 7 Val ---

Overall Accuracy: 17.17% (1717/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2328     0.3034     0.2634
1          0.1279     0.1183     0.1229
2          0.0851     0.0430     0.0571
3          0.0588     0.0787     0.0673
4          0.1000     0.0101     0.0183
5          0.1667     0.0377     0.0615
6          0.1875     0.2079     0.1972
7          0.2500     0.1250     0.1667
8          0.3333     0.0753     0.1228
9          0.3625     0.3222     0.3412
10         0.0000     0.0000     0.0000
11         0.0610     0.0417     0.0495
12         0.0800     0.0194     0.0312
13         0.0982     0.1569     0.1208
14         0.0952     0.2157     0.1321
15         0.0645     0.0177     0.0278
16         0.0952     0.0460     0.0620
17         0.3226     0.3540     0.3376
18         0.2000     0.0762     0.1103
19         0.1509     0.0792     0.1039
20         0.4848     0.3107     0.3787
21         0.1532     0.1959     0.1719
22         0.1000     0.0947     0.0973
23         0.1958     0.2718     0.2276
24         0.2241     0.5843     0.3240
25         0.0000     0.0000     0.0000
26         0.0000     0.0000     0.0000
27         0.0794     0.0562     0.0658
28         0.1404     0.0833     0.1046
29         0.1034     0.0667     0.0811
30         0.1064     0.1980     0.1384
31         0.0891     0.1875     0.1208
32         0.2069     0.0606     0.0937
33         0.1053     0.0759     0.0882
34         0.1311     0.1524     0.1410
35         0.0742     0.2079     0.1094
36         0.2576     0.1667     0.2024
37         0.1818     0.0180     0.0328
38         0.0875     0.0737     0.0800
39         0.1667     0.0161     0.0294
40         0.0838     0.1628     0.1107
41         0.2049     0.4808     0.2874
42         0.1111     0.0377     0.0563
43         0.1379     0.1702     0.1524
44         0.1111     0.0202     0.0342
45         0.0526     0.0116     0.0190
46         0.0744     0.1011     0.0857
47         0.3778     0.3119     0.3417
48         0.2051     0.1600     0.1798
49         0.1975     0.4660     0.2775
50         0.0250     0.0098     0.0141
51         0.0931     0.2000     0.1271
52         0.3598     0.7083     0.4772
53         0.2818     0.6458     0.3924
54         0.4516     0.2456     0.3182
55         0.0000     0.0000     0.0000
56         0.1190     0.3333     0.1754
57         0.2083     0.0490     0.0794
58         0.1456     0.2804     0.1917
59         0.2083     0.1327     0.1622
60         0.6588     0.5138     0.5773
61         0.1975     0.1798     0.1882
62         0.2920     0.3883     0.3333
63         0.5714     0.0769     0.1356
64         0.1750     0.0648     0.0946
65         0.1333     0.0202     0.0351
66         0.1026     0.0440     0.0615
67         0.0575     0.0562     0.0568
68         0.2500     0.4907     0.3313
69         0.1503     0.5269     0.2339
70         0.2273     0.2252     0.2262
71         0.3059     0.2826     0.2938
72         0.0435     0.0185     0.0260
73         0.3139     0.3707     0.3399
74         0.1094     0.0654     0.0819
75         0.1283     0.3964     0.1938
76         0.1211     0.3298     0.1771
77         0.0854     0.0700     0.0769
78         0.0000     0.0000     0.0000
79         0.0513     0.0204     0.0292
80         0.2143     0.0268     0.0476
81         0.1165     0.1224     0.1194
82         0.2865     0.5699     0.3813
83         0.2340     0.1019     0.1419
84         0.0469     0.0278     0.0349
85         0.2626     0.2453     0.2537
86         0.2885     0.1351     0.1840
87         0.1224     0.1395     0.1304
88         0.0732     0.0286     0.0411
89         0.1399     0.1887     0.1606
90         0.1280     0.1429     0.1350
91         0.3077     0.0870     0.1356
92         0.0899     0.1619     0.1156
93         0.0719     0.0990     0.0833
94         0.4167     0.2632     0.3226
95         0.1914     0.5052     0.2776
96         0.1562     0.1875     0.1705
97         0.1118     0.1682     0.1343
98         0.0984     0.1379     0.1148
99         0.3333     0.0095     0.0185
----------------------------------------
Macro Avg  0.1707     0.1716     0.1486

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 6/100 | Time: 325.5s | Loss: 0.1390 | Train Acc: 95.60%
--- Evaluating on Epoch 6 Val ---

Overall Accuracy: 94.75% (11370/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9568     0.9685     0.9626
1          0.9695     0.9795     0.9745
2          0.9226     0.9584     0.9402
3          0.9523     0.9328     0.9424
4          0.9725     0.9281     0.9498
5          0.9284     0.9606     0.9442
6          0.9653     0.9771     0.9711
7          0.9261     0.9591     0.9423
8          0.9435     0.9120     0.9275
9          0.9362     0.8942     0.9148
----------------------------------------
Macro Avg  0.9473     0.9470     0.9469

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 8/100 | Time: 202.3s | Loss: 3.4631 | Train Acc: 18.01%
--- Evaluating on Epoch 8 Val ---

Overall Accuracy: 18.09% (1809/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2979     0.1573     0.2059
1          0.1544     0.2258     0.1834
2          0.1092     0.1398     0.1226
3          0.1111     0.0112     0.0204
4          0.0357     0.0303     0.0328
5          0.1600     0.0755     0.1026
6          0.0991     0.2079     0.1342
7          0.0986     0.2188     0.1359
8          0.1961     0.1075     0.1389
9          0.3333     0.3333     0.3333
10         0.0000     0.0000     0.0000
11         0.1667     0.0250     0.0435
12         0.1771     0.1650     0.1709
13         0.1744     0.1471     0.1596
14         0.1057     0.1275     0.1156
15         0.1250     0.0796     0.0973
16         0.2000     0.0690     0.1026
17         0.3415     0.3717     0.3559
18         0.1733     0.1238     0.1444
19         0.1591     0.0693     0.0966
20         0.2824     0.3592     0.3162
21         0.1318     0.4227     0.2010
22         0.1389     0.1053     0.1198
23         0.2949     0.2233     0.2541
24         0.1933     0.5169     0.2813
25         0.0952     0.0247     0.0392
26         0.0625     0.0095     0.0165
27         0.0875     0.0787     0.0828
28         0.2381     0.0521     0.0855
29         0.1852     0.0556     0.0855
30         0.1826     0.2079     0.1944
31         0.1333     0.0417     0.0635
32         0.5000     0.0101     0.0198
33         0.0897     0.1772     0.1191
34         0.0829     0.1619     0.1097
35         0.0926     0.1980     0.1262
36         0.2321     0.2549     0.2430
37         0.1481     0.0360     0.0580
38         0.1224     0.0632     0.0833
39         0.0889     0.0968     0.0927
40         0.1356     0.0930     0.1103
41         0.4057     0.4135     0.4095
42         0.0728     0.1038     0.0856
43         0.0819     0.2447     0.1227
44         0.1048     0.1313     0.1166
45         0.0000     0.0000     0.0000
46         0.1444     0.1461     0.1453
47         0.4302     0.3394     0.3795
48         0.1511     0.2100     0.1757
49         0.4444     0.1165     0.1846
50         0.0000     0.0000     0.0000
51         0.1321     0.1474     0.1393
52         0.4567     0.6042     0.5202
53         0.2289     0.6771     0.3421
54         0.3023     0.2281     0.2600
55         0.0000     0.0000     0.0000
56         0.1921     0.3222     0.2407
57         0.1190     0.0490     0.0694
58         0.4643     0.1215     0.1926
59         0.2500     0.1239     0.1657
60         0.4813     0.7064     0.5725
61         0.1954     0.1910     0.1932
62         0.1980     0.3883     0.2623
63         0.2632     0.1442     0.1863
64         0.0597     0.0370     0.0457
65         0.0377     0.0202     0.0263
66         0.0455     0.0110     0.0177
67         0.1875     0.1348     0.1569
68         0.2931     0.4722     0.3617
69         0.3229     0.3333     0.3280
70         0.2409     0.2973     0.2661
71         0.2340     0.5978     0.3364
72         0.0000     0.0000     0.0000
73         0.3846     0.3448     0.3636
74         0.0813     0.1215     0.0974
75         0.1404     0.5856     0.2265
76         0.3182     0.0745     0.1207
77         0.0769     0.0700     0.0733
78         0.0000     0.0000     0.0000
79         0.0678     0.0408     0.0510
80         0.1538     0.0179     0.0320
81         0.4000     0.0204     0.0388
82         0.3648     0.6237     0.4603
83         0.1204     0.3333     0.1769
84         0.0778     0.0648     0.0707
85         0.2388     0.3019     0.2667
86         0.1978     0.3243     0.2457
87         0.1190     0.0581     0.0781
88         0.0746     0.0476     0.0581
89         0.2553     0.1132     0.1569
90         0.1186     0.0625     0.0819
91         0.1456     0.2500     0.1840
92         0.0882     0.0571     0.0694
93         0.2105     0.0396     0.0667
94         0.5192     0.2368     0.3253
95         0.2624     0.3814     0.3109
96         0.2784     0.3375     0.3051
97         0.1069     0.1308     0.1176
98         0.1354     0.1494     0.1421
99         0.0769     0.0762     0.0766
----------------------------------------
Macro Avg  0.1829     0.1805     0.1590

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 7/100 | Time: 265.4s | Loss: 0.1261 | Train Acc: 96.05%
--- Evaluating on Epoch 7 Val ---

Overall Accuracy: 95.10% (11412/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9683     0.9633     0.9658
1          0.9780     0.9773     0.9776
2          0.9369     0.9584     0.9476
3          0.9422     0.9492     0.9457
4          0.9766     0.9171     0.9459
5          0.9626     0.9418     0.9521
6          0.9653     0.9771     0.9711
7          0.9665     0.9401     0.9531
8          0.8958     0.9547     0.9243
9          0.9187     0.9272     0.9229
----------------------------------------
Macro Avg  0.9511     0.9506     0.9506

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 9/100 | Time: 227.0s | Loss: 3.3921 | Train Acc: 18.94%
--- Evaluating on Epoch 9 Val ---

Overall Accuracy: 18.54% (1854/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3750     0.2360     0.2897
1          0.1959     0.2043     0.2000
2          0.0753     0.0753     0.0753
3          0.0741     0.0674     0.0706
4          0.0753     0.0707     0.0729
5          0.0903     0.3585     0.1442
6          0.1848     0.1683     0.1762
7          0.1974     0.1562     0.1744
8          0.1527     0.2151     0.1786
9          0.3976     0.3667     0.3815
10         0.0000     0.0000     0.0000
11         0.2273     0.0417     0.0704
12         0.1308     0.1650     0.1459
13         0.1667     0.1275     0.1444
14         0.2273     0.0490     0.0806
15         0.1172     0.1327     0.1245
16         0.0741     0.0460     0.0567
17         0.3133     0.4159     0.3574
18         0.1667     0.0667     0.0952
19         0.1667     0.0495     0.0763
20         0.2990     0.2816     0.2900
21         0.2292     0.2268     0.2280
22         0.1538     0.0632     0.0896
23         0.2435     0.2718     0.2569
24         0.2576     0.5730     0.3554
25         0.0952     0.0247     0.0392
26         0.0667     0.0190     0.0296
27         0.1134     0.1236     0.1183
28         0.2727     0.1562     0.1987
29         0.0980     0.1667     0.1235
30         0.2014     0.2871     0.2367
31         0.1507     0.1146     0.1302
32         0.1493     0.1010     0.1205
33         0.0749     0.1772     0.1053
34         0.1343     0.0857     0.1047
35         0.1316     0.0990     0.1130
36         0.1544     0.4314     0.2274
37         0.0870     0.0360     0.0510
38         0.0900     0.0947     0.0923
39         0.1389     0.0403     0.0625
40         0.1308     0.1628     0.1451
41         0.4362     0.3942     0.4141
42         0.0857     0.0283     0.0426
43         0.0718     0.1489     0.0969
44         0.1429     0.0202     0.0354
45         0.0000     0.0000     0.0000
46         0.2143     0.0337     0.0583
47         0.4444     0.2569     0.3256
48         0.1500     0.2700     0.1929
49         0.3818     0.2039     0.2658
50         0.0000     0.0000     0.0000
51         0.1176     0.2737     0.1646
52         0.4082     0.6250     0.4938
53         0.2560     0.6667     0.3699
54         0.2690     0.4035     0.3228
55         0.0000     0.0000     0.0000
56         0.2353     0.2222     0.2286
57         0.1094     0.2059     0.1429
58         0.3175     0.1869     0.2353
59         0.2444     0.0973     0.1392
60         0.4103     0.7339     0.5263
61         0.0978     0.3034     0.1479
62         0.3273     0.3495     0.3380
63         0.2097     0.1250     0.1566
64         0.1190     0.0463     0.0667
65         0.0331     0.0404     0.0364
66         0.0962     0.0549     0.0699
67         0.1600     0.0449     0.0702
68         0.3053     0.5370     0.3893
69         0.2836     0.4086     0.3348
70         0.2623     0.2883     0.2747
71         0.2070     0.5109     0.2947
72         0.0667     0.0185     0.0290
73         0.2250     0.0776     0.1154
74         0.1081     0.1121     0.1101
75         0.2837     0.3604     0.3175
76         0.2137     0.2660     0.2370
77         0.1875     0.0300     0.0517
78         0.0500     0.0312     0.0385
79         0.0769     0.0102     0.0180
80         0.0667     0.0089     0.0157
81         0.1429     0.0816     0.1039
82         0.4783     0.3548     0.4074
83         0.1895     0.1667     0.1773
84         0.1176     0.0185     0.0320
85         0.3118     0.2736     0.2915
86         0.2857     0.2162     0.2462
87         0.0957     0.1047     0.1000
88         0.0690     0.2762     0.1105
89         0.1694     0.1981     0.1826
90         0.1264     0.0982     0.1106
91         0.2381     0.2717     0.2538
92         0.0377     0.0190     0.0253
93         0.1765     0.0297     0.0508
94         0.2273     0.4825     0.3090
95         0.3429     0.2474     0.2874
96         0.2800     0.2625     0.2710
97         0.1387     0.2243     0.1714
98         0.1084     0.2529     0.1517
99         0.0417     0.0095     0.0155
----------------------------------------
Macro Avg  0.1793     0.1853     0.1650

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 8/100 | Time: 248.3s | Loss: 0.1155 | Train Acc: 96.38%
--- Evaluating on Epoch 8 Val ---

Overall Accuracy: 95.13% (11416/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9524     0.9799     0.9659
1          0.9745     0.9817     0.9781
2          0.9176     0.9655     0.9410
3          0.9470     0.9516     0.9493
4          0.9607     0.9509     0.9558
5          0.9410     0.9568     0.9488
6          0.9722     0.9738     0.9730
7          0.9761     0.9272     0.9510
8          0.9682     0.8830     0.9236
9          0.9012     0.9416     0.9210
----------------------------------------
Macro Avg  0.9511     0.9512     0.9508

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 10/100 | Time: 211.4s | Loss: 3.3279 | Train Acc: 20.23%
--- Evaluating on Epoch 10 Val ---

Overall Accuracy: 20.48% (2048/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.5660     0.3371     0.4225
1          0.2386     0.2258     0.2320
2          0.1250     0.0430     0.0640
3          0.0412     0.0449     0.0430
4          0.0492     0.0303     0.0375
5          0.1786     0.1415     0.1579
6          0.2400     0.1782     0.2045
7          0.1418     0.1979     0.1652
8          0.1500     0.0645     0.0902
9          0.4054     0.3333     0.3659
10         0.0000     0.0000     0.0000
11         0.1905     0.0333     0.0567
12         0.2000     0.1845     0.1919
13         0.1306     0.2843     0.1790
14         0.1053     0.0588     0.0755
15         0.1429     0.0088     0.0167
16         0.2000     0.0805     0.1148
17         0.4375     0.1858     0.2609
18         0.1343     0.2571     0.1765
19         0.1549     0.1089     0.1279
20         0.4235     0.3495     0.3830
21         0.2456     0.2887     0.2654
22         0.1842     0.2211     0.2010
23         0.3548     0.4272     0.3877
24         0.4487     0.3933     0.4192
25         0.0833     0.0864     0.0848
26         0.0667     0.0190     0.0296
27         0.0628     0.1461     0.0878
28         0.4054     0.1562     0.2256
29         0.1800     0.1000     0.1286
30         0.2213     0.2673     0.2422
31         0.1379     0.0833     0.1039
32         0.1333     0.0202     0.0351
33         0.1009     0.1392     0.1170
34         0.1138     0.1333     0.1228
35         0.1400     0.0693     0.0927
36         0.2189     0.3627     0.2731
37         0.1475     0.0811     0.1047
38         0.1176     0.0421     0.0620
39         0.1731     0.0726     0.1023
40         0.2143     0.0349     0.0600
41         0.4340     0.4423     0.4381
42         0.0526     0.0943     0.0676
43         0.1044     0.2766     0.1516
44         0.0995     0.2222     0.1375
45         0.1111     0.0116     0.0211
46         0.1714     0.0674     0.0968
47         0.3689     0.4128     0.3896
48         0.2525     0.2500     0.2513
49         0.5000     0.2136     0.2993
50         0.0000     0.0000     0.0000
51         0.1241     0.1895     0.1500
52         0.4403     0.6146     0.5130
53         0.3312     0.5417     0.4111
54         0.3150     0.3509     0.3320
55         0.0000     0.0000     0.0000
56         0.2364     0.2889     0.2600
57         0.1951     0.1569     0.1739
58         0.2238     0.2991     0.2560
59         0.2500     0.0973     0.1401
60         0.4469     0.7339     0.5556
61         0.2268     0.2472     0.2366
62         0.2671     0.3786     0.3133
63         0.2143     0.0865     0.1233
64         0.0571     0.0185     0.0280
65         0.0632     0.0606     0.0619
66         0.0702     0.0440     0.0541
67         0.2549     0.1461     0.1857
68         0.2965     0.6204     0.4012
69         0.3697     0.4731     0.4151
70         0.2773     0.2973     0.2870
71         0.3611     0.4239     0.3900
72         0.0656     0.0370     0.0473
73         0.4359     0.4397     0.4378
74         0.0806     0.1589     0.1069
75         0.1658     0.5586     0.2557
76         0.2523     0.2872     0.2687
77         0.0973     0.1100     0.1033
78         0.0625     0.0104     0.0179
79         0.1071     0.0306     0.0476
80         0.0488     0.0179     0.0261
81         0.1571     0.1122     0.1310
82         0.3413     0.6129     0.4385
83         0.2500     0.1111     0.1538
84         0.0741     0.0370     0.0494
85         0.1667     0.4528     0.2437
86         0.3083     0.3333     0.3203
87         0.2045     0.1047     0.1385
88         0.1707     0.0667     0.0959
89         0.0879     0.3491     0.1404
90         0.1333     0.0536     0.0764
91         0.2011     0.4022     0.2681
92         0.0896     0.0571     0.0698
93         0.2174     0.0495     0.0806
94         0.3945     0.3772     0.3857
95         0.3258     0.2990     0.3118
96         0.2102     0.4625     0.2891
97         0.1682     0.1682     0.1682
98         0.1057     0.3218     0.1591
99         0.1231     0.0762     0.0941
----------------------------------------
Macro Avg  0.2017     0.2045     0.1858

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 9/100 | Time: 242.7s | Loss: 0.1078 | Train Acc: 96.61%
--- Evaluating on Epoch 9 Val ---

Overall Accuracy: 95.65% (11478/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9391     0.9851     0.9616
1          0.9874     0.9765     0.9819
2          0.9454     0.9637     0.9545
3          0.9260     0.9648     0.9450
4          0.9609     0.9569     0.9589
5          0.9484     0.9653     0.9568
6          0.9875     0.9697     0.9785
7          0.9740     0.9378     0.9556
8          0.9591     0.9214     0.9399
9          0.9325     0.9239     0.9282
----------------------------------------
Macro Avg  0.9560     0.9565     0.9561

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 11/100 | Time: 203.6s | Loss: 3.2720 | Train Acc: 21.03%
--- Evaluating on Epoch 11 Val ---

Overall Accuracy: 21.15% (2115/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3243     0.4045     0.3600
1          0.2151     0.2151     0.2151
2          0.1069     0.1505     0.1250
3          0.0761     0.0787     0.0773
4          0.1364     0.0303     0.0496
5          0.1503     0.2170     0.1776
6          0.1689     0.2475     0.2008
7          0.2198     0.2083     0.2139
8          0.1449     0.2151     0.1732
9          0.2893     0.3889     0.3318
10         0.1176     0.0198     0.0339
11         0.1333     0.0167     0.0296
12         0.1471     0.3883     0.2133
13         0.1828     0.1667     0.1744
14         0.2653     0.1275     0.1722
15         0.0964     0.1416     0.1147
16         0.1212     0.0920     0.1046
17         0.3103     0.3982     0.3488
18         0.1791     0.1143     0.1395
19         0.1429     0.0594     0.0839
20         0.2023     0.5049     0.2889
21         0.2053     0.4021     0.2718
22         0.1477     0.1368     0.1421
23         0.3019     0.3107     0.3062
24         0.2462     0.5393     0.3380
25         0.1667     0.1235     0.1418
26         0.1000     0.0286     0.0444
27         0.1463     0.0674     0.0923
28         0.2581     0.2500     0.2540
29         0.1618     0.1222     0.1392
30         0.1667     0.3366     0.2230
31         0.1569     0.2500     0.1928
32         0.2250     0.0909     0.1295
33         0.1364     0.1519     0.1437
34         0.0667     0.0286     0.0400
35         0.1176     0.1584     0.1350
36         0.1667     0.3824     0.2321
37         0.1455     0.0721     0.0964
38         0.1429     0.0842     0.1060
39         0.1171     0.1048     0.1106
40         0.0787     0.1163     0.0939
41         0.3731     0.4808     0.4202
42         0.0886     0.0660     0.0757
43         0.0991     0.2234     0.1373
44         0.1042     0.0505     0.0680
45         0.1667     0.0233     0.0408
46         0.1546     0.1685     0.1613
47         0.3881     0.4771     0.4280
48         0.2290     0.3000     0.2597
49         0.3833     0.2233     0.2822
50         0.0000     0.0000     0.0000
51         0.2405     0.2000     0.2184
52         0.4912     0.5833     0.5333
53         0.2563     0.7396     0.3807
54         0.2586     0.3947     0.3125
55         0.0000     0.0000     0.0000
56         0.3378     0.2778     0.3049
57         0.1735     0.1667     0.1700
58         0.2526     0.2243     0.2376
59         0.2407     0.2301     0.2353
60         0.7391     0.6239     0.6766
61         0.2212     0.2584     0.2383
62         0.3377     0.2524     0.2889
63         0.2212     0.2212     0.2212
64         0.0963     0.1204     0.1070
65         0.0732     0.0303     0.0429
66         0.0841     0.2088     0.1199
67         0.2000     0.0225     0.0404
68         0.5915     0.3889     0.4693
69         0.2747     0.5376     0.3636
70         0.3580     0.2613     0.3021
71         0.5333     0.1739     0.2623
72         0.0571     0.0185     0.0280
73         0.3333     0.3276     0.3304
74         0.1250     0.0841     0.1006
75         0.2701     0.4234     0.3298
76         0.2134     0.3723     0.2713
77         0.1053     0.0600     0.0764
78         0.0725     0.0521     0.0606
79         0.0769     0.0102     0.0180
80         0.0741     0.0536     0.0622
81         0.2000     0.1224     0.1519
82         0.4681     0.4731     0.4706
83         0.1760     0.2037     0.1888
84         0.0385     0.0093     0.0149
85         0.2879     0.3585     0.3193
86         0.1909     0.3784     0.2538
87         0.1077     0.0814     0.0927
88         0.1667     0.0952     0.1212
89         0.1888     0.2547     0.2169
90         0.1392     0.0982     0.1152
91         0.3793     0.2391     0.2933
92         0.1200     0.0857     0.1000
93         0.2286     0.0792     0.1176
94         0.2989     0.4825     0.3691
95         0.3000     0.2474     0.2712
96         0.2769     0.2250     0.2483
97         0.1797     0.2150     0.1957
98         0.2174     0.1149     0.1504
99         0.0625     0.0286     0.0392
----------------------------------------
Macro Avg  0.2031     0.2106     0.1927

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 10/100 | Time: 290.0s | Loss: 0.0997 | Train Acc: 96.86%
--- Evaluating on Epoch 10 Val ---

Overall Accuracy: 95.53% (11464/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9470     0.9843     0.9653
1          0.9717     0.9831     0.9774
2          0.9335     0.9682     0.9505
3          0.9774     0.9230     0.9494
4          0.9507     0.9619     0.9563
5          0.9410     0.9568     0.9488
6          0.9693     0.9804     0.9748
7          0.9832     0.9310     0.9564
8          0.9386     0.9402     0.9394
9          0.9350     0.9247     0.9298
----------------------------------------
Macro Avg  0.9547     0.9554     0.9548


Epoch 12/100 | Time: 271.0s | Loss: 3.2230 | Train Acc: 22.02%
--- Evaluating on Epoch 12 Val ---

Overall Accuracy: 21.84% (2184/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3000     0.4382     0.3562
1          0.2256     0.3226     0.2655
2          0.1207     0.0753     0.0927
3          0.0494     0.0449     0.0471
4          0.1364     0.0303     0.0496
5          0.1615     0.1981     0.1780
6          0.1944     0.2079     0.2010
7          0.2361     0.1771     0.2024
8          0.1743     0.2043     0.1881
9          0.3617     0.3778     0.3696
10         0.0667     0.0198     0.0305
11         0.1500     0.0250     0.0429
12         0.1576     0.2816     0.2021
13         0.1698     0.0882     0.1161
14         0.2545     0.1373     0.1783
15         0.1165     0.1062     0.1111
16         0.2195     0.1034     0.1406
17         0.2850     0.4867     0.3595
18         0.1321     0.1333     0.1327
19         0.1333     0.0594     0.0822
20         0.3739     0.4175     0.3945
21         0.2236     0.3711     0.2791
22         0.1800     0.1895     0.1846
23         0.3611     0.3786     0.3697
24         0.3534     0.4607     0.4000
25         0.1905     0.0494     0.0784
26         0.0595     0.0476     0.0529
27         0.0732     0.0674     0.0702
28         0.5116     0.2292     0.3165
29         0.1538     0.1778     0.1649
30         0.2115     0.4752     0.2927
31         0.1250     0.1562     0.1389
32         0.2000     0.0909     0.1250
33         0.1143     0.1013     0.1074
34         0.1230     0.1429     0.1322
35         0.1269     0.1683     0.1447
36         0.1706     0.4216     0.2429
37         0.1150     0.1171     0.1161
38         0.1161     0.1368     0.1256
39         0.1026     0.0968     0.0996
40         0.2041     0.1163     0.1481
41         0.3413     0.5481     0.4207
42         0.0789     0.0849     0.0818
43         0.1023     0.2340     0.1424
44         0.0667     0.0101     0.0175
45         0.1111     0.0814     0.0940
46         0.0783     0.1461     0.1020
47         0.5224     0.3211     0.3977
48         0.1396     0.3700     0.2027
49         0.2400     0.4660     0.3168
50         0.0000     0.0000     0.0000
51         0.2283     0.2211     0.2246
52         0.3092     0.8021     0.4464
53         0.3239     0.5938     0.4191
54         0.3387     0.3684     0.3529
55         0.0000     0.0000     0.0000
56         0.2870     0.3444     0.3131
57         0.2358     0.2451     0.2404
58         0.2544     0.2710     0.2624
59         0.3684     0.1239     0.1854
60         0.8358     0.5138     0.6364
61         0.1695     0.3371     0.2256
62         0.3617     0.3301     0.3452
63         0.3409     0.1442     0.2027
64         0.1010     0.0926     0.0966
65         0.0435     0.0202     0.0276
66         0.1429     0.0220     0.0381
67         0.2195     0.1011     0.1385
68         0.3456     0.6944     0.4615
69         0.3388     0.4409     0.3832
70         0.4524     0.1712     0.2484
71         0.4433     0.4674     0.4550
72         0.0417     0.0093     0.0152
73         0.5273     0.2500     0.3392
74         0.0728     0.1028     0.0853
75         0.3267     0.4414     0.3755
76         0.2661     0.3511     0.3028
77         0.0920     0.0800     0.0856
78         0.1127     0.0833     0.0958
79         0.2381     0.0510     0.0840
80         0.0851     0.0357     0.0503
81         0.1282     0.2041     0.1575
82         0.5395     0.4409     0.4852
83         0.2188     0.1296     0.1628
84         0.0476     0.0093     0.0155
85         0.2342     0.3491     0.2803
86         0.2249     0.3423     0.2714
87         0.1183     0.1279     0.1229
88         0.1746     0.1048     0.1310
89         0.2315     0.2358     0.2336
90         0.2121     0.0625     0.0966
91         0.2010     0.4348     0.2749
92         0.0000     0.0000     0.0000
93         0.1566     0.1287     0.1413
94         0.5714     0.4211     0.4848
95         0.4318     0.1959     0.2695
96         0.2571     0.2250     0.2400
97         0.1096     0.2991     0.1604
98         0.1441     0.1839     0.1616
99         0.0938     0.0286     0.0438
----------------------------------------
Macro Avg  0.2141     0.2182     0.1998

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 11/100 | Time: 254.0s | Loss: 0.0937 | Train Acc: 97.03%
--- Evaluating on Epoch 11 Val ---

Epoch 13/100 | Time: 208.9s | Loss: 3.1766 | Train Acc: 23.02%
--- Evaluating on Epoch 13 Val ---

Overall Accuracy: 22.17% (2217/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4923     0.3596     0.4156
1          0.2025     0.3441     0.2550
2          0.1667     0.0860     0.1135
3          0.0895     0.1910     0.1219
4          0.3333     0.0606     0.1026
5          0.2113     0.1415     0.1695
6          0.2623     0.1584     0.1975
7          0.2000     0.1979     0.1990
8          0.1806     0.2796     0.2194
9          0.3299     0.3556     0.3422
10         0.0556     0.0099     0.0168
11         0.2222     0.0167     0.0310
12         0.2083     0.2427     0.2242
13         0.0959     0.1373     0.1129
14         0.2031     0.1275     0.1566
15         0.2619     0.0973     0.1419
16         0.2333     0.0805     0.1197
17         0.3366     0.3009     0.3178
18         0.1156     0.2190     0.1513
19         0.1692     0.1089     0.1325
20         0.3774     0.3883     0.3828
21         0.3898     0.2371     0.2949
22         0.2895     0.1158     0.1654
23         0.3626     0.3204     0.3402
24         0.2908     0.4607     0.3565
25         0.1250     0.0864     0.1022
26         0.0526     0.0095     0.0161
27         0.1279     0.1236     0.1257
28         0.2151     0.3854     0.2761
29         0.1049     0.1667     0.1288
30         0.2329     0.1683     0.1954
31         0.2500     0.1354     0.1757
32         0.2364     0.1313     0.1688
33         0.0637     0.1266     0.0847
34         0.1667     0.0952     0.1212
35         0.1509     0.0792     0.1039
36         0.1872     0.3725     0.2492
37         0.1442     0.1351     0.1395
38         0.2500     0.1158     0.1583
39         0.1250     0.0887     0.1038
40         0.1458     0.0814     0.1045
41         0.5778     0.5000     0.5361
42         0.0541     0.0377     0.0444
43         0.1124     0.3191     0.1662
44         0.1111     0.0202     0.0342
45         0.1429     0.0116     0.0215
46         0.1515     0.0562     0.0820
47         0.4935     0.3486     0.4086
48         0.1659     0.3400     0.2230
49         0.2276     0.5437     0.3209
50         0.0625     0.0098     0.0169
51         0.1445     0.2632     0.1866
52         0.4110     0.6979     0.5174
53         0.3457     0.5833     0.4341
54         0.3228     0.3596     0.3402
55         0.0323     0.0215     0.0258
56         0.2561     0.2333     0.2442
57         0.1737     0.3235     0.2260
58         0.2083     0.3738     0.2676
59         0.2742     0.1504     0.1943
60         0.6990     0.6606     0.6792
61         0.1923     0.3371     0.2449
62         0.2697     0.3981     0.3216
63         0.2807     0.1538     0.1988
64         0.0250     0.0093     0.0135
65         0.0256     0.0101     0.0145
66         0.0579     0.1209     0.0783
67         0.1818     0.0449     0.0721
68         0.4145     0.5833     0.4846
69         0.4091     0.4839     0.4433
70         0.3580     0.2613     0.3021
71         0.4483     0.2826     0.3467
72         0.2105     0.0370     0.0630
73         0.4719     0.3621     0.4098
74         0.1190     0.0467     0.0671
75         0.2302     0.5225     0.3196
76         0.2667     0.3404     0.2991
77         0.1111     0.0900     0.0994
78         0.1143     0.0417     0.0611
79         0.3529     0.0612     0.1043
80         0.0625     0.0179     0.0278
81         0.1176     0.0408     0.0606
82         0.3917     0.5054     0.4413
83         0.2679     0.1389     0.1829
84         0.0357     0.0093     0.0147
85         0.2733     0.3868     0.3203
86         0.3431     0.3153     0.3286
87         0.1124     0.2209     0.1490
88         0.1206     0.1619     0.1382
89         0.2857     0.2075     0.2404
90         0.2000     0.0714     0.1053
91         0.2375     0.4130     0.3016
92         0.0843     0.0667     0.0745
93         0.1915     0.0891     0.1216
94         0.5102     0.4386     0.4717
95         0.2325     0.5464     0.3262
96         0.2276     0.4125     0.2933
97         0.1842     0.2617     0.2162
98         0.0909     0.4713     0.1524
99         0.1892     0.0667     0.0986
----------------------------------------
Macro Avg  0.2232     0.2222     0.2031

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Overall Accuracy: 95.77% (11492/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9597     0.9790     0.9693
1          0.9860     0.9787     0.9823
2          0.9708     0.9408     0.9555
3          0.9318     0.9631     0.9472
4          0.9508     0.9645     0.9576
5          0.9318     0.9737     0.9523
6          0.9914     0.9469     0.9686
7          0.9555     0.9606     0.9580
8          0.9462     0.9453     0.9457
9          0.9503     0.9222     0.9360
----------------------------------------
Macro Avg  0.9574     0.9575     0.9573

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 14/100 | Time: 256.4s | Loss: 3.1312 | Train Acc: 23.93%
--- Evaluating on Epoch 14 Val ---

Overall Accuracy: 22.58% (2258/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4505     0.4607     0.4556
1          0.2568     0.2043     0.2275
2          0.0741     0.0430     0.0544
3          0.1364     0.0337     0.0541
4          0.1961     0.1010     0.1333
5          0.2024     0.1604     0.1789
6          0.2500     0.1980     0.2210
7          0.2333     0.1458     0.1795
8          0.1286     0.3333     0.1856
9          0.3229     0.3444     0.3333
10         0.0595     0.0495     0.0541
11         0.2353     0.0333     0.0584
12         0.2338     0.1748     0.2000
13         0.1765     0.1765     0.1765
14         0.4583     0.1078     0.1746
15         0.1416     0.1416     0.1416
16         0.2439     0.1149     0.1562
17         0.2908     0.5044     0.3689
18         0.1587     0.0952     0.1190
19         0.1000     0.2277     0.1390
20         0.2321     0.5340     0.3235
21         0.3176     0.2784     0.2967
22         0.1481     0.0842     0.1074
23         0.2877     0.6117     0.3913
24         0.2193     0.6629     0.3296
25         0.0746     0.1235     0.0930
26         0.0877     0.0476     0.0617
27         0.0736     0.3034     0.1184
28         0.5217     0.2500     0.3380
29         0.2326     0.1111     0.1504
30         0.2680     0.4059     0.3228
31         0.1406     0.2812     0.1875
32         0.3784     0.1414     0.2059
33         0.0829     0.2152     0.1197
34         0.1304     0.0857     0.1034
35         0.1579     0.1782     0.1674
36         0.2077     0.4216     0.2783
37         0.1406     0.1622     0.1506
38         0.1120     0.1474     0.1273
39         0.1579     0.0484     0.0741
40         0.2609     0.0698     0.1101
41         0.5854     0.4615     0.5161
42         0.0759     0.0566     0.0649
43         0.1111     0.2447     0.1528
44         0.1091     0.1212     0.1148
45         0.3000     0.0349     0.0625
46         0.1800     0.1011     0.1295
47         0.5244     0.3945     0.4503
48         0.2174     0.3500     0.2682
49         0.3902     0.3107     0.3459
50         0.0208     0.0098     0.0133
51         0.1410     0.3474     0.2006
52         0.4710     0.6771     0.5556
53         0.3622     0.4792     0.4126
54         0.3028     0.3772     0.3359
55         0.1000     0.0108     0.0194
56         0.3140     0.3000     0.3068
57         0.1917     0.2255     0.2072
58         0.2353     0.2617     0.2478
59         0.2661     0.2566     0.2613
60         0.5338     0.7248     0.6148
61         0.2260     0.3708     0.2809
62         0.3300     0.3204     0.3251
63         0.3256     0.1346     0.1905
64         0.0842     0.0741     0.0788
65         0.0508     0.0303     0.0380
66         0.0807     0.1429     0.1032
67         0.1667     0.3146     0.2179
68         0.3743     0.5926     0.4588
69         0.3214     0.4839     0.3863
70         0.2704     0.3874     0.3185
71         0.4688     0.4891     0.4787
72         0.1220     0.0463     0.0671
73         0.4464     0.2155     0.2907
74         0.0556     0.0093     0.0160
75         0.3456     0.4234     0.3806
76         0.3553     0.2872     0.3176
77         0.1250     0.0900     0.1047
78         0.1190     0.0521     0.0725
79         0.1250     0.0408     0.0615
80         0.0556     0.0089     0.0154
81         0.1905     0.0816     0.1143
82         0.5692     0.3978     0.4684
83         0.3913     0.0833     0.1374
84         0.0571     0.0185     0.0280
85         0.3000     0.2830     0.2913
86         0.3191     0.2703     0.2927
87         0.1507     0.1279     0.1384
88         0.1181     0.1429     0.1293
89         0.2976     0.2358     0.2632
90         0.2424     0.0714     0.1103
91         0.2991     0.3478     0.3216
92         0.2174     0.0476     0.0781
93         0.2857     0.0990     0.1471
94         0.3247     0.5526     0.4091
95         0.5484     0.1753     0.2656
96         0.3191     0.1875     0.2362
97         0.1116     0.2430     0.1529
98         0.1698     0.1034     0.1286
99         0.1538     0.0381     0.0611
----------------------------------------
Macro Avg  0.2353     0.2258     0.2093

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 12/100 | Time: 317.1s | Loss: 0.0890 | Train Acc: 97.14%
--- Evaluating on Epoch 12 Val ---

Overall Accuracy: 95.90% (11508/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9550     0.9834     0.9690
1          0.9752     0.9817     0.9784
2          0.9541     0.9549     0.9545
3          0.9593     0.9475     0.9534
4          0.9510     0.9687     0.9598
5          0.9543     0.9597     0.9570
6          0.9786     0.9738     0.9762
7          0.9735     0.9477     0.9604
8          0.9336     0.9479     0.9407
9          0.9503     0.9230     0.9365
----------------------------------------
Macro Avg  0.9585     0.9588     0.9586

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 15/100 | Time: 208.2s | Loss: 3.0914 | Train Acc: 24.69%
--- Evaluating on Epoch 15 Val ---

Overall Accuracy: 22.81% (2281/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4512     0.4157     0.4327
1          0.2083     0.1613     0.1818
2          0.1200     0.0968     0.1071
3          0.0690     0.0225     0.0339
4          0.2857     0.0404     0.0708
5          0.1899     0.1415     0.1622
6          0.1498     0.3069     0.2013
7          0.1579     0.1875     0.1714
8          0.1632     0.3333     0.2191
9          0.3605     0.3444     0.3523
10         0.1923     0.0495     0.0787
11         0.3077     0.0333     0.0602
12         0.2038     0.3107     0.2462
13         0.1194     0.1569     0.1356
14         0.1587     0.2941     0.2062
15         0.2258     0.0619     0.0972
16         0.1447     0.1264     0.1350
17         0.3793     0.3894     0.3843
18         0.1250     0.1619     0.1411
19         0.1311     0.0792     0.0988
20         0.2802     0.4951     0.3579
21         0.1862     0.4742     0.2674
22         0.2391     0.1158     0.1560
23         0.5254     0.3010     0.3827
24         0.3197     0.5281     0.3983
25         0.1228     0.1728     0.1436
26         0.0909     0.0190     0.0315
27         0.0928     0.1011     0.0968
28         0.4306     0.3229     0.3690
29         0.2903     0.1000     0.1488
30         0.2778     0.1485     0.1935
31         0.1500     0.1875     0.1667
32         0.2759     0.1616     0.2038
33         0.1005     0.2658     0.1458
34         0.1622     0.0571     0.0845
35         0.2195     0.0891     0.1268
36         0.2979     0.2745     0.2857
37         0.1765     0.0541     0.0828
38         0.3600     0.0947     0.1500
39         0.1170     0.1613     0.1356
40         0.1121     0.1395     0.1244
41         0.4252     0.5192     0.4675
42         0.0929     0.1226     0.1057
43         0.1111     0.2447     0.1528
44         0.1228     0.0707     0.0897
45         0.1103     0.1744     0.1351
46         0.1695     0.1124     0.1351
47         0.4653     0.4312     0.4476
48         0.1674     0.4000     0.2360
49         0.4342     0.3204     0.3687
50         0.2000     0.0098     0.0187
51         0.1905     0.2105     0.2000
52         0.5172     0.6250     0.5660
53         0.3065     0.5938     0.4043
54         0.2679     0.3947     0.3191
55         0.2500     0.0108     0.0206
56         0.3474     0.3667     0.3568
57         0.2708     0.2549     0.2626
58         0.1695     0.2804     0.2113
59         0.2683     0.1947     0.2256
60         0.6847     0.6972     0.6909
61         0.2871     0.3258     0.3053
62         0.3190     0.3592     0.3379
63         0.2234     0.2019     0.2121
64         0.0000     0.0000     0.0000
65         0.1143     0.0404     0.0597
66         0.0610     0.2308     0.0966
67         0.1875     0.0337     0.0571
68         0.6076     0.4444     0.5134
69         0.4433     0.4624     0.4526
70         0.3913     0.0811     0.1343
71         0.4423     0.5000     0.4694
72         0.1667     0.0278     0.0476
73         0.4234     0.4052     0.4141
74         0.0893     0.1402     0.1091
75         0.3105     0.5315     0.3920
76         0.4333     0.2766     0.3377
77         0.0926     0.0500     0.0649
78         0.0364     0.0208     0.0265
79         0.1299     0.1020     0.1143
80         0.3333     0.0089     0.0174
81         0.1892     0.0714     0.1037
82         0.4412     0.4839     0.4615
83         0.2170     0.2130     0.2150
84         0.0808     0.0741     0.0773
85         0.2308     0.4528     0.3057
86         0.4030     0.2432     0.3034
87         0.1573     0.1628     0.1600
88         0.1333     0.1714     0.1500
89         0.2326     0.2830     0.2553
90         0.2500     0.0268     0.0484
91         0.3699     0.2935     0.3273
92         0.1489     0.0667     0.0921
93         0.3750     0.0594     0.1026
94         0.2236     0.6140     0.3279
95         0.2600     0.5361     0.3502
96         0.2903     0.2250     0.2535
97         0.1414     0.2523     0.1812
98         0.1410     0.2529     0.1811
99         0.1364     0.0857     0.1053
----------------------------------------
Macro Avg  0.2406     0.2282     0.2115

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 13/100 | Time: 247.4s | Loss: 0.0833 | Train Acc: 97.29%
--- Evaluating on Epoch 13 Val ---

Overall Accuracy: 96.07% (11528/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9695     0.9729     0.9712
1          0.9831     0.9824     0.9828
2          0.9527     0.9611     0.9569
3          0.9641     0.9467     0.9553
4          0.9382     0.9755     0.9564
5          0.9676     0.9540     0.9608
6          0.9686     0.9845     0.9765
7          0.9773     0.9477     0.9623
8          0.9369     0.9513     0.9441
9          0.9449     0.9281     0.9364
----------------------------------------
Macro Avg  0.9603     0.9604     0.9603

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 16/100 | Time: 213.8s | Loss: 3.0562 | Train Acc: 25.32%
--- Evaluating on Epoch 16 Val ---

Overall Accuracy: 23.35% (2335/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3082     0.5056     0.3830
1          0.2718     0.3011     0.2857
2          0.1037     0.1828     0.1323
3          0.0364     0.0225     0.0278
4          0.2286     0.0808     0.1194
5          0.2745     0.1321     0.1783
6          0.1842     0.2079     0.1953
7          0.2857     0.1875     0.2264
8          0.2015     0.2903     0.2379
9          0.2587     0.4111     0.3176
10         0.1207     0.0693     0.0881
11         0.2254     0.1333     0.1675
12         0.2344     0.1456     0.1796
13         0.1702     0.0784     0.1074
14         0.2857     0.1961     0.2326
15         0.1370     0.0885     0.1075
16         0.2500     0.0690     0.1081
17         0.3464     0.5487     0.4247
18         0.1111     0.0381     0.0567
19         0.3750     0.0297     0.0550
20         0.4083     0.4757     0.4395
21         0.2410     0.4845     0.3219
22         0.1702     0.1684     0.1693
23         0.3571     0.2427     0.2890
24         0.3936     0.4157     0.4044
25         0.3810     0.0988     0.1569
26         0.1034     0.1143     0.1086
27         0.1287     0.1461     0.1368
28         0.4030     0.2812     0.3313
29         0.2182     0.1333     0.1655
30         0.2327     0.3663     0.2846
31         0.1170     0.4167     0.1826
32         0.3333     0.1313     0.1884
33         0.1818     0.2025     0.1916
34         0.0526     0.0095     0.0161
35         0.1258     0.1881     0.1508
36         0.1772     0.4412     0.2528
37         0.1557     0.2342     0.1871
38         0.1141     0.2211     0.1505
39         0.1744     0.1210     0.1429
40         0.1754     0.1163     0.1399
41         0.3750     0.5192     0.4355
42         0.1017     0.1132     0.1071
43         0.1122     0.3511     0.1701
44         0.1250     0.0303     0.0488
45         0.1389     0.0581     0.0820
46         0.1639     0.1124     0.1333
47         0.5000     0.3761     0.4293
48         0.4028     0.2900     0.3372
49         0.4340     0.2233     0.2949
50         0.0952     0.0196     0.0325
51         0.1733     0.2737     0.2122
52         0.4961     0.6562     0.5650
53         0.4588     0.4062     0.4309
54         0.2857     0.3158     0.3000
55         0.1250     0.0430     0.0640
56         0.3563     0.3444     0.3503
57         0.2243     0.2353     0.2297
58         0.2400     0.2804     0.2586
59         0.3333     0.1947     0.2458
60         0.7701     0.6147     0.6837
61         0.2627     0.3483     0.2995
62         0.3750     0.1165     0.1778
63         0.2286     0.2308     0.2297
64         0.0465     0.0185     0.0265
65         0.0435     0.0101     0.0164
66         0.0711     0.1538     0.0972
67         0.2459     0.1685     0.2000
68         0.6582     0.4815     0.5561
69         0.2427     0.6237     0.3494
70         0.3148     0.1532     0.2061
71         0.5106     0.5217     0.5161
72         0.2500     0.0093     0.0179
73         0.4815     0.3362     0.3959
74         0.1259     0.1589     0.1405
75         0.3232     0.4775     0.3855
76         0.2068     0.5213     0.2961
77         0.1077     0.1400     0.1217
78         0.0920     0.0833     0.0874
79         0.0968     0.2143     0.1333
80         0.0556     0.0179     0.0270
81         0.2973     0.1122     0.1630
82         0.5301     0.4731     0.5000
83         0.2642     0.1296     0.1739
84         0.1481     0.0370     0.0593
85         0.2567     0.4528     0.3276
86         0.2381     0.4505     0.3115
87         0.1392     0.1279     0.1333
88         0.1750     0.0667     0.0966
89         0.3390     0.1887     0.2424
90         0.2500     0.0804     0.1216
91         0.4800     0.2609     0.3380
92         0.1569     0.2286     0.1860
93         0.2703     0.0990     0.1449
94         0.5816     0.5000     0.5377
95         0.3731     0.2577     0.3049
96         0.3049     0.3125     0.3086
97         0.1075     0.3738     0.1670
98         0.1524     0.1839     0.1667
99         0.0933     0.0667     0.0778
----------------------------------------
Macro Avg  0.2486     0.2337     0.2209

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 14/100 | Time: 257.8s | Loss: 0.0791 | Train Acc: 97.48%
--- Evaluating on Epoch 14 Val ---

Overall Accuracy: 95.75% (11490/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9770     0.9659     0.9714
1          0.9731     0.9824     0.9777
2          0.9215     0.9752     0.9476
3          0.9244     0.9721     0.9477
4          0.9764     0.9459     0.9609
5          0.9526     0.9615     0.9570
6          0.9699     0.9763     0.9731
7          0.9810     0.9416     0.9609
8          0.9511     0.9308     0.9409
9          0.9470     0.9213     0.9340
----------------------------------------
Macro Avg  0.9574     0.9573     0.9571


Epoch 17/100 | Time: 221.0s | Loss: 3.0223 | Train Acc: 26.03%
--- Evaluating on Epoch 17 Val ---

Overall Accuracy: 22.06% (2206/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2488     0.6067     0.3529
1          0.1675     0.3656     0.2297
2          0.1837     0.0968     0.1268
3          0.0920     0.0899     0.0909
4          0.1481     0.0404     0.0635
5          0.2500     0.1038     0.1467
6          0.1800     0.0891     0.1192
7          0.1684     0.3438     0.2260
8          0.2778     0.2151     0.2424
9          0.3704     0.3333     0.3509
10         0.1549     0.1089     0.1279
11         0.1970     0.1083     0.1398
12         0.1236     0.1068     0.1146
13         0.1196     0.2157     0.1538
14         0.1236     0.3235     0.1789
15         0.3889     0.0619     0.1069
16         0.1068     0.1264     0.1158
17         0.3933     0.3097     0.3465
18         0.1263     0.1143     0.1200
19         0.1707     0.1386     0.1530
20         0.5926     0.3107     0.4076
21         0.2710     0.2990     0.2843
22         0.1781     0.1368     0.1548
23         0.3485     0.4466     0.3915
24         0.3091     0.5730     0.4016
25         0.2903     0.1111     0.1607
26         0.0000     0.0000     0.0000
27         0.1266     0.1124     0.1190
28         0.3256     0.2917     0.3077
29         0.1667     0.0778     0.1061
30         0.1809     0.1683     0.1744
31         0.2667     0.0833     0.1270
32         0.2679     0.1515     0.1935
33         0.0452     0.0886     0.0598
34         0.3684     0.0667     0.1129
35         0.1169     0.0891     0.1011
36         0.3878     0.1863     0.2517
37         0.1250     0.0360     0.0559
38         0.2000     0.0842     0.1185
39         0.2667     0.0645     0.1039
40         0.1000     0.1628     0.1239
41         0.3121     0.4712     0.3755
42         0.1176     0.0377     0.0571
43         0.1688     0.1383     0.1520
44         0.1690     0.1212     0.1412
45         0.4444     0.0465     0.0842
46         0.2188     0.0787     0.1157
47         0.4731     0.4037     0.4356
48         0.2131     0.2600     0.2342
49         0.2889     0.2524     0.2694
50         0.5000     0.0196     0.0377
51         0.1833     0.1158     0.1419
52         0.3645     0.7708     0.4950
53         0.3790     0.4896     0.4273
54         0.2439     0.3509     0.2878
55         0.0000     0.0000     0.0000
56         0.1212     0.3556     0.1808
57         0.1722     0.2549     0.2055
58         0.2460     0.2897     0.2661
59         0.1448     0.2832     0.1916
60         0.6355     0.6239     0.6296
61         0.1759     0.4270     0.2492
62         0.3178     0.3981     0.3534
63         0.1735     0.3269     0.2267
64         0.0943     0.0463     0.0621
65         0.0741     0.0606     0.0667
66         0.1429     0.0769     0.1000
67         0.1159     0.3034     0.1677
68         0.4125     0.6111     0.4925
69         0.3913     0.2903     0.3333
70         0.3333     0.1441     0.2013
71         0.2763     0.6848     0.3938
72         0.1193     0.1204     0.1198
73         0.2781     0.4483     0.3432
74         0.2059     0.0654     0.0993
75         0.3551     0.4414     0.3936
76         0.2154     0.4468     0.2907
77         0.0877     0.0500     0.0637
78         0.2500     0.0208     0.0385
79         0.2188     0.0714     0.1077
80         0.2143     0.0268     0.0476
81         0.1429     0.1327     0.1376
82         0.3214     0.5806     0.4138
83         0.2234     0.1944     0.2079
84         0.0870     0.0185     0.0305
85         0.2059     0.3302     0.2536
86         0.5946     0.1982     0.2973
87         0.1333     0.1860     0.1553
88         0.1478     0.1619     0.1545
89         0.2500     0.1509     0.1882
90         0.1304     0.0536     0.0759
91         0.2952     0.3370     0.3147
92         0.1186     0.0667     0.0854
93         0.1047     0.1980     0.1370
94         0.3931     0.5000     0.4402
95         0.1751     0.5361     0.2640
96         0.1622     0.3000     0.2105
97         0.2340     0.1028     0.1429
98         0.1735     0.1954     0.1838
99         0.1667     0.0476     0.0741
----------------------------------------
Macro Avg  0.2283     0.2215     0.1991


Epoch 15/100 | Time: 264.9s | Loss: 0.0738 | Train Acc: 97.66%
--- Evaluating on Epoch 15 Val ---

Overall Accuracy: 96.17% (11541/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9590     0.9825     0.9706
1          0.9725     0.9853     0.9789
2          0.9527     0.9611     0.9569
3          0.9592     0.9623     0.9607
4          0.9780     0.9408     0.9590
5          0.9705     0.9578     0.9641
6          0.9817     0.9673     0.9745
7          0.9616     0.9674     0.9645
8          0.9327     0.9582     0.9452
9          0.9491     0.9306     0.9398
----------------------------------------
Macro Avg  0.9617     0.9613     0.9614

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 18/100 | Time: 224.0s | Loss: 2.9891 | Train Acc: 26.57%
--- Evaluating on Epoch 18 Val ---

Overall Accuracy: 23.86% (2386/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3092     0.5281     0.3900
1          0.3059     0.2796     0.2921
2          0.1064     0.1075     0.1070
3          0.0463     0.0562     0.0508
4          0.1000     0.0909     0.0952
5          0.1392     0.2075     0.1667
6          0.2353     0.1584     0.1893
7          0.3500     0.1458     0.2059
8          0.2985     0.2151     0.2500
9          0.7368     0.3111     0.4375
10         0.1190     0.0495     0.0699
11         0.1750     0.1167     0.1400
12         0.2903     0.1748     0.2182
13         0.1828     0.1667     0.1744
14         0.2840     0.2255     0.2514
15         0.2500     0.1062     0.1491
16         0.1714     0.1379     0.1529
17         0.3696     0.4513     0.4064
18         0.1489     0.0667     0.0921
19         0.2241     0.1287     0.1635
20         0.3846     0.4854     0.4292
21         0.1726     0.5979     0.2679
22         0.2564     0.1053     0.1493
23         0.2812     0.5243     0.3661
24         0.2511     0.6180     0.3571
25         0.1075     0.1235     0.1149
26         0.1029     0.0667     0.0809
27         0.0880     0.2135     0.1246
28         0.5370     0.3021     0.3867
29         0.1702     0.1778     0.1739
30         0.3012     0.2475     0.2717
31         0.1111     0.3750     0.1714
32         0.4167     0.1515     0.2222
33         0.1429     0.1772     0.1582
34         0.1508     0.1810     0.1645
35         0.0971     0.0990     0.0980
36         0.3000     0.2647     0.2812
37         0.1538     0.1802     0.1660
38         0.1875     0.1263     0.1509
39         0.1634     0.2016     0.1805
40         0.2203     0.1512     0.1793
41         0.4312     0.4519     0.4413
42         0.1184     0.0849     0.0989
43         0.1778     0.1702     0.1739
44         0.1042     0.0505     0.0680
45         0.2174     0.0581     0.0917
46         0.0747     0.1461     0.0989
47         0.3333     0.4220     0.3725
48         0.2650     0.3100     0.2857
49         0.3906     0.2427     0.2994
50         0.2143     0.0294     0.0517
51         0.2056     0.2316     0.2178
52         0.4651     0.6250     0.5333
53         0.4651     0.4167     0.4396
54         0.2979     0.3684     0.3294
55         0.0449     0.0430     0.0440
56         0.2913     0.3333     0.3109
57         0.3846     0.2451     0.2994
58         0.2437     0.3645     0.2921
59         0.2823     0.3097     0.2954
60         0.8028     0.5229     0.6333
61         0.2959     0.3258     0.3102
62         0.3190     0.3592     0.3379
63         0.1309     0.3462     0.1900
64         0.1148     0.0648     0.0828
65         0.0781     0.0505     0.0613
66         0.1379     0.0440     0.0667
67         0.1695     0.1124     0.1351
68         0.3929     0.7130     0.5066
69         0.3504     0.5161     0.4174
70         0.4074     0.0991     0.1594
71         0.4381     0.5000     0.4670
72         0.1071     0.1111     0.1091
73         0.3623     0.4310     0.3937
74         0.0857     0.1121     0.0972
75         0.2959     0.5225     0.3779
76         0.2982     0.3617     0.3269
77         0.0992     0.1200     0.1086
78         0.1765     0.0312     0.0531
79         0.1462     0.1939     0.1667
80         0.2857     0.0179     0.0336
81         0.1395     0.1837     0.1586
82         0.5432     0.4731     0.5057
83         0.2471     0.1944     0.2176
84         0.0909     0.0370     0.0526
85         0.3407     0.2925     0.3147
86         0.4776     0.2883     0.3596
87         0.2162     0.1860     0.2000
88         0.3333     0.0667     0.1111
89         0.2333     0.1981     0.2143
90         0.1750     0.0625     0.0921
91         0.2621     0.4130     0.3207
92         0.1429     0.0381     0.0602
93         0.1875     0.1485     0.1657
94         0.4437     0.5526     0.4922
95         0.2753     0.5052     0.3564
96         0.3077     0.1500     0.2017
97         0.1761     0.2897     0.2191
98         0.2857     0.0460     0.0792
99         0.1250     0.0952     0.1081
----------------------------------------
Macro Avg  0.2494     0.2377     0.2250

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 16/100 | Time: 288.5s | Loss: 0.0698 | Train Acc: 97.75%
--- Evaluating on Epoch 16 Val ---

Epoch 19/100 | Time: 256.5s | Loss: 2.9614 | Train Acc: 27.11%
--- Evaluating on Epoch 19 Val ---

Overall Accuracy: 96.14% (11537/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9527     0.9878     0.9699
1          0.9875     0.9839     0.9857
2          0.9578     0.9637     0.9608
3          0.9697     0.9434     0.9564
4          0.9682     0.9535     0.9608
5          0.9300     0.9719     0.9505
6          0.9778     0.9738     0.9758
7          0.9707     0.9553     0.9629
8          0.9639     0.9351     0.9493
9          0.9293     0.9450     0.9371
----------------------------------------
Macro Avg  0.9608     0.9613     0.9609


Overall Accuracy: 23.70% (2370/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3446     0.5730     0.4304
1          0.2872     0.2903     0.2888
2          0.1007     0.1505     0.1207
3          0.0577     0.0337     0.0426
4          0.1447     0.1111     0.1257
5          0.1299     0.3113     0.1833
6          0.3235     0.1089     0.1630
7          0.3188     0.2292     0.2667
8          0.2432     0.2903     0.2647
9          0.4521     0.3667     0.4049
10         0.1429     0.0990     0.1170
11         0.1912     0.1083     0.1383
12         0.3774     0.1942     0.2564
13         0.3333     0.0490     0.0855
14         0.2188     0.2745     0.2435
15         0.1359     0.1239     0.1296
16         0.1622     0.1379     0.1491
17         0.3597     0.4425     0.3968
18         0.0984     0.0571     0.0723
19         0.2090     0.1386     0.1667
20         0.3669     0.4951     0.4215
21         0.2538     0.5155     0.3401
22         0.2903     0.0947     0.1429
23         0.3879     0.4369     0.4110
24         0.2414     0.5506     0.3356
25         0.1786     0.1235     0.1460
26         0.0588     0.0095     0.0164
27         0.1633     0.1798     0.1711
28         0.3846     0.3646     0.3743
29         0.1250     0.1889     0.1504
30         0.4062     0.2574     0.3152
31         0.2062     0.2083     0.2073
32         0.6250     0.1010     0.1739
33         0.0798     0.2152     0.1164
34         0.0698     0.0286     0.0405
35         0.1667     0.1188     0.1387
36         0.2260     0.3922     0.2867
37         0.1351     0.0450     0.0676
38         0.1188     0.2526     0.1616
39         0.1538     0.0323     0.0533
40         0.1695     0.1163     0.1379
41         0.5849     0.2981     0.3949
42         0.1333     0.0943     0.1105
43         0.1283     0.2553     0.1708
44         0.1527     0.2020     0.1739
45         0.0947     0.1047     0.0994
46         0.1628     0.0787     0.1061
47         0.5645     0.3211     0.4094
48         0.4058     0.2800     0.3314
49         0.8000     0.0777     0.1416
50         0.0588     0.0098     0.0168
51         0.2500     0.2000     0.2222
52         0.4261     0.7812     0.5515
53         0.3137     0.6667     0.4267
54         0.3009     0.2982     0.2996
55         0.1250     0.0323     0.0513
56         0.2683     0.3667     0.3099
57         0.3636     0.2353     0.2857
58         0.2917     0.1963     0.2346
59         0.3404     0.1416     0.2000
60         0.5532     0.7156     0.6240
61         0.3069     0.3483     0.3263
62         0.3333     0.1845     0.2375
63         0.1299     0.3846     0.1942
64         0.1200     0.1389     0.1288
65         0.0806     0.1010     0.0897
66         0.0773     0.1648     0.1053
67         0.1700     0.4831     0.2515
68         0.4128     0.6574     0.5071
69         0.3833     0.4946     0.4319
70         0.2517     0.3333     0.2868
71         0.4396     0.4348     0.4372
72         0.0784     0.0370     0.0503
73         0.6774     0.1810     0.2857
74         0.1831     0.1215     0.1461
75         0.4474     0.4595     0.4533
76         0.3592     0.3936     0.3756
77         0.1118     0.1800     0.1379
78         0.0625     0.0312     0.0417
79         0.0899     0.3367     0.1419
80         0.0962     0.0446     0.0610
81         0.2083     0.1531     0.1765
82         0.5909     0.4194     0.4906
83         0.2192     0.1481     0.1768
84         0.0536     0.0278     0.0366
85         0.1895     0.5094     0.2762
86         0.3046     0.4144     0.3511
87         0.2800     0.0814     0.1261
88         0.2105     0.0381     0.0645
89         0.2427     0.2358     0.2392
90         0.2037     0.0982     0.1325
91         0.3889     0.3043     0.3415
92         0.1200     0.0857     0.1000
93         0.3438     0.1089     0.1654
94         0.3026     0.6053     0.4035
95         0.5517     0.1649     0.2540
96         0.2450     0.4625     0.3203
97         0.2857     0.1682     0.2118
98         0.2128     0.1149     0.1493
99         0.2857     0.0190     0.0357
----------------------------------------
Macro Avg  0.2581     0.2384     0.2216


Epoch 20/100 | Time: 223.9s | Loss: 2.9320 | Train Acc: 27.77%
--- Evaluating on Epoch 20 Val ---

Epoch 17/100 | Time: 246.9s | Loss: 0.0647 | Train Acc: 97.94%
--- Evaluating on Epoch 17 Val ---

Overall Accuracy: 23.59% (2359/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4655     0.3034     0.3673
1          0.2637     0.2581     0.2609
2          0.1250     0.1398     0.1320
3          0.0676     0.0562     0.0613
4          0.1935     0.0606     0.0923
5          0.1818     0.1509     0.1649
6          0.1835     0.1980     0.1905
7          0.1174     0.3646     0.1777
8          0.1608     0.3441     0.2192
9          0.2342     0.4111     0.2984
10         0.1515     0.0495     0.0746
11         0.2742     0.1417     0.1868
12         0.1652     0.3592     0.2263
13         0.1905     0.0392     0.0650
14         0.1648     0.1471     0.1554
15         0.1897     0.0973     0.1287
16         0.1571     0.1264     0.1401
17         0.3457     0.4956     0.4073
18         0.1395     0.0571     0.0811
19         0.1707     0.1386     0.1530
20         0.6071     0.3301     0.4277
21         0.3056     0.3402     0.3220
22         0.1927     0.2211     0.2059
23         0.3377     0.2524     0.2889
24         0.3000     0.4719     0.3668
25         0.2128     0.1235     0.1562
26         0.0897     0.0667     0.0765
27         0.0851     0.0449     0.0588
28         0.3684     0.3646     0.3665
29         0.2286     0.1778     0.2000
30         0.3131     0.3069     0.3100
31         0.3750     0.1562     0.2206
32         0.2750     0.1111     0.1583
33         0.1579     0.1899     0.1724
34         0.2075     0.1048     0.1392
35         0.1333     0.0990     0.1136
36         0.2680     0.2549     0.2613
37         0.2034     0.1081     0.1412
38         0.2500     0.1579     0.1935
39         0.1143     0.2903     0.1640
40         0.1852     0.0581     0.0885
41         0.4857     0.4904     0.4880
42         0.1111     0.0566     0.0750
43         0.1623     0.2660     0.2016
44         0.1429     0.0505     0.0746
45         0.0000     0.0000     0.0000
46         0.1154     0.1011     0.1078
47         0.5455     0.3853     0.4516
48         0.1632     0.3900     0.2301
49         0.4054     0.2913     0.3390
50         0.5714     0.0392     0.0734
51         0.2385     0.2737     0.2549
52         0.4157     0.7708     0.5401
53         0.3308     0.4583     0.3843
54         0.2632     0.2632     0.2632
55         0.1818     0.0215     0.0385
56         0.2917     0.3889     0.3333
57         0.3016     0.1863     0.2303
58         0.2377     0.2710     0.2533
59         0.3478     0.1416     0.2013
60         0.7778     0.7064     0.7404
61         0.2222     0.3146     0.2605
62         0.2057     0.4175     0.2756
63         0.3833     0.2212     0.2805
64         0.0921     0.0648     0.0761
65         0.1633     0.0808     0.1081
66         0.0722     0.0769     0.0745
67         0.2245     0.2472     0.2353
68         0.5429     0.5278     0.5352
69         0.2470     0.6559     0.3588
70         0.3077     0.2523     0.2772
71         0.5735     0.4239     0.4875
72         0.2222     0.0370     0.0635
73         0.4730     0.3017     0.3684
74         0.1348     0.1121     0.1224
75         0.3630     0.4775     0.4125
76         0.2470     0.4362     0.3154
77         0.0758     0.0500     0.0602
78         0.1000     0.0521     0.0685
79         0.1538     0.1837     0.1674
80         0.1364     0.0268     0.0448
81         0.2346     0.1939     0.2123
82         0.4545     0.4839     0.4687
83         0.1337     0.4815     0.2093
84         0.0902     0.2037     0.1250
85         0.3871     0.2264     0.2857
86         0.2878     0.3604     0.3200
87         0.1772     0.1628     0.1697
88         0.1410     0.1048     0.1202
89         0.1879     0.2925     0.2288
90         0.2051     0.0714     0.1060
91         0.4348     0.3261     0.3727
92         0.1264     0.2095     0.1577
93         0.4545     0.0990     0.1626
94         0.3986     0.5175     0.4504
95         0.3729     0.2268     0.2821
96         0.3571     0.2500     0.2941
97         0.1586     0.3364     0.2156
98         0.1176     0.1379     0.1270
99         0.1207     0.1333     0.1267
----------------------------------------
Macro Avg  0.2502     0.2350     0.2232


Overall Accuracy: 96.31% (11557/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9640     0.9834     0.9736
1          0.9796     0.9883     0.9839
2          0.9701     0.9469     0.9584
3          0.9748     0.9516     0.9631
4          0.9642     0.9560     0.9601
5          0.9687     0.9568     0.9627
6          0.9686     0.9853     0.9769
7          0.9363     0.9803     0.9578
8          0.9623     0.9377     0.9498
9          0.9446     0.9374     0.9410
----------------------------------------
Macro Avg  0.9633     0.9624     0.9627

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 21/100 | Time: 205.9s | Loss: 2.9017 | Train Acc: 28.43%
--- Evaluating on Epoch 21 Val ---

Overall Accuracy: 24.32% (2432/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6038     0.3596     0.4507
1          0.2838     0.2258     0.2515
2          0.0780     0.1828     0.1093
3          0.1029     0.0787     0.0892
4          0.1389     0.1010     0.1170
5          0.2114     0.2453     0.2271
6          0.1485     0.1485     0.1485
7          0.1488     0.3333     0.2058
8          0.2545     0.3011     0.2759
9          0.1887     0.4444     0.2649
10         0.1633     0.0792     0.1067
11         0.3226     0.0833     0.1325
12         0.4167     0.0971     0.1575
13         0.1698     0.0882     0.1161
14         0.2266     0.2843     0.2522
15         0.1628     0.1239     0.1407
16         0.1078     0.1264     0.1164
17         0.3968     0.4425     0.4184
18         0.1905     0.0762     0.1088
19         0.2245     0.1089     0.1467
20         0.2658     0.6117     0.3706
21         0.3564     0.3711     0.3636
22         0.1852     0.1579     0.1705
23         0.3646     0.3398     0.3518
24         0.2986     0.4831     0.3691
25         0.1259     0.2222     0.1607
26         0.1795     0.0667     0.0972
27         0.1166     0.2135     0.1508
28         0.3750     0.3438     0.3587
29         0.1391     0.1778     0.1561
30         0.3733     0.2772     0.3182
31         0.1901     0.2396     0.2120
32         0.3939     0.1313     0.1970
33         0.1733     0.1646     0.1688
34         0.0606     0.0381     0.0468
35         0.1203     0.1881     0.1467
36         0.2500     0.3235     0.2821
37         0.2281     0.1171     0.1548
38         0.2174     0.1579     0.1829
39         0.1711     0.1048     0.1300
40         0.1633     0.0930     0.1185
41         0.4173     0.5096     0.4589
42         0.1373     0.1321     0.1346
43         0.0998     0.4574     0.1638
44         0.1837     0.0909     0.1216
45         0.3125     0.0581     0.0980
46         0.1053     0.0899     0.0970
47         0.4608     0.4312     0.4455
48         0.4516     0.2800     0.3457
49         0.4348     0.2913     0.3488
50         0.2353     0.0392     0.0672
51         0.1775     0.3158     0.2273
52         0.4643     0.6771     0.5508
53         0.2344     0.7812     0.3606
54         0.2448     0.4123     0.3072
55         0.0000     0.0000     0.0000
56         0.3671     0.3222     0.3432
57         0.2179     0.3333     0.2636
58         0.2604     0.2336     0.2463
59         0.2875     0.2035     0.2383
60         0.6827     0.6514     0.6667
61         0.2429     0.3820     0.2969
62         0.3203     0.3981     0.3550
63         0.2021     0.3654     0.2603
64         0.0833     0.0185     0.0303
65         0.1321     0.0707     0.0921
66         0.1098     0.2088     0.1439
67         0.2784     0.3034     0.2903
68         0.6986     0.4722     0.5635
69         0.4298     0.5269     0.4734
70         0.3253     0.2432     0.2784
71         0.5185     0.4565     0.4855
72         0.1429     0.0278     0.0465
73         0.5000     0.3190     0.3895
74         0.1385     0.0841     0.1047
75         0.4464     0.4505     0.4484
76         0.3721     0.3404     0.3556
77         0.1091     0.1200     0.1143
78         0.0903     0.1354     0.1083
79         0.1167     0.1429     0.1284
80         0.0000     0.0000     0.0000
81         0.2000     0.2143     0.2069
82         0.4433     0.4624     0.4526
83         0.2045     0.1667     0.1837
84         0.0682     0.0278     0.0395
85         0.2563     0.4811     0.3344
86         0.3279     0.3604     0.3433
87         0.1707     0.1628     0.1667
88         0.1558     0.1143     0.1319
89         0.2596     0.2547     0.2571
90         0.2727     0.0536     0.0896
91         0.5476     0.2500     0.3433
92         0.1481     0.0762     0.1006
93         0.2500     0.1089     0.1517
94         0.3926     0.5614     0.4621
95         0.5833     0.2165     0.3158
96         0.3125     0.3125     0.3125
97         0.3030     0.1869     0.2312
98         0.1029     0.2069     0.1374
99         0.0725     0.0476     0.0575
----------------------------------------
Macro Avg  0.2539     0.2439     0.2311

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 18/100 | Time: 253.5s | Loss: 0.0617 | Train Acc: 98.05%
--- Evaluating on Epoch 18 Val ---

Overall Accuracy: 95.91% (11509/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9440     0.9886     0.9658
1          0.9753     0.9868     0.9810
2          0.9387     0.9744     0.9562
3          0.9477     0.9648     0.9561
4          0.9682     0.9518     0.9599
5          0.9520     0.9681     0.9600
6          0.9882     0.9616     0.9747
7          0.9592     0.9629     0.9610
8          0.9867     0.8881     0.9348
9          0.9313     0.9408     0.9360
----------------------------------------
Macro Avg  0.9591     0.9588     0.9586


Epoch 22/100 | Time: 244.9s | Loss: 2.8768 | Train Acc: 29.01%
--- Evaluating on Epoch 22 Val ---

Overall Accuracy: 25.42% (2542/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4393     0.5281     0.4796
1          0.2422     0.4194     0.3071
2          0.0988     0.0860     0.0920
3          0.0769     0.0562     0.0649
4          0.1852     0.1010     0.1307
5          0.1727     0.3585     0.2331
6          0.1505     0.1386     0.1443
7          0.2033     0.2604     0.2283
8          0.1309     0.3871     0.1957
9          0.5072     0.3889     0.4403
10         0.2500     0.0891     0.1314
11         0.3667     0.1833     0.2444
12         0.2951     0.1748     0.2195
13         0.1727     0.1863     0.1792
14         0.2353     0.2353     0.2353
15         0.1414     0.1239     0.1321
16         0.1964     0.1264     0.1538
17         0.4545     0.3097     0.3684
18         0.1667     0.0762     0.1046
19         0.1852     0.1485     0.1648
20         0.3073     0.6117     0.4091
21         0.2993     0.4227     0.3504
22         0.3000     0.1895     0.2323
23         0.3022     0.5340     0.3860
24         0.3333     0.4157     0.3700
25         0.1833     0.1358     0.1560
26         0.0870     0.1524     0.1107
27         0.0984     0.2697     0.1441
28         0.6000     0.2500     0.3529
29         0.2308     0.2000     0.2143
30         0.2368     0.3564     0.2846
31         0.2464     0.1771     0.2061
32         0.3273     0.1818     0.2338
33         0.2182     0.1519     0.1791
34         0.1429     0.1619     0.1518
35         0.2000     0.1485     0.1705
36         0.2538     0.3235     0.2845
37         0.1947     0.3333     0.2458
38         0.3443     0.2211     0.2692
39         0.1805     0.1935     0.1868
40         0.2193     0.2907     0.2500
41         0.3576     0.5673     0.4387
42         0.1096     0.0755     0.0894
43         0.1944     0.2234     0.2079
44         0.1935     0.0606     0.0923
45         0.1538     0.0930     0.1159
46         0.2400     0.0674     0.1053
47         0.4369     0.4128     0.4245
48         0.2319     0.4800     0.3127
49         0.1875     0.5534     0.2801
50         0.3333     0.0196     0.0370
51         0.2609     0.2526     0.2567
52         0.4641     0.7396     0.5703
53         0.2952     0.5104     0.3740
54         0.3306     0.3596     0.3445
55         0.1667     0.0215     0.0381
56         0.3421     0.2889     0.3133
57         0.3012     0.2451     0.2703
58         0.2764     0.3178     0.2957
59         0.3125     0.1770     0.2260
60         0.6545     0.6606     0.6575
61         0.4894     0.2584     0.3382
62         0.2825     0.4854     0.3571
63         0.2522     0.2788     0.2648
64         0.1765     0.0278     0.0480
65         0.1818     0.0606     0.0909
66         0.0938     0.1319     0.1096
67         0.2353     0.0899     0.1301
68         0.5040     0.5833     0.5408
69         0.4227     0.4409     0.4316
70         0.3077     0.2883     0.2977
71         0.4603     0.3152     0.3742
72         0.1739     0.0370     0.0611
73         0.3711     0.3103     0.3380
74         0.1029     0.1308     0.1152
75         0.2985     0.5405     0.3846
76         0.3723     0.3723     0.3723
77         0.0634     0.0900     0.0744
78         0.1489     0.0729     0.0979
79         0.1707     0.0714     0.1007
80         0.1739     0.0357     0.0593
81         0.1680     0.2143     0.1883
82         0.4173     0.5699     0.4818
83         0.1802     0.2870     0.2214
84         0.0750     0.0278     0.0405
85         0.2840     0.4340     0.3433
86         0.3684     0.3153     0.3398
87         0.1569     0.1860     0.1702
88         0.1552     0.0857     0.1104
89         0.2549     0.2453     0.2500
90         0.1948     0.1339     0.1587
91         0.2937     0.4022     0.3394
92         0.1273     0.0667     0.0875
93         0.3667     0.1089     0.1679
94         0.4793     0.5088     0.4936
95         0.3519     0.1959     0.2517
96         0.3529     0.2250     0.2748
97         0.2234     0.1963     0.2090
98         0.2159     0.2184     0.2171
99         0.1029     0.0667     0.0809
----------------------------------------
Macro Avg  0.2587     0.2533     0.2390

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 19/100 | Time: 260.8s | Loss: 0.0582 | Train Acc: 98.14%
--- Evaluating on Epoch 19 Val ---

Overall Accuracy: 95.98% (11518/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9672     0.9808     0.9739
1          0.9761     0.9897     0.9829
2          0.9770     0.9372     0.9567
3          0.9842     0.9172     0.9495
4          0.9541     0.9670     0.9605
5          0.9711     0.9465     0.9587
6          0.9656     0.9861     0.9757
7          0.9553     0.9712     0.9632
8          0.9169     0.9607     0.9383
9          0.9341     0.9349     0.9345
----------------------------------------
Macro Avg  0.9601     0.9591     0.9594


Epoch 23/100 | Time: 200.5s | Loss: 2.8497 | Train Acc: 29.49%
--- Evaluating on Epoch 23 Val ---

Overall Accuracy: 24.12% (2412/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6557     0.4494     0.5333
1          0.2645     0.3441     0.2991
2          0.1162     0.2473     0.1581
3          0.0643     0.1236     0.0846
4          0.1410     0.1111     0.1243
5          0.2586     0.1415     0.1829
6          0.2200     0.1089     0.1457
7          0.2239     0.1562     0.1840
8          0.2500     0.3333     0.2857
9          0.7179     0.3111     0.4341
10         0.1111     0.0297     0.0469
11         0.3636     0.1000     0.1569
12         0.2738     0.2233     0.2460
13         0.2500     0.0490     0.0820
14         0.2597     0.1961     0.2235
15         0.1940     0.1150     0.1444
16         0.1961     0.1149     0.1449
17         0.3659     0.5310     0.4332
18         0.2051     0.0762     0.1111
19         0.5000     0.0792     0.1368
20         0.3841     0.5146     0.4398
21         0.2232     0.5155     0.3115
22         0.3600     0.0947     0.1500
23         0.3469     0.3301     0.3383
24         0.3838     0.4270     0.4043
25         0.2432     0.1111     0.1525
26         0.1429     0.0286     0.0476
27         0.1296     0.0787     0.0979
28         0.4648     0.3438     0.3952
29         0.2895     0.1222     0.1719
30         0.2645     0.4059     0.3203
31         0.1743     0.1979     0.1854
32         0.4483     0.1313     0.2031
33         0.0857     0.2658     0.1296
34         0.1690     0.1143     0.1364
35         0.1500     0.0891     0.1118
36         0.2756     0.3431     0.3057
37         0.2321     0.1171     0.1557
38         0.1133     0.1789     0.1388
39         0.2889     0.1048     0.1538
40         0.2857     0.1163     0.1653
41         0.5128     0.3846     0.4396
42         0.0986     0.3868     0.1571
43         0.1046     0.3404     0.1600
44         0.1667     0.0909     0.1176
45         0.1429     0.1047     0.1208
46         0.0947     0.1011     0.0978
47         0.6216     0.2110     0.3151
48         0.3008     0.3700     0.3318
49         0.5806     0.1748     0.2687
50         0.1719     0.1078     0.1325
51         0.2264     0.1263     0.1622
52         0.4533     0.7083     0.5528
53         0.3314     0.5833     0.4226
54         0.4211     0.2807     0.3368
55         0.1143     0.0430     0.0625
56         0.4717     0.2778     0.3497
57         0.2537     0.3333     0.2881
58         0.3333     0.1869     0.2395
59         0.2569     0.3274     0.2879
60         0.8167     0.4495     0.5799
61         0.2177     0.3596     0.2712
62         0.3934     0.2330     0.2927
63         0.1253     0.4423     0.1953
64         0.0838     0.1389     0.1045
65         0.1231     0.0808     0.0976
66         0.0852     0.1648     0.1124
67         0.2045     0.3034     0.2443
68         0.4153     0.7037     0.5223
69         0.4894     0.4946     0.4920
70         0.3380     0.2162     0.2637
71         0.5455     0.4565     0.4970
72         0.0854     0.1574     0.1107
73         0.3195     0.4655     0.3789
74         0.1860     0.0748     0.1067
75         0.4831     0.5135     0.4978
76         0.3088     0.4468     0.3652
77         0.0902     0.1100     0.0991
78         0.0759     0.0625     0.0686
79         0.1803     0.2245     0.2000
80         0.1224     0.0536     0.0745
81         0.1905     0.1633     0.1758
82         0.5915     0.4516     0.5122
83         0.2424     0.1481     0.1839
84         0.1944     0.0648     0.0972
85         0.4045     0.3396     0.3692
86         0.3271     0.3153     0.3211
87         0.1500     0.2093     0.1748
88         0.1268     0.1714     0.1457
89         0.4706     0.1509     0.2286
90         0.2500     0.0982     0.1410
91         0.4198     0.3696     0.3931
92         0.1739     0.0762     0.1060
93         0.2059     0.0693     0.1037
94         0.3198     0.6228     0.4226
95         0.3944     0.2887     0.3333
96         0.2308     0.3375     0.2741
97         0.1280     0.2523     0.1698
98         0.1731     0.1034     0.1295
99         0.0861     0.1238     0.1016
----------------------------------------
Macro Avg  0.2751     0.2412     0.2347


Epoch 20/100 | Time: 238.0s | Loss: 0.0543 | Train Acc: 98.23%
--- Evaluating on Epoch 20 Val ---

Overall Accuracy: 96.23% (11548/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9892     0.9589     0.9738
1          0.9911     0.9765     0.9837
2          0.9694     0.9531     0.9612
3          0.9620     0.9533     0.9576
4          0.9766     0.9552     0.9658
5          0.9487     0.9709     0.9597
6          0.9787     0.9747     0.9766
7          0.9790     0.9545     0.9666
8          0.8956     0.9744     0.9333
9          0.9343     0.9509     0.9426
----------------------------------------
Macro Avg  0.9625     0.9622     0.9621


Epoch 24/100 | Time: 207.6s | Loss: 2.8245 | Train Acc: 29.98%
--- Evaluating on Epoch 24 Val ---

Overall Accuracy: 25.50% (2550/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2767     0.6404     0.3864
1          0.2338     0.3871     0.2915
2          0.1047     0.2151     0.1408
3          0.0972     0.0787     0.0870
4          0.1327     0.1313     0.1320
5          0.1366     0.2075     0.1648
6          0.1333     0.0396     0.0611
7          0.2632     0.2083     0.2326
8          0.3034     0.2903     0.2967
9          0.3250     0.4333     0.3714
10         0.0959     0.0693     0.0805
11         0.3043     0.1167     0.1687
12         0.2277     0.2233     0.2255
13         0.1735     0.1667     0.1700
14         0.2530     0.2059     0.2270
15         0.3191     0.1327     0.1875
16         0.1333     0.1609     0.1458
17         0.3509     0.5310     0.4225
18         0.1923     0.0476     0.0763
19         0.2073     0.1683     0.1858
20         0.4867     0.5340     0.5093
21         0.2036     0.5876     0.3024
22         0.3333     0.1158     0.1719
23         0.3950     0.4563     0.4234
24         0.3445     0.4607     0.3942
25         0.1548     0.1605     0.1576
26         0.1364     0.0857     0.1053
27         0.1013     0.0899     0.0952
28         0.5306     0.2708     0.3586
29         0.2429     0.1889     0.2125
30         0.3571     0.1980     0.2548
31         0.1366     0.2292     0.1712
32         0.3810     0.1616     0.2270
33         0.1060     0.2025     0.1391
34         0.1957     0.0857     0.1192
35         0.1833     0.2178     0.1991
36         0.3696     0.1667     0.2297
37         0.2135     0.1712     0.1900
38         0.2063     0.1368     0.1646
39         0.2135     0.1532     0.1784
40         0.1812     0.2907     0.2232
41         0.4732     0.5096     0.4907
42         0.1311     0.0755     0.0958
43         0.1517     0.3404     0.2098
44         0.1282     0.0505     0.0725
45         0.1048     0.1512     0.1238
46         0.1207     0.1573     0.1366
47         0.5116     0.4037     0.4513
48         0.2140     0.4600     0.2921
49         0.3656     0.3301     0.3469
50         0.3636     0.0392     0.0708
51         0.2258     0.0737     0.1111
52         0.3361     0.8438     0.4807
53         0.3122     0.6667     0.4252
54         0.4894     0.2018     0.2857
55         0.0000     0.0000     0.0000
56         0.2446     0.3778     0.2969
57         0.3898     0.2255     0.2857
58         0.3063     0.3178     0.3119
59         0.2826     0.1150     0.1635
60         0.6750     0.7431     0.7074
61         0.3191     0.3371     0.3279
62         0.3676     0.2427     0.2924
63         0.3191     0.2885     0.3030
64         0.1370     0.0926     0.1105
65         0.1091     0.0606     0.0779
66         0.1667     0.0330     0.0550
67         0.1875     0.2360     0.2090
68         0.5036     0.6389     0.5633
69         0.3920     0.5269     0.4495
70         0.2716     0.1982     0.2292
71         0.4000     0.5435     0.4608
72         0.1667     0.0833     0.1111
73         0.3304     0.3276     0.3290
74         0.1429     0.1215     0.1313
75         0.4444     0.5045     0.4726
76         0.3391     0.4149     0.3732
77         0.1698     0.0900     0.1176
78         0.1090     0.1771     0.1349
79         0.2000     0.1224     0.1519
80         0.1935     0.0536     0.0839
81         0.1206     0.3878     0.1840
82         0.5196     0.5699     0.5436
83         0.2524     0.2407     0.2464
84         0.1351     0.0463     0.0690
85         0.2857     0.4340     0.3446
86         0.2772     0.4595     0.3458
87         0.1126     0.1977     0.1435
88         0.2500     0.0571     0.0930
89         0.2658     0.1981     0.2270
90         0.1758     0.1429     0.1576
91         0.4250     0.3696     0.3953
92         0.1570     0.1810     0.1681
93         0.2000     0.0693     0.1029
94         0.4493     0.5439     0.4921
95         0.3280     0.4227     0.3694
96         0.2159     0.2375     0.2262
97         0.3265     0.1495     0.2051
98         0.1481     0.1839     0.1641
99         0.1053     0.0952     0.1000
----------------------------------------
Macro Avg  0.2558     0.2558     0.2380

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 21/100 | Time: 255.7s | Loss: 0.0516 | Train Acc: 98.26%
--- Evaluating on Epoch 21 Val ---

Overall Accuracy: 96.25% (11550/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9707     0.9843     0.9774
1          0.9768     0.9868     0.9818
2          0.9180     0.9805     0.9483
3          0.9577     0.9639     0.9608
4          0.9749     0.9535     0.9641
5          0.9695     0.9550     0.9622
6          0.9810     0.9706     0.9758
7          0.9722     0.9545     0.9633
8          0.9678     0.9249     0.9459
9          0.9357     0.9484     0.9420
----------------------------------------
Macro Avg  0.9624     0.9622     0.9621


Epoch 25/100 | Time: 202.1s | Loss: 2.8053 | Train Acc: 30.30%
--- Evaluating on Epoch 25 Val ---

Overall Accuracy: 25.18% (2518/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3810     0.5393     0.4465
1          0.2688     0.2688     0.2688
2          0.0789     0.0645     0.0710
3          0.0833     0.0337     0.0480
4          0.1237     0.1212     0.1224
5          0.1795     0.3302     0.2326
6          0.2203     0.1287     0.1625
7          0.2838     0.2188     0.2471
8          0.4091     0.2903     0.3396
9          0.6957     0.3556     0.4706
10         0.1087     0.0495     0.0680
11         0.2405     0.1583     0.1910
12         0.2574     0.2524     0.2549
13         0.1525     0.0882     0.1118
14         0.5652     0.1275     0.2080
15         0.3095     0.1150     0.1677
16         0.2449     0.1379     0.1765
17         0.3045     0.5929     0.4024
18         0.2157     0.1048     0.1410
19         0.2692     0.0693     0.1102
20         0.3630     0.5146     0.4257
21         0.2291     0.5361     0.3210
22         0.2222     0.1684     0.1916
23         0.2796     0.5049     0.3599
24         0.2635     0.4944     0.3438
25         0.1406     0.2222     0.1722
26         0.0879     0.1524     0.1115
27         0.0763     0.3371     0.1245
28         0.4020     0.4271     0.4141
29         0.2973     0.1222     0.1732
30         0.2695     0.3762     0.3140
31         0.1667     0.2500     0.2000
32         0.5385     0.1414     0.2240
33         0.1548     0.1646     0.1595
34         0.0818     0.0857     0.0837
35         0.1269     0.2475     0.1678
36         0.1509     0.5490     0.2368
37         0.2247     0.1802     0.2000
38         0.1488     0.3368     0.2065
39         0.2091     0.1855     0.1966
40         0.2500     0.0698     0.1091
41         0.6875     0.4231     0.5238
42         0.1534     0.2547     0.1915
43         0.1479     0.2234     0.1780
44         0.1525     0.0909     0.1139
45         0.2727     0.0698     0.1111
46         0.1591     0.0787     0.1053
47         0.5672     0.3486     0.4318
48         0.6154     0.2400     0.3453
49         0.5102     0.2427     0.3289
50         0.1481     0.0784     0.1026
51         0.2097     0.1368     0.1656
52         0.4481     0.7188     0.5520
53         0.4023     0.3646     0.3825
54         0.4359     0.2982     0.3542
55         0.0682     0.0323     0.0438
56         0.3966     0.2556     0.3108
57         0.4082     0.1961     0.2649
58         0.3162     0.4019     0.3539
59         0.2609     0.1593     0.1978
60         0.5634     0.7339     0.6375
61         0.3152     0.3258     0.3204
62         0.3548     0.3204     0.3367
63         0.1923     0.3846     0.2564
64         0.0976     0.0370     0.0537
65         0.1400     0.0707     0.0940
66         0.1207     0.0769     0.0940
67         0.2174     0.3371     0.2643
68         0.5207     0.5833     0.5502
69         0.3413     0.6129     0.4385
70         0.2717     0.2252     0.2463
71         0.3475     0.5326     0.4206
72         0.2609     0.0556     0.0916
73         0.4500     0.2328     0.3068
74         0.0752     0.1589     0.1021
75         0.4071     0.5135     0.4542
76         0.3736     0.3617     0.3676
77         0.0909     0.1900     0.1230
78         0.1562     0.1042     0.1250
79         0.1266     0.2041     0.1562
80         0.2353     0.0357     0.0620
81         0.2152     0.1735     0.1921
82         0.4906     0.5591     0.5226
83         0.4118     0.1296     0.1972
84         0.1046     0.1481     0.1226
85         0.2620     0.4623     0.3345
86         0.3667     0.2973     0.3284
87         0.1727     0.2209     0.1939
88         0.1667     0.0857     0.1132
89         0.4048     0.1604     0.2297
90         0.3462     0.0804     0.1304
91         0.3933     0.3804     0.3867
92         0.1327     0.1238     0.1281
93         0.5385     0.0693     0.1228
94         0.5410     0.5789     0.5593
95         0.4035     0.2371     0.2987
96         0.3467     0.3250     0.3355
97         0.2985     0.1869     0.2299
98         0.2000     0.0575     0.0893
99         0.0811     0.0571     0.0670
----------------------------------------
Macro Avg  0.2797     0.2516     0.2412


Epoch 22/100 | Time: 276.7s | Loss: 0.0492 | Train Acc: 98.42%
--- Evaluating on Epoch 22 Val ---

Epoch 26/100 | Time: 251.4s | Loss: 2.7792 | Train Acc: 30.69%
--- Evaluating on Epoch 26 Val ---

Overall Accuracy: 96.36% (11563/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9664     0.9816     0.9740
1          0.9860     0.9839     0.9849
2          0.9688     0.9593     0.9640
3          0.9738     0.9426     0.9579
4          0.9716     0.9569     0.9642
5          0.9537     0.9653     0.9594
6          0.9640     0.9853     0.9745
7          0.9717     0.9621     0.9669
8          0.9277     0.9641     0.9456
9          0.9484     0.9323     0.9403
----------------------------------------
Macro Avg  0.9632     0.9633     0.9632

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Overall Accuracy: 26.48% (2648/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.5057     0.4944     0.5000
1          0.2395     0.4301     0.3077
2          0.1404     0.1720     0.1546
3          0.1121     0.1348     0.1224
4          0.1944     0.1414     0.1637
5          0.1597     0.2170     0.1840
6          0.1795     0.2079     0.1927
7          0.1728     0.2917     0.2171
8          0.2403     0.3333     0.2793
9          0.4861     0.3889     0.4321
10         0.1765     0.0594     0.0889
11         0.3000     0.2000     0.2400
12         0.1919     0.1845     0.1881
13         0.1910     0.1667     0.1780
14         0.2386     0.2059     0.2211
15         0.2449     0.1062     0.1481
16         0.2121     0.1609     0.1830
17         0.3268     0.4425     0.3759
18         0.2115     0.1048     0.1401
19         0.2162     0.0792     0.1159
20         0.4194     0.5049     0.4581
21         0.2737     0.5361     0.3624
22         0.1534     0.2842     0.1993
23         0.3750     0.3786     0.3768
24         0.2980     0.5056     0.3750
25         0.1765     0.1481     0.1611
26         0.1143     0.1143     0.1143
27         0.1156     0.1910     0.1441
28         0.4928     0.3542     0.4121
29         0.2319     0.1778     0.2013
30         0.3152     0.2871     0.3005
31         0.1560     0.2292     0.1857
32         0.2917     0.2121     0.2456
33         0.1667     0.1519     0.1589
34         0.1215     0.1238     0.1226
35         0.2154     0.1386     0.1687
36         0.3077     0.3529     0.3288
37         0.2115     0.0991     0.1350
38         0.2051     0.1684     0.1850
39         0.2581     0.1935     0.2212
40         0.2533     0.2209     0.2360
41         0.4485     0.5865     0.5083
42         0.1304     0.0566     0.0789
43         0.2545     0.1489     0.1879
44         0.1370     0.1010     0.1163
45         0.2759     0.0930     0.1391
46         0.2727     0.0674     0.1081
47         0.4632     0.4037     0.4314
48         0.2353     0.4400     0.3066
49         0.2814     0.4563     0.3481
50         0.3333     0.0294     0.0541
51         0.2193     0.2632     0.2392
52         0.4345     0.6562     0.5228
53         0.4103     0.3333     0.3678
54         0.3451     0.3421     0.3436
55         0.0741     0.0430     0.0544
56         0.2787     0.3778     0.3208
57         0.6667     0.1765     0.2791
58         0.2201     0.4299     0.2911
59         0.2705     0.2920     0.2809
60         0.7766     0.6697     0.7192
61         0.2292     0.4944     0.3132
62         0.3267     0.3204     0.3235
63         0.3191     0.2885     0.3030
64         0.1538     0.0185     0.0331
65         0.1071     0.1515     0.1255
66         0.0857     0.0330     0.0476
67         0.2020     0.2247     0.2128
68         0.5259     0.5648     0.5446
69         0.3790     0.5054     0.4332
70         0.3256     0.1261     0.1818
71         0.3062     0.6957     0.4252
72         0.1481     0.0741     0.0988
73         0.3672     0.4052     0.3852
74         0.1698     0.0841     0.1125
75         0.3519     0.5135     0.4176
76         0.3309     0.4894     0.3948
77         0.1096     0.0800     0.0925
78         0.1702     0.0833     0.1119
79         0.1268     0.0918     0.1065
80         0.2250     0.0804     0.1184
81         0.1840     0.2347     0.2063
82         0.4380     0.5699     0.4953
83         0.2424     0.2963     0.2667
84         0.1731     0.0833     0.1125
85         0.3231     0.3962     0.3559
86         0.3453     0.4324     0.3840
87         0.1774     0.2558     0.2095
88         0.1583     0.2095     0.1803
89         0.3333     0.2170     0.2629
90         0.1176     0.1250     0.1212
91         0.3248     0.4130     0.3636
92         0.1350     0.2095     0.1642
93         0.1391     0.1584     0.1481
94         0.4820     0.5877     0.5296
95         0.3563     0.3196     0.3370
96         0.3333     0.3250     0.3291
97         0.2394     0.3178     0.2731
98         0.1695     0.1149     0.1370
99         0.0857     0.0286     0.0429
----------------------------------------
Macro Avg  0.2614     0.2648     0.2492

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 27/100 | Time: 228.5s | Loss: 2.7576 | Train Acc: 31.06%
--- Evaluating on Epoch 27 Val ---

Overall Accuracy: 26.25% (2625/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6875     0.3708     0.4818
1          0.2632     0.3763     0.3097
2          0.1017     0.0645     0.0789
3          0.0526     0.0899     0.0664
4          0.1081     0.2020     0.1408
5          0.2632     0.2358     0.2488
6          0.1400     0.1386     0.1393
7          0.2475     0.2604     0.2538
8          0.2727     0.3548     0.3084
9          0.4270     0.4222     0.4246
10         0.2069     0.0594     0.0923
11         0.1769     0.1917     0.1840
12         0.2875     0.2233     0.2514
13         0.1682     0.1765     0.1722
14         0.1969     0.2451     0.2183
15         0.2459     0.1327     0.1724
16         0.1809     0.1954     0.1878
17         0.3471     0.5221     0.4170
18         0.1842     0.1333     0.1547
19         0.1466     0.1683     0.1567
20         0.5229     0.5534     0.5377
21         0.1987     0.6289     0.3020
22         0.3333     0.1474     0.2044
23         0.3697     0.4272     0.3964
24         0.3958     0.4270     0.4108
25         0.2200     0.1358     0.1679
26         0.2381     0.0476     0.0794
27         0.1138     0.1573     0.1321
28         0.5758     0.3958     0.4691
29         0.2830     0.1667     0.2098
30         0.3053     0.2871     0.2959
31         0.1531     0.3333     0.2098
32         0.3269     0.1717     0.2252
33         0.1616     0.2025     0.1798
34         0.1322     0.1524     0.1416
35         0.1379     0.1980     0.1626
36         0.3494     0.2843     0.3135
37         0.2759     0.1441     0.1893
38         0.0987     0.3158     0.1504
39         0.2500     0.2097     0.2281
40         0.2400     0.1395     0.1765
41         0.5213     0.4712     0.4949
42         0.1129     0.1321     0.1217
43         0.1667     0.4149     0.2378
44         0.1159     0.0808     0.0952
45         0.2222     0.1395     0.1714
46         0.1842     0.0787     0.1102
47         0.6667     0.2936     0.4076
48         0.3659     0.3000     0.3297
49         0.4921     0.3010     0.3735
50         0.3529     0.0588     0.1008
51         0.1979     0.2000     0.1990
52         0.5111     0.7188     0.5974
53         0.4356     0.4583     0.4467
54         0.3200     0.3509     0.3347
55         0.1515     0.0538     0.0794
56         0.3404     0.3556     0.3478
57         0.3636     0.2745     0.3128
58         0.2883     0.2991     0.2936
59         0.3778     0.1504     0.2152
60         0.8052     0.5688     0.6667
61         0.3171     0.4382     0.3679
62         0.3304     0.3592     0.3442
63         0.1949     0.3654     0.2542
64         0.1250     0.0648     0.0854
65         0.1200     0.0606     0.0805
66         0.0777     0.1648     0.1056
67         0.2258     0.3146     0.2629
68         0.5943     0.5833     0.5888
69         0.4811     0.5484     0.5126
70         0.3061     0.1351     0.1875
71         0.6269     0.4565     0.5283
72         0.1154     0.0278     0.0448
73         0.4018     0.3879     0.3947
74         0.1304     0.0841     0.1023
75         0.3270     0.6216     0.4286
76         0.3924     0.3298     0.3584
77         0.1215     0.1300     0.1256
78         0.0625     0.0104     0.0179
79         0.1846     0.2449     0.2105
80         0.2941     0.0446     0.0775
81         0.2069     0.1837     0.1946
82         0.4712     0.5269     0.4975
83         0.1744     0.2778     0.2143
84         0.1765     0.1389     0.1554
85         0.2885     0.4245     0.3435
86         0.3833     0.4144     0.3983
87         0.1930     0.2558     0.2200
88         0.1374     0.1714     0.1525
89         0.2830     0.1415     0.1887
90         0.2444     0.0982     0.1401
91         0.5424     0.3478     0.4238
92         0.1296     0.1333     0.1315
93         0.1951     0.0792     0.1127
94         0.5242     0.5702     0.5462
95         0.3750     0.3093     0.3390
96         0.3333     0.4250     0.3736
97         0.1840     0.2804     0.2222
98         0.1506     0.2874     0.1976
99         0.1522     0.0667     0.0927
----------------------------------------
Macro Avg  0.2795     0.2629     0.2560


Epoch 23/100 | Time: 283.4s | Loss: 0.0457 | Train Acc: 98.50%
--- Evaluating on Epoch 23 Val ---

Overall Accuracy: 96.60% (11592/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9807     0.9773     0.9790
1          0.9861     0.9868     0.9864
2          0.9614     0.9682     0.9648
3          0.9686     0.9607     0.9646
4          0.9758     0.9560     0.9658
5          0.9518     0.9634     0.9576
6          0.9588     0.9886     0.9734
7          0.9703     0.9659     0.9681
8          0.9640     0.9385     0.9511
9          0.9390     0.9509     0.9449
----------------------------------------
Macro Avg  0.9656     0.9656     0.9656

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 28/100 | Time: 196.9s | Loss: 2.7343 | Train Acc: 31.66%
--- Evaluating on Epoch 28 Val ---

Overall Accuracy: 26.28% (2628/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3898     0.5169     0.4444
1          0.2887     0.3011     0.2947
2          0.1556     0.2258     0.1842
3          0.1290     0.0449     0.0667
4          0.1591     0.0707     0.0979
5          0.1780     0.3208     0.2290
6          0.2018     0.2277     0.2140
7          0.2727     0.1562     0.1987
8          0.4286     0.2581     0.3221
9          0.4658     0.3778     0.4172
10         0.1778     0.0792     0.1096
11         0.3939     0.1083     0.1699
12         0.2167     0.1262     0.1595
13         0.3220     0.1863     0.2360
14         0.3099     0.2157     0.2543
15         0.1337     0.2389     0.1714
16         0.1944     0.1609     0.1761
17         0.2590     0.5752     0.3571
18         0.1636     0.1714     0.1674
19         0.3056     0.1089     0.1606
20         0.3333     0.5825     0.4240
21         0.3762     0.3918     0.3838
22         0.2656     0.1789     0.2138
23         0.3432     0.5631     0.4265
24         0.2086     0.7079     0.3223
25         0.2037     0.1358     0.1630
26         0.0312     0.0095     0.0146
27         0.1923     0.1124     0.1418
28         0.3388     0.4271     0.3779
29         0.1481     0.2222     0.1778
30         0.2532     0.1980     0.2222
31         0.2247     0.2083     0.2162
32         0.1935     0.2424     0.2152
33         0.1940     0.1646     0.1781
34         0.1139     0.0857     0.0978
35         0.1809     0.1683     0.1744
36         0.1636     0.4412     0.2387
37         0.2258     0.1261     0.1618
38         0.1910     0.1789     0.1848
39         0.3966     0.1855     0.2527
40         0.1682     0.2093     0.1865
41         0.4660     0.4615     0.4638
42         0.2353     0.1132     0.1529
43         0.2289     0.2021     0.2147
44         0.1644     0.1212     0.1395
45         0.2647     0.1047     0.1500
46         0.2326     0.1124     0.1515
47         0.6034     0.3211     0.4192
48         0.3750     0.3300     0.3511
49         0.3750     0.2330     0.2874
50         0.1600     0.0392     0.0630
51         0.1871     0.2737     0.2222
52         0.5000     0.5938     0.5429
53         0.2896     0.6667     0.4038
54         0.2340     0.5439     0.3272
55         0.0833     0.0108     0.0190
56         0.3700     0.4111     0.3895
57         0.2303     0.3431     0.2756
58         0.3594     0.2150     0.2690
59         0.2857     0.2655     0.2752
60         0.5882     0.7339     0.6531
61         0.1832     0.5618     0.2762
62         0.3307     0.4078     0.3652
63         0.3103     0.2596     0.2827
64         0.0930     0.0370     0.0530
65         0.0902     0.1111     0.0995
66         0.1364     0.0659     0.0889
67         0.1570     0.3034     0.2069
68         0.4364     0.6667     0.5275
69         0.3048     0.6129     0.4071
70         0.2637     0.2162     0.2376
71         0.4380     0.5761     0.4977
72         0.1429     0.0833     0.1053
73         0.5312     0.2931     0.3778
74         0.2778     0.0467     0.0800
75         0.6389     0.4144     0.5027
76         0.2000     0.5106     0.2874
77         0.0645     0.1200     0.0839
78         0.0909     0.0104     0.0187
79         0.1720     0.1633     0.1675
80         0.1667     0.0714     0.1000
81         0.2414     0.2143     0.2270
82         0.5238     0.4731     0.4972
83         0.2360     0.1944     0.2132
84         0.1163     0.0926     0.1031
85         0.3520     0.4151     0.3810
86         0.4507     0.2883     0.3516
87         0.2353     0.1860     0.2078
88         0.2632     0.0952     0.1399
89         0.3636     0.1509     0.2133
90         0.2368     0.0804     0.1200
91         0.3220     0.4130     0.3619
92         0.1484     0.1810     0.1631
93         0.1875     0.0594     0.0902
94         0.5439     0.5439     0.5439
95         0.2392     0.5155     0.3268
96         0.3590     0.3500     0.3544
97         0.1931     0.2617     0.2222
98         0.1750     0.1609     0.1677
99         0.0870     0.0190     0.0313
----------------------------------------
Macro Avg  0.2643     0.2633     0.2446


Epoch 24/100 | Time: 248.0s | Loss: 0.0431 | Train Acc: 98.61%
--- Evaluating on Epoch 24 Val ---

Overall Accuracy: 96.51% (11581/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9756     0.9808     0.9782
1          0.9839     0.9883     0.9861
2          0.9637     0.9611     0.9624
3          0.9771     0.9443     0.9604
4          0.9613     0.9679     0.9646
5          0.9362     0.9775     0.9564
6          0.9779     0.9787     0.9783
7          0.9576     0.9750     0.9662
8          0.9597     0.9351     0.9472
9          0.9536     0.9391     0.9463
----------------------------------------
Macro Avg  0.9647     0.9648     0.9646


Epoch 29/100 | Time: 209.7s | Loss: 2.7162 | Train Acc: 32.05%
--- Evaluating on Epoch 29 Val ---

Overall Accuracy: 26.28% (2628/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.5172     0.5056     0.5114
1          0.3605     0.3333     0.3464
2          0.1240     0.1720     0.1441
3          0.0890     0.2360     0.1292
4          0.1250     0.1010     0.1117
5          0.3231     0.1981     0.2456
6          0.1842     0.1386     0.1582
7          0.2209     0.1979     0.2088
8          0.2279     0.3333     0.2707
9          0.4390     0.4000     0.4186
10         0.2264     0.1188     0.1558
11         0.3478     0.1333     0.1928
12         0.2087     0.2330     0.2202
13         0.2388     0.1569     0.1893
14         0.1644     0.2353     0.1935
15         0.2048     0.1504     0.1735
16         0.1622     0.1379     0.1491
17         0.3803     0.4779     0.4235
18         0.1780     0.2000     0.1883
19         0.7500     0.0297     0.0571
20         0.4126     0.5728     0.4797
21         0.3034     0.4536     0.3636
22         0.3061     0.1579     0.2083
23         0.4404     0.4660     0.4528
24         0.3623     0.5618     0.4405
25         0.2203     0.1605     0.1857
26         0.2195     0.0857     0.1233
27         0.1240     0.1685     0.1429
28         0.4568     0.3854     0.4181
29         0.1330     0.3000     0.1843
30         0.1901     0.4950     0.2747
31         0.2184     0.1979     0.2077
32         0.2750     0.2222     0.2458
33         0.1778     0.2025     0.1893
34         0.1961     0.0952     0.1282
35         0.1486     0.2178     0.1767
36         0.3625     0.2843     0.3187
37         0.2205     0.2523     0.2353
38         0.2632     0.1579     0.1974
39         0.1500     0.3145     0.2031
40         0.1688     0.1512     0.1595
41         0.5147     0.3365     0.4070
42         0.1197     0.1604     0.1371
43         0.2035     0.2447     0.2222
44         0.2000     0.0404     0.0672
45         0.1633     0.0930     0.1185
46         0.2000     0.1124     0.1439
47         0.5942     0.3761     0.4607
48         0.1715     0.5900     0.2658
49         0.3605     0.3010     0.3280
50         0.3333     0.0294     0.0541
51         0.1852     0.2105     0.1970
52         0.5128     0.6250     0.5634
53         0.4409     0.4271     0.4339
54         0.3804     0.3070     0.3398
55         0.1000     0.0108     0.0194
56         0.2517     0.4000     0.3090
57         0.4808     0.2451     0.3247
58         0.3197     0.3645     0.3406
59         0.3509     0.1770     0.2353
60         0.8833     0.4862     0.6272
61         0.3913     0.4045     0.3978
62         0.3597     0.4854     0.4132
63         0.2632     0.3365     0.2954
64         0.0698     0.1667     0.0984
65         0.1944     0.0707     0.1037
66         0.1132     0.1319     0.1218
67         0.1954     0.1910     0.1932
68         0.7013     0.5000     0.5838
69         0.5696     0.4839     0.5233
70         0.3286     0.2072     0.2541
71         0.5926     0.5217     0.5549
72         0.1667     0.0648     0.0933
73         0.3566     0.3966     0.3755
74         0.1667     0.0561     0.0839
75         0.2893     0.6306     0.3966
76         0.3810     0.3404     0.3596
77         0.0758     0.0500     0.0602
78         0.1224     0.0625     0.0828
79         0.1889     0.1735     0.1809
80         0.1579     0.0268     0.0458
81         0.1765     0.1531     0.1639
82         0.6197     0.4731     0.5366
83         0.2114     0.2407     0.2251
84         0.2000     0.1019     0.1350
85         0.3359     0.4057     0.3675
86         0.2621     0.4865     0.3407
87         0.2121     0.1628     0.1842
88         0.1628     0.2667     0.2022
89         0.3519     0.1792     0.2375
90         0.1800     0.0804     0.1111
91         0.5500     0.3587     0.4342
92         0.1098     0.1810     0.1367
93         0.1967     0.1188     0.1481
94         0.5299     0.5439     0.5368
95         0.2752     0.4227     0.3333
96         0.4194     0.3250     0.3662
97         0.1602     0.2710     0.2014
98         0.1818     0.1379     0.1569
99         0.1220     0.0952     0.1070
----------------------------------------
Macro Avg  0.2853     0.2623     0.2556


Epoch 25/100 | Time: 255.4s | Loss: 0.0399 | Train Acc: 98.70%
--- Evaluating on Epoch 25 Val ---

Overall Accuracy: 96.44% (11573/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9757     0.9834     0.9795
1          0.9853     0.9831     0.9842
2          0.9612     0.9629     0.9620
3          0.9435     0.9713     0.9572
4          0.9507     0.9788     0.9646
5          0.9462     0.9737     0.9598
6          0.9874     0.9608     0.9739
7          0.9813     0.9545     0.9677
8          0.9606     0.9377     0.9490
9          0.9478     0.9374     0.9426
----------------------------------------
Macro Avg  0.9640     0.9644     0.9640


Epoch 30/100 | Time: 208.5s | Loss: 2.6909 | Train Acc: 32.27%
--- Evaluating on Epoch 30 Val ---

Overall Accuracy: 27.20% (2720/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.5244     0.4831     0.5029
1          0.2292     0.3548     0.2785
2          0.1187     0.2043     0.1502
3          0.1096     0.0899     0.0988
4          0.1408     0.1010     0.1176
5          0.1620     0.3302     0.2174
6          0.1792     0.1881     0.1836
7          0.2778     0.2604     0.2688
8          0.2353     0.3441     0.2795
9          0.6140     0.3889     0.4762
10         0.3478     0.0792     0.1290
11         0.4667     0.1167     0.1867
12         0.2936     0.3107     0.3019
13         0.2397     0.2843     0.2601
14         0.2500     0.1176     0.1600
15         0.2545     0.1239     0.1667
16         0.2545     0.1609     0.1972
17         0.3413     0.6283     0.4424
18         0.1552     0.0857     0.1104
19         0.2203     0.1287     0.1625
20         0.3588     0.5922     0.4469
21         0.2849     0.5258     0.3696
22         0.3191     0.1579     0.2113
23         0.4557     0.3495     0.3956
24         0.3500     0.3146     0.3314
25         0.1709     0.2469     0.2020
26         0.1522     0.1333     0.1421
27         0.0975     0.2584     0.1415
28         0.4524     0.3958     0.4222
29         0.2267     0.1889     0.2061
30         0.2720     0.3366     0.3009
31         0.2170     0.2396     0.2277
32         0.3600     0.1818     0.2416
33         0.2432     0.1139     0.1552
34         0.1037     0.1619     0.1264
35         0.1791     0.1188     0.1429
36         0.2083     0.4412     0.2830
37         0.2619     0.1982     0.2256
38         0.2353     0.0842     0.1240
39         0.1811     0.3710     0.2434
40         0.2632     0.1163     0.1613
41         0.3733     0.5385     0.4409
42         0.1543     0.2358     0.1866
43         0.1659     0.3723     0.2295
44         0.2273     0.0505     0.0826
45         0.2188     0.0814     0.1186
46         0.1515     0.1124     0.1290
47         0.4545     0.4128     0.4327
48         0.3139     0.4300     0.3629
49         0.4079     0.3010     0.3464
50         0.2800     0.0686     0.1102
51         0.1481     0.2105     0.1739
52         0.4924     0.6771     0.5702
53         0.3105     0.6146     0.4126
54         0.4444     0.3158     0.3692
55         0.3333     0.0108     0.0208
56         0.3523     0.3444     0.3483
57         0.3133     0.2549     0.2811
58         0.2957     0.3178     0.3063
59         0.3636     0.2832     0.3184
60         0.6159     0.7798     0.6883
61         0.3511     0.3708     0.3607
62         0.2963     0.5437     0.3836
63         0.2228     0.3942     0.2847
64         0.0923     0.0556     0.0694
65         0.1286     0.0909     0.1065
66         0.1111     0.0220     0.0367
67         0.2255     0.2584     0.2408
68         0.5701     0.5648     0.5674
69         0.4545     0.5376     0.4926
70         0.3273     0.1622     0.2169
71         0.4015     0.5761     0.4732
72         0.1316     0.0926     0.1087
73         0.4302     0.3190     0.3663
74         0.1132     0.1121     0.1127
75         0.4024     0.6126     0.4857
76         0.3398     0.3723     0.3553
77         0.0993     0.1500     0.1195
78         0.0758     0.0521     0.0617
79         0.1654     0.2245     0.1905
80         0.2778     0.0446     0.0769
81         0.2184     0.1939     0.2054
82         0.5684     0.5806     0.5745
83         0.3462     0.1667     0.2250
84         0.1596     0.1389     0.1485
85         0.3636     0.4151     0.3877
86         0.4516     0.2523     0.3237
87         0.2165     0.2442     0.2295
88         0.1520     0.1810     0.1652
89         0.1728     0.3113     0.2222
90         0.2258     0.1250     0.1609
91         0.3193     0.4130     0.3602
92         0.1500     0.0571     0.0828
93         0.2632     0.0990     0.1439
94         0.4855     0.5877     0.5317
95         0.4127     0.2680     0.3250
96         0.3768     0.3250     0.3490
97         0.2074     0.2617     0.2314
98         0.1912     0.1494     0.1677
99         0.1190     0.0476     0.0680
----------------------------------------
Macro Avg  0.2784     0.2709     0.2573

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 26/100 | Time: 251.6s | Loss: 0.0370 | Train Acc: 98.82%
--- Evaluating on Epoch 26 Val ---

Overall Accuracy: 96.60% (11592/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9807     0.9799     0.9803
1          0.9853     0.9861     0.9857
2          0.9712     0.9549     0.9630
3          0.9485     0.9664     0.9574
4          0.9750     0.9569     0.9658
5          0.9593     0.9728     0.9660
6          0.9780     0.9796     0.9788
7          0.9709     0.9606     0.9657
8          0.9617     0.9436     0.9526
9          0.9278     0.9569     0.9421
----------------------------------------
Macro Avg  0.9658     0.9658     0.9657


Epoch 31/100 | Time: 204.0s | Loss: 2.6739 | Train Acc: 32.99%
--- Evaluating on Epoch 31 Val ---

Overall Accuracy: 26.92% (2692/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4747     0.5281     0.5000
1          0.2067     0.4624     0.2857
2          0.1170     0.1183     0.1176
3          0.0901     0.1124     0.1000
4          0.1389     0.1515     0.1449
5          0.1582     0.2925     0.2053
6          0.2414     0.1386     0.1761
7          0.3099     0.2292     0.2635
8          0.2785     0.2366     0.2558
9          0.5000     0.3667     0.4231
10         0.1585     0.1287     0.1421
11         0.3333     0.1083     0.1635
12         0.1774     0.3204     0.2284
13         0.1982     0.2157     0.2066
14         0.2297     0.1667     0.1932
15         0.2063     0.1150     0.1477
16         0.1806     0.1494     0.1635
17         0.3841     0.5575     0.4549
18         0.1789     0.2095     0.1930
19         0.2632     0.1485     0.1899
20         0.3716     0.5340     0.4382
21         0.2642     0.5258     0.3517
22         0.2537     0.1789     0.2099
23         0.3840     0.4660     0.4211
24         0.3694     0.4607     0.4100
25         0.2500     0.1111     0.1538
26         0.1406     0.0857     0.1065
27         0.1127     0.0899     0.1000
28         0.5714     0.2917     0.3862
29         0.1419     0.2333     0.1765
30         0.1745     0.4059     0.2440
31         0.3051     0.1875     0.2323
32         0.2727     0.1818     0.2182
33         0.1507     0.1392     0.1447
34         0.1739     0.1143     0.1379
35         0.2535     0.1782     0.2093
36         0.3429     0.3529     0.3478
37         0.2063     0.2342     0.2194
38         0.2131     0.1368     0.1667
39         0.1886     0.3468     0.2443
40         0.2059     0.3256     0.2523
41         0.5243     0.5192     0.5217
42         0.2308     0.1415     0.1754
43         0.1977     0.3617     0.2556
44         0.2069     0.1212     0.1529
45         0.1250     0.1163     0.1205
46         0.1667     0.1011     0.1259
47         0.4571     0.4404     0.4486
48         0.2121     0.5600     0.3077
49         0.5000     0.1650     0.2482
50         0.2045     0.0882     0.1233
51         0.1857     0.1368     0.1576
52         0.4823     0.7083     0.5738
53         0.3174     0.5521     0.4030
54         0.2857     0.4561     0.3514
55         0.0833     0.0108     0.0190
56         0.3333     0.3667     0.3492
57         0.3810     0.2353     0.2909
58         0.2543     0.4112     0.3143
59         0.4000     0.1593     0.2278
60         0.7264     0.7064     0.7163
61         0.4412     0.3371     0.3822
62         0.4267     0.3107     0.3596
63         0.3061     0.2885     0.2970
64         0.1818     0.0926     0.1227
65         0.1129     0.0707     0.0870
66         0.1250     0.0220     0.0374
67         0.2113     0.1685     0.1875
68         0.5116     0.6111     0.5570
69         0.5102     0.5376     0.5236
70         0.3000     0.0541     0.0916
71         0.3913     0.6848     0.4980
72         0.1509     0.1481     0.1495
73         0.3628     0.3534     0.3581
74         0.1190     0.0467     0.0671
75         0.3953     0.6126     0.4806
76         0.4737     0.2872     0.3576
77         0.1190     0.0500     0.0704
78         0.1970     0.1354     0.1605
79         0.2381     0.1531     0.1863
80         0.1200     0.0268     0.0438
81         0.2400     0.1224     0.1622
82         0.6522     0.4839     0.5556
83         0.1703     0.2870     0.2138
84         0.1565     0.1667     0.1614
85         0.3165     0.4151     0.3592
86         0.3929     0.3964     0.3946
87         0.2400     0.2093     0.2236
88         0.2000     0.0952     0.1290
89         0.2362     0.2830     0.2575
90         0.2500     0.1429     0.1818
91         0.1569     0.5543     0.2446
92         0.1077     0.0667     0.0824
93         0.1644     0.1188     0.1379
94         0.7083     0.4474     0.5484
95         0.2213     0.5773     0.3200
96         0.2788     0.3625     0.3152
97         0.1743     0.1776     0.1759
98         0.1748     0.2069     0.1895
99         0.2000     0.0667     0.1000
----------------------------------------
Macro Avg  0.2718     0.2687     0.2538


Epoch 32/100 | Time: 203.7s | Loss: 2.6548 | Train Acc: 33.19%
--- Evaluating on Epoch 32 Val ---

Epoch 27/100 | Time: 254.7s | Loss: 0.0353 | Train Acc: 98.90%
--- Evaluating on Epoch 27 Val ---

Overall Accuracy: 26.87% (2687/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3475     0.5506     0.4261
1          0.3797     0.3226     0.3488
2          0.1122     0.1183     0.1152
3          0.0794     0.0562     0.0658
4          0.1935     0.1212     0.1491
5          0.2063     0.2453     0.2241
6          0.1557     0.1881     0.1704
7          0.2602     0.3333     0.2922
8          0.2385     0.3333     0.2780
9          0.3953     0.3778     0.3864
10         0.1842     0.0693     0.1007
11         0.4783     0.0917     0.1538
12         0.3038     0.2330     0.2637
13         0.2453     0.1275     0.1677
14         0.2222     0.2549     0.2374
15         0.1786     0.0442     0.0709
16         0.2692     0.1609     0.2014
17         0.3353     0.5044     0.4028
18         0.1378     0.2571     0.1794
19         0.1593     0.1782     0.1682
20         0.4435     0.5340     0.4846
21         0.2417     0.5979     0.3442
22         0.2059     0.2947     0.2424
23         0.3953     0.4951     0.4397
24         0.4308     0.3146     0.3636
25         0.1754     0.2469     0.2051
26         0.1231     0.0762     0.0941
27         0.1538     0.1798     0.1658
28         0.4556     0.4271     0.4409
29         0.2540     0.1778     0.2092
30         0.3818     0.2079     0.2692
31         0.1862     0.2812     0.2241
32         0.2192     0.1616     0.1860
33         0.0918     0.1139     0.1017
34         0.2273     0.0952     0.1342
35         0.1895     0.1782     0.1837
36         0.4493     0.3039     0.3626
37         0.2881     0.1532     0.2000
38         0.1690     0.1263     0.1446
39         0.4250     0.1371     0.2073
40         0.2963     0.0930     0.1416
41         0.4649     0.5096     0.4862
42         0.2254     0.1509     0.1808
43         0.1871     0.3085     0.2329
44         0.1818     0.1212     0.1455
45         0.2857     0.0698     0.1121
46         0.2273     0.1124     0.1504
47         0.4694     0.4220     0.4444
48         0.3763     0.3500     0.3627
49         0.5370     0.2816     0.3694
50         0.2222     0.0784     0.1159
51         0.1381     0.2632     0.1812
52         0.5288     0.5729     0.5500
53         0.3117     0.5000     0.3840
54         0.2857     0.2807     0.2832
55         0.0000     0.0000     0.0000
56         0.3299     0.3556     0.3422
57         0.2284     0.3627     0.2803
58         0.3077     0.3738     0.3376
59         0.3846     0.2212     0.2809
60         0.5845     0.7615     0.6614
61         0.2973     0.4944     0.3713
62         0.3071     0.3786     0.3391
63         0.3696     0.3269     0.3469
64         0.0667     0.0463     0.0546
65         0.1250     0.1111     0.1176
66         0.0580     0.0440     0.0500
67         0.2589     0.3258     0.2886
68         0.5299     0.5741     0.5511
69         0.4946     0.4946     0.4946
70         0.2287     0.3874     0.2876
71         0.4688     0.4891     0.4787
72         0.0714     0.0278     0.0400
73         0.3490     0.4483     0.3925
74         0.1439     0.1776     0.1590
75         0.3846     0.6306     0.4778
76         0.3237     0.4787     0.3863
77         0.0867     0.2600     0.1300
78         0.2353     0.0417     0.0708
79         0.1875     0.2449     0.2124
80         0.1429     0.0179     0.0317
81         0.2154     0.1429     0.1718
82         0.4231     0.5914     0.4933
83         0.2778     0.1852     0.2222
84         0.1250     0.0741     0.0930
85         0.2953     0.4151     0.3451
86         0.5185     0.2523     0.3394
87         0.2326     0.2326     0.2326
88         0.1854     0.2667     0.2188
89         0.2222     0.2453     0.2332
90         0.2031     0.1161     0.1477
91         0.3564     0.3913     0.3731
92         0.1449     0.0952     0.1149
93         0.2500     0.0990     0.1418
94         0.2471     0.7368     0.3700
95         0.6000     0.2165     0.3182
96         0.2205     0.5375     0.3127
97         0.2532     0.1869     0.2151
98         0.2045     0.1034     0.1374
99         0.0960     0.1143     0.1043
----------------------------------------
Macro Avg  0.2716     0.2686     0.2531


Overall Accuracy: 96.52% (11582/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9816     0.9808     0.9812
1          0.9847     0.9897     0.9872
2          0.9499     0.9717     0.9607
3          0.9739     0.9475     0.9605
4          0.9385     0.9814     0.9595
5          0.9514     0.9728     0.9620
6          0.9812     0.9804     0.9808
7          0.9653     0.9689     0.9671
8          0.9673     0.9334     0.9500
9          0.9545     0.9222     0.9380
----------------------------------------
Macro Avg  0.9648     0.9649     0.9647


Epoch 33/100 | Time: 257.0s | Loss: 2.6361 | Train Acc: 33.62%
--- Evaluating on Epoch 33 Val ---

Overall Accuracy: 27.08% (2708/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4595     0.5730     0.5100
1          0.3069     0.3333     0.3196
2          0.1412     0.1290     0.1348
3          0.1207     0.0787     0.0952
4          0.1681     0.1919     0.1792
5          0.2258     0.1981     0.2111
6          0.1596     0.1485     0.1538
7          0.2571     0.2812     0.2687
8          0.1959     0.3118     0.2407
9          0.5769     0.3333     0.4225
10         0.1884     0.1287     0.1529
11         0.4000     0.2000     0.2667
12         0.2422     0.3010     0.2684
13         0.2193     0.2451     0.2315
14         0.1867     0.2745     0.2222
15         0.2063     0.1150     0.1477
16         0.1324     0.2069     0.1614
17         0.3131     0.5929     0.4098
18         0.1618     0.2095     0.1826
19         0.2239     0.1485     0.1786
20         0.5972     0.4175     0.4914
21         0.2194     0.5361     0.3114
22         0.2150     0.2421     0.2277
23         0.4681     0.4272     0.4467
24         0.4568     0.4157     0.4353
25         0.1852     0.1852     0.1852
26         0.1340     0.1238     0.1287
27         0.1176     0.1124     0.1149
28         0.5714     0.4167     0.4819
29         0.3091     0.1889     0.2345
30         0.2645     0.3168     0.2883
31         0.1950     0.3229     0.2431
32         0.1982     0.2222     0.2095
33         0.1163     0.2532     0.1594
34         0.1970     0.1238     0.1520
35         0.2131     0.1287     0.1605
36         0.5588     0.1863     0.2794
37         0.2895     0.0991     0.1477
38         0.2903     0.0947     0.1429
39         0.1624     0.3065     0.2123
40         0.2683     0.1279     0.1732
41         0.3237     0.5385     0.4043
42         0.1261     0.1415     0.1333
43         0.2564     0.2128     0.2326
44         0.1757     0.1313     0.1503
45         0.1463     0.0698     0.0945
46         0.1923     0.0562     0.0870
47         0.4737     0.4128     0.4412
48         0.1961     0.6000     0.2956
49         0.3974     0.3010     0.3425
50         0.2800     0.0686     0.1102
51         0.2258     0.2211     0.2234
52         0.4872     0.5938     0.5352
53         0.4023     0.3646     0.3825
54         0.2736     0.4825     0.3492
55         0.0909     0.0108     0.0192
56         0.3368     0.3556     0.3459
57         0.3587     0.3235     0.3402
58         0.3370     0.2897     0.3116
59         0.2534     0.3274     0.2857
60         0.7973     0.5413     0.6448
61         0.2556     0.5169     0.3420
62         0.3725     0.3689     0.3707
63         0.4000     0.2885     0.3352
64         0.2000     0.0833     0.1176
65         0.1346     0.0707     0.0927
66         0.0833     0.0769     0.0800
67         0.1886     0.3708     0.2500
68         0.6000     0.6667     0.6316
69         0.5065     0.4194     0.4588
70         0.3390     0.1802     0.2353
71         0.6452     0.4348     0.5195
72         0.1429     0.0926     0.1124
73         0.3846     0.3448     0.3636
74         0.2069     0.0561     0.0882
75         0.4304     0.6126     0.5056
76         0.3548     0.3511     0.3529
77         0.1444     0.1300     0.1368
78         0.1048     0.2500     0.1477
79         0.2468     0.1939     0.2171
80         0.3333     0.0446     0.0787
81         0.1736     0.2143     0.1918
82         0.4741     0.5914     0.5263
83         0.2252     0.2315     0.2283
84         0.1884     0.1204     0.1469
85         0.3613     0.4057     0.3822
86         0.4607     0.3694     0.4100
87         0.2059     0.2442     0.2234
88         0.1776     0.2571     0.2101
89         0.2527     0.2170     0.2335
90         0.2143     0.1071     0.1429
91         0.3838     0.4130     0.3979
92         0.1364     0.1143     0.1244
93         0.2432     0.0891     0.1304
94         0.5339     0.5526     0.5431
95         0.3365     0.3608     0.3483
96         0.4091     0.2250     0.2903
97         0.1435     0.3084     0.1958
98         0.1739     0.2299     0.1980
99         0.1316     0.0952     0.1105
----------------------------------------
Macro Avg  0.2834     0.2699     0.2618


Epoch 28/100 | Time: 294.2s | Loss: 0.0323 | Train Acc: 98.96%
--- Evaluating on Epoch 28 Val ---

Overall Accuracy: 96.68% (11602/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9633     0.9886     0.9758
1          0.9840     0.9905     0.9872
2          0.9705     0.9611     0.9658
3          0.9661     0.9590     0.9626
4          0.9545     0.9772     0.9657
5          0.9618     0.9690     0.9654
6          0.9796     0.9796     0.9796
7          0.9799     0.9591     0.9693
8          0.9567     0.9445     0.9506
9          0.9470     0.9374     0.9422
----------------------------------------
Macro Avg  0.9664     0.9666     0.9664

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 34/100 | Time: 191.7s | Loss: 2.6206 | Train Acc: 33.75%
--- Evaluating on Epoch 34 Val ---

Overall Accuracy: 27.35% (2735/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6061     0.4494     0.5161
1          0.3846     0.3226     0.3509
2          0.1152     0.2043     0.1473
3          0.1023     0.1011     0.1017
4          0.1646     0.1313     0.1461
5          0.2194     0.3208     0.2605
6          0.2211     0.2079     0.2143
7          0.3099     0.2292     0.2635
8          0.2314     0.3011     0.2617
9          0.4304     0.3778     0.4024
10         0.1765     0.0594     0.0889
11         0.3415     0.1167     0.1739
12         0.2446     0.3301     0.2810
13         0.2193     0.2451     0.2315
14         0.2787     0.1667     0.2086
15         0.2083     0.1770     0.1914
16         0.2182     0.1379     0.1690
17         0.3571     0.5752     0.4407
18         0.2308     0.1429     0.1765
19         0.1880     0.2178     0.2018
20         0.4041     0.5728     0.4739
21         0.2747     0.5155     0.3584
22         0.3488     0.1579     0.2174
23         0.3770     0.4466     0.4089
24         0.3117     0.5393     0.3951
25         0.1789     0.2099     0.1932
26         0.1964     0.1048     0.1366
27         0.1154     0.1011     0.1078
28         0.4059     0.4271     0.4162
29         0.3654     0.2111     0.2676
30         0.2344     0.2970     0.2620
31         0.1888     0.2812     0.2259
32         0.4474     0.1717     0.2482
33         0.1724     0.1899     0.1807
34         0.1527     0.1905     0.1695
35         0.1220     0.3465     0.1804
36         0.3137     0.3137     0.3137
37         0.1935     0.1622     0.1765
38         0.1771     0.1789     0.1780
39         0.1587     0.2419     0.1917
40         0.2321     0.1512     0.1831
41         0.5541     0.3942     0.4607
42         0.1600     0.1132     0.1326
43         0.2230     0.3511     0.2727
44         0.1702     0.0808     0.1096
45         0.1304     0.0349     0.0550
46         0.1250     0.1461     0.1347
47         0.4766     0.4679     0.4722
48         0.1902     0.5800     0.2864
49         0.3517     0.4951     0.4113
50         0.3043     0.0686     0.1120
51         0.1961     0.1053     0.1370
52         0.4963     0.6979     0.5801
53         0.3333     0.5521     0.4157
54         0.3088     0.3684     0.3360
55         0.2857     0.0215     0.0400
56         0.3140     0.4222     0.3602
57         0.3158     0.3529     0.3333
58         0.3182     0.2617     0.2872
59         0.3750     0.2389     0.2919
60         0.7952     0.6055     0.6875
61         0.2878     0.4494     0.3509
62         0.4024     0.3204     0.3568
63         0.3500     0.3365     0.3431
64         0.1000     0.1019     0.1009
65         0.1220     0.1010     0.1105
66         0.1233     0.0989     0.1098
67         0.2000     0.1236     0.1528
68         0.5882     0.6481     0.6167
69         0.3425     0.5376     0.4184
70         0.3368     0.2883     0.3107
71         0.5149     0.5652     0.5389
72         0.1607     0.0833     0.1098
73         0.3750     0.3362     0.3545
74         0.1731     0.0841     0.1132
75         0.3743     0.6036     0.4621
76         0.3087     0.4894     0.3786
77         0.1143     0.0800     0.0941
78         0.1160     0.2188     0.1516
79         0.1638     0.1939     0.1776
80         0.3750     0.0268     0.0500
81         0.3421     0.1327     0.1912
82         0.5823     0.4946     0.5349
83         0.2651     0.2037     0.2304
84         0.1818     0.1111     0.1379
85         0.6364     0.1981     0.3022
86         0.3960     0.3604     0.3774
87         0.2056     0.2558     0.2280
88         0.2955     0.1238     0.1745
89         0.2750     0.2075     0.2366
90         0.1892     0.1250     0.1505
91         0.4070     0.3804     0.3933
92         0.1679     0.2095     0.1864
93         0.3333     0.0693     0.1148
94         0.6237     0.5088     0.5604
95         0.2647     0.4639     0.3371
96         0.3390     0.2500     0.2878
97         0.2029     0.2617     0.2286
98         0.1146     0.1264     0.1202
99         0.0802     0.1429     0.1027
----------------------------------------
Macro Avg  0.2847     0.2730     0.2622

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 29/100 | Time: 238.4s | Loss: 0.0304 | Train Acc: 98.99%
--- Evaluating on Epoch 29 Val ---

Overall Accuracy: 96.71% (11605/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9815     0.9755     0.9785
1          0.9825     0.9890     0.9857
2          0.9506     0.9708     0.9606
3          0.9813     0.9467     0.9637
4          0.9679     0.9687     0.9683
5          0.9583     0.9709     0.9646
6          0.9779     0.9755     0.9767
7          0.9620     0.9795     0.9707
8          0.9464     0.9505     0.9484
9          0.9594     0.9399     0.9496
----------------------------------------
Macro Avg  0.9668     0.9667     0.9667

   [!] Model checkpoint saved to ./checkpoints\best_model_data_1.pkl

Epoch 35/100 | Time: 210.7s | Loss: 2.6021 | Train Acc: 34.31%
--- Evaluating on Epoch 35 Val ---

Overall Accuracy: 27.22% (2722/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2835     0.6180     0.3887
1          0.2282     0.3656     0.2810
2          0.1509     0.0860     0.1096
3          0.1875     0.0674     0.0992
4          0.0857     0.1515     0.1095
5          0.2407     0.2453     0.2430
6          0.2698     0.1683     0.2073
7          0.2418     0.2292     0.2353
8          0.3836     0.3011     0.3373
9          0.2787     0.3778     0.3208
10         0.1818     0.1188     0.1437
11         0.2836     0.1583     0.2032
12         0.2124     0.2330     0.2222
13         0.3077     0.1961     0.2395
14         0.3026     0.2255     0.2584
15         0.2857     0.1062     0.1548
16         0.1579     0.1379     0.1472
17         0.4088     0.4956     0.4480
18         0.1818     0.0762     0.1074
19         0.2083     0.1485     0.1734
20         0.4365     0.5340     0.4803
21         0.2714     0.5567     0.3649
22         0.2881     0.1789     0.2208
23         0.3194     0.5922     0.4150
24         0.2674     0.5618     0.3623
25         0.1443     0.1728     0.1573
26         0.1429     0.0381     0.0602
27         0.1118     0.1910     0.1411
28         0.2414     0.4375     0.3111
29         0.2297     0.1889     0.2073
30         0.3111     0.2772     0.2932
31         0.4146     0.1771     0.2482
32         0.2202     0.2424     0.2308
33         0.1429     0.2025     0.1675
34         0.1333     0.0952     0.1111
35         0.1282     0.0990     0.1117
36         0.3333     0.3627     0.3474
37         0.2449     0.1081     0.1500
38         0.1651     0.1895     0.1765
39         0.2597     0.1613     0.1990
40         0.1840     0.2674     0.2180
41         0.4787     0.4327     0.4545
42         0.1561     0.3019     0.2058
43         0.1835     0.3085     0.2302
44         0.1882     0.1616     0.1739
45         0.1667     0.0930     0.1194
46         0.1667     0.1573     0.1618
47         0.5606     0.3394     0.4229
48         0.4400     0.2200     0.2933
49         0.5926     0.1553     0.2462
50         0.2333     0.0686     0.1061
51         0.1639     0.2105     0.1843
52         0.5041     0.6354     0.5622
53         0.3939     0.4062     0.4000
54         0.3485     0.4035     0.3740
55         0.0702     0.0430     0.0533
56         0.2640     0.5222     0.3507
57         0.3333     0.3333     0.3333
58         0.3393     0.3551     0.3470
59         0.3134     0.1858     0.2333
60         0.6697     0.6697     0.6697
61         0.2847     0.4607     0.3519
62         0.3676     0.4854     0.4184
63         0.2193     0.3942     0.2818
64         0.1111     0.0648     0.0819
65         0.1282     0.0505     0.0725
66         0.0952     0.0879     0.0914
67         0.1899     0.3371     0.2429
68         0.3988     0.6389     0.4911
69         0.3198     0.5914     0.4151
70         0.2987     0.2072     0.2447
71         0.3986     0.5978     0.4783
72         0.1587     0.0926     0.1170
73         0.3049     0.4310     0.3571
74         0.1798     0.1495     0.1633
75         0.5825     0.5405     0.5607
76         0.3504     0.5106     0.4156
77         0.1887     0.1000     0.1307
78         0.2258     0.0729     0.1102
79         0.1700     0.1735     0.1717
80         0.0926     0.0446     0.0602
81         0.2432     0.1837     0.2093
82         0.5100     0.5484     0.5285
83         0.2373     0.2593     0.2478
84         0.2045     0.0833     0.1184
85         0.3894     0.4151     0.4018
86         0.4697     0.2793     0.3503
87         0.2373     0.1628     0.1931
88         0.2319     0.1524     0.1839
89         0.2973     0.2075     0.2444
90         0.1887     0.1786     0.1835
91         0.2404     0.4783     0.3200
92         0.1429     0.0286     0.0476
93         0.2308     0.0891     0.1286
94         0.4132     0.6053     0.4911
95         0.3407     0.4742     0.3966
96         0.2885     0.3750     0.3261
97         0.1986     0.2617     0.2258
98         0.1689     0.2874     0.2128
99         0.1489     0.0667     0.0921
----------------------------------------
Macro Avg  0.2669     0.2731     0.2548


Epoch 30/100 | Time: 258.1s | Loss: 0.0292 | Train Acc: 99.09%
--- Evaluating on Epoch 30 Val ---

Overall Accuracy: 96.65% (11598/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9692     0.9895     0.9792
1          0.9818     0.9897     0.9858
2          0.9764     0.9531     0.9647
3          0.9715     0.9508     0.9611
4          0.9575     0.9712     0.9643
5          0.9715     0.9578     0.9646
6          0.9740     0.9812     0.9776
7          0.9784     0.9606     0.9694
8          0.9452     0.9573     0.9512
9          0.9374     0.9501     0.9437
----------------------------------------
Macro Avg  0.9663     0.9661     0.9661


Epoch 36/100 | Time: 215.0s | Loss: 2.5795 | Train Acc: 34.88%
--- Evaluating on Epoch 36 Val ---

Overall Accuracy: 27.75% (2775/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.5200     0.4382     0.4756
1          0.2941     0.3763     0.3302
2          0.1169     0.0968     0.1059
3          0.1474     0.1573     0.1522
4          0.2558     0.1111     0.1549
5          0.2283     0.2736     0.2489
6          0.1333     0.1584     0.1448
7          0.1929     0.2812     0.2288
8          0.3196     0.3333     0.3263
9          0.4000     0.3778     0.3886
10         0.1714     0.0594     0.0882
11         0.3077     0.1667     0.2162
12         0.3220     0.3689     0.3439
13         0.3500     0.2059     0.2593
14         0.3333     0.1961     0.2469
15         0.2239     0.1327     0.1667
16         0.1545     0.2184     0.1810
17         0.3563     0.5487     0.4321
18         0.1579     0.1429     0.1500
19         0.2364     0.1287     0.1667
20         0.5234     0.5437     0.5333
21         0.4432     0.4021     0.4216
22         0.1890     0.3263     0.2394
23         0.4519     0.4563     0.4541
24         0.3082     0.5056     0.3830
25         0.2500     0.1605     0.1955
26         0.1569     0.0762     0.1026
27         0.2162     0.0899     0.1270
28         0.4388     0.4479     0.4433
29         0.1172     0.3333     0.1734
30         0.2982     0.3366     0.3163
31         0.2055     0.3125     0.2479
32         0.3469     0.1717     0.2297
33         0.1218     0.2405     0.1617
34         0.1683     0.1619     0.1650
35         0.1984     0.2475     0.2203
36         0.3889     0.2745     0.3218
37         0.2778     0.1351     0.1818
38         0.1298     0.2842     0.1782
39         0.2315     0.2016     0.2155
40         0.1418     0.2209     0.1727
41         0.5694     0.3942     0.4659
42         0.1901     0.2547     0.2177
43         0.1892     0.3723     0.2509
44         0.1765     0.0606     0.0902
45         0.2593     0.0814     0.1239
46         0.2500     0.0449     0.0762
47         0.6000     0.3578     0.4483
48         0.3065     0.3800     0.3393
49         0.4103     0.3107     0.3536
50         0.2121     0.0686     0.1037
51         0.1387     0.2526     0.1791
52         0.4921     0.6458     0.5586
53         0.3134     0.6562     0.4242
54         0.3861     0.3421     0.3628
55         0.2727     0.0323     0.0577
56         0.2925     0.4778     0.3629
57         0.2482     0.3431     0.2881
58         0.3178     0.3832     0.3475
59         0.2752     0.2655     0.2703
60         0.7396     0.6514     0.6927
61         0.3579     0.3820     0.3696
62         0.3504     0.3981     0.3727
63         0.2741     0.3558     0.3096
64         0.1170     0.1019     0.1089
65         0.0750     0.0606     0.0670
66         0.0615     0.0440     0.0513
67         0.3051     0.2022     0.2432
68         0.5271     0.6296     0.5738
69         0.4298     0.5269     0.4734
70         0.3289     0.2252     0.2674
71         0.5155     0.5435     0.5291
72         0.1556     0.0648     0.0915
73         0.4658     0.2931     0.3598
74         0.1667     0.1589     0.1627
75         0.4430     0.5946     0.5077
76         0.2982     0.5426     0.3849
77         0.1186     0.0700     0.0881
78         0.2029     0.1458     0.1697
79         0.2160     0.2755     0.2422
80         0.3077     0.0357     0.0640
81         0.2955     0.1327     0.1831
82         0.5096     0.5699     0.5381
83         0.1780     0.1944     0.1858
84         0.1770     0.1852     0.1810
85         0.4267     0.3019     0.3536
86         0.4225     0.2703     0.3297
87         0.3200     0.1860     0.2353
88         0.1743     0.1810     0.1776
89         0.1761     0.2925     0.2199
90         0.2353     0.0714     0.1096
91         0.3654     0.4130     0.3878
92         0.1233     0.2667     0.1687
93         0.1744     0.1485     0.1604
94         0.4481     0.6053     0.5149
95         0.4531     0.2990     0.3602
96         0.2761     0.4625     0.3458
97         0.2018     0.2056     0.2037
98         0.1856     0.2069     0.1957
99         0.1698     0.0857     0.1139
----------------------------------------
Macro Avg  0.2849     0.2781     0.2671

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 31/100 | Time: 250.0s | Loss: 0.0267 | Train Acc: 99.11%
--- Evaluating on Epoch 31 Val ---

Overall Accuracy: 96.53% (11583/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9858     0.9711     0.9784
1          0.9754     0.9890     0.9821
2          0.9386     0.9735     0.9557
3          0.9726     0.9607     0.9666
4          0.9637     0.9662     0.9649
5          0.9797     0.9484     0.9638
6          0.9678     0.9836     0.9757
7          0.9555     0.9773     0.9663
8          0.9623     0.9385     0.9503
9          0.9527     0.9374     0.9450
----------------------------------------
Macro Avg  0.9654     0.9646     0.9649


Epoch 37/100 | Time: 219.2s | Loss: 2.5667 | Train Acc: 34.91%
--- Evaluating on Epoch 37 Val ---

Overall Accuracy: 27.93% (2793/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4946     0.5169     0.5055
1          0.2632     0.4301     0.3265
2          0.0820     0.0538     0.0649
3          0.1500     0.1348     0.1420
4          0.1463     0.1212     0.1326
5          0.2138     0.2925     0.2470
6          0.1818     0.1386     0.1573
7          0.3243     0.2500     0.2824
8          0.3370     0.3333     0.3351
9          0.4286     0.3667     0.3952
10         0.2195     0.0891     0.1268
11         0.2083     0.1667     0.1852
12         0.1712     0.2427     0.2008
13         0.2247     0.1961     0.2094
14         0.2018     0.2157     0.2085
15         0.2714     0.1681     0.2077
16         0.1979     0.2184     0.2077
17         0.4775     0.4690     0.4732
18         0.1887     0.0952     0.1266
19         0.2833     0.1683     0.2112
20         0.4355     0.5243     0.4758
21         0.2738     0.4742     0.3472
22         0.3182     0.1474     0.2014
23         0.3846     0.5340     0.4472
24         0.3378     0.5618     0.4219
25         0.1731     0.2222     0.1946
26         0.1134     0.1048     0.1089
27         0.1356     0.2697     0.1805
28         0.4878     0.4167     0.4494
29         0.2500     0.2444     0.2472
30         0.1725     0.4356     0.2472
31         0.2500     0.2083     0.2273
32         0.3913     0.1818     0.2483
33         0.1739     0.2532     0.2062
34         0.2281     0.1238     0.1605
35         0.1561     0.2673     0.1971
36         0.4394     0.2843     0.3452
37         0.2469     0.1802     0.2083
38         0.2414     0.1474     0.1830
39         0.2692     0.2258     0.2456
40         0.2097     0.1512     0.1757
41         0.5000     0.4808     0.4902
42         0.1974     0.1415     0.1648
43         0.2727     0.3191     0.2941
44         0.1386     0.1414     0.1400
45         0.1020     0.1744     0.1288
46         0.1127     0.1798     0.1385
47         0.5479     0.3670     0.4396
48         0.3115     0.3800     0.3423
49         0.3981     0.3981     0.3981
50         0.2593     0.1373     0.1795
51         0.2167     0.1368     0.1677
52         0.4841     0.6354     0.5495
53         0.3333     0.5625     0.4186
54         0.4124     0.3509     0.3791
55         0.0745     0.0753     0.0749
56         0.3846     0.3333     0.3571
57         0.5000     0.2255     0.3108
58         0.3433     0.4299     0.3817
59         0.3239     0.2035     0.2500
60         0.8429     0.5413     0.6592
61         0.3628     0.4607     0.4059
62         0.3409     0.4369     0.3830
63         0.2453     0.3750     0.2966
64         0.2121     0.0648     0.0993
65         0.1250     0.0707     0.0903
66         0.1010     0.1099     0.1053
67         0.2500     0.1798     0.2092
68         0.5246     0.5926     0.5565
69         0.4536     0.4731     0.4632
70         0.4286     0.1892     0.2625
71         0.4472     0.5978     0.5116
72         0.2000     0.0741     0.1081
73         0.2975     0.4052     0.3431
74         0.1789     0.1589     0.1683
75         0.2673     0.7297     0.3913
76         0.5079     0.3404     0.4076
77         0.1250     0.0900     0.1047
78         0.1552     0.1875     0.1698
79         0.2381     0.2041     0.2198
80         0.2632     0.0446     0.0763
81         0.2055     0.3061     0.2459
82         0.4865     0.5806     0.5294
83         0.2273     0.2778     0.2500
84         0.2410     0.1852     0.2094
85         0.3960     0.3774     0.3865
86         0.3712     0.4414     0.4033
87         0.2150     0.2674     0.2383
88         0.2135     0.1810     0.1959
89         0.3810     0.1509     0.2162
90         0.2121     0.0625     0.0966
91         0.2484     0.4348     0.3162
92         0.0784     0.0381     0.0513
93         0.2963     0.0792     0.1250
94         0.6154     0.5614     0.5872
95         0.2237     0.5052     0.3101
96         0.3125     0.3750     0.3409
97         0.1762     0.3178     0.2267
98         0.1682     0.2069     0.1856
99         0.0370     0.0095     0.0152
----------------------------------------
Macro Avg  0.2834     0.2798     0.2683

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 32/100 | Time: 295.3s | Loss: 0.0251 | Train Acc: 99.25%
--- Evaluating on Epoch 32 Val ---

Epoch 38/100 | Time: 259.9s | Loss: 2.5491 | Train Acc: 35.34%
--- Evaluating on Epoch 38 Val ---

Overall Accuracy: 96.42% (11570/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9592     0.9878     0.9733
1          0.9698     0.9905     0.9800
2          0.9729     0.9531     0.9629
3          0.9803     0.9369     0.9581
4          0.9475     0.9772     0.9621
5          0.9512     0.9681     0.9596
6          0.9725     0.9820     0.9772
7          0.9696     0.9682     0.9689
8          0.9615     0.9385     0.9499
9          0.9551     0.9357     0.9453
----------------------------------------
Macro Avg  0.9640     0.9638     0.9637


Overall Accuracy: 28.01% (2801/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4845     0.5281     0.5054
1          0.2727     0.3548     0.3084
2          0.1504     0.1828     0.1650
3          0.1100     0.1236     0.1164
4          0.0943     0.1010     0.0976
5          0.2727     0.1981     0.2295
6          0.1743     0.1881     0.1810
7          0.2453     0.2708     0.2574
8          0.4655     0.2903     0.3576
9          0.3704     0.4444     0.4040
10         0.2157     0.1089     0.1447
11         0.2708     0.2167     0.2407
12         0.2538     0.3204     0.2833
13         0.3548     0.2157     0.2683
14         0.1667     0.2255     0.1917
15         0.3333     0.0973     0.1507
16         0.1912     0.1494     0.1677
17         0.4486     0.4248     0.4364
18         0.1727     0.1810     0.1767
19         0.3684     0.0693     0.1167
20         0.5591     0.5049     0.5306
21         0.3333     0.5155     0.4049
22         0.3519     0.2000     0.2550
23         0.3901     0.5340     0.4508
24         0.3830     0.4045     0.3934
25         0.2105     0.1481     0.1739
26         0.1724     0.0952     0.1227
27         0.2571     0.1011     0.1452
28         0.4211     0.4167     0.4188
29         0.2198     0.2222     0.2210
30         0.2696     0.3069     0.2870
31         0.2099     0.3542     0.2636
32         0.3088     0.2121     0.2515
33         0.1500     0.2278     0.1809
34         0.1238     0.1238     0.1238
35         0.2088     0.1881     0.1979
36         0.2085     0.4804     0.2908
37         0.1930     0.0991     0.1310
38         0.2542     0.1579     0.1948
39         0.4186     0.1452     0.2156
40         0.1117     0.2558     0.1555
41         0.5000     0.5192     0.5094
42         0.1569     0.3019     0.2065
43         0.2199     0.3298     0.2638
44         0.1443     0.1414     0.1429
45         0.1226     0.1512     0.1354
46         0.1667     0.1011     0.1259
47         0.4667     0.4495     0.4579
48         0.3973     0.2900     0.3353
49         0.4095     0.4175     0.4135
50         0.1304     0.1176     0.1237
51         0.1490     0.3263     0.2046
52         0.5040     0.6562     0.5701
53         0.3597     0.5208     0.4255
54         0.3661     0.3596     0.3628
55         0.1818     0.0215     0.0385
56         0.2515     0.4778     0.3295
57         0.2920     0.3235     0.3070
58         0.4262     0.2430     0.3095
59         0.3053     0.2566     0.2788
60         0.8400     0.5780     0.6848
61         0.3362     0.4382     0.3805
62         0.3714     0.3786     0.3750
63         0.2533     0.3654     0.2992
64         0.1321     0.0648     0.0870
65         0.1212     0.0808     0.0970
66         0.1053     0.0440     0.0620
67         0.2081     0.3483     0.2605
68         0.5111     0.6389     0.5679
69         0.4432     0.4194     0.4309
70         0.3182     0.1892     0.2373
71         0.4524     0.6196     0.5229
72         0.1636     0.0833     0.1104
73         0.3628     0.3534     0.3581
74         0.2600     0.1215     0.1656
75         0.6022     0.5045     0.5490
76         0.3559     0.4468     0.3962
77         0.1290     0.1600     0.1429
78         0.1707     0.1458     0.1573
79         0.2346     0.1939     0.2123
80         0.1639     0.0893     0.1156
81         0.1881     0.1939     0.1910
82         0.5385     0.5269     0.5326
83         0.2857     0.2222     0.2500
84         0.1928     0.1481     0.1675
85         0.3729     0.4151     0.3929
86         0.4416     0.3063     0.3617
87         0.2892     0.2791     0.2840
88         0.1729     0.2190     0.1933
89         0.2121     0.3302     0.2583
90         0.2055     0.1339     0.1622
91         0.2986     0.4674     0.3644
92         0.1649     0.1524     0.1584
93         0.2500     0.0990     0.1418
94         0.4138     0.6316     0.5000
95         0.3592     0.3814     0.3700
96         0.2750     0.4125     0.3300
97         0.1562     0.2804     0.2007
98         0.1635     0.1954     0.1780
99         0.1200     0.0286     0.0462
----------------------------------------
Macro Avg  0.2836     0.2808     0.2704

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 39/100 | Time: 207.2s | Loss: 2.5327 | Train Acc: 35.76%
--- Evaluating on Epoch 39 Val ---

Overall Accuracy: 27.20% (2720/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4414     0.5506     0.4900
1          0.3375     0.2903     0.3121
2          0.1039     0.1720     0.1296
3          0.1240     0.1685     0.1429
4          0.1915     0.0909     0.1233
5          0.2973     0.2075     0.2444
6          0.2344     0.1485     0.1818
7          0.1913     0.3646     0.2509
8          0.3137     0.3441     0.3282
9          0.4177     0.3667     0.3905
10         0.2381     0.0495     0.0820
11         0.2794     0.1583     0.2021
12         0.3235     0.3204     0.3220
13         0.4091     0.0882     0.1452
14         0.2033     0.2451     0.2222
15         0.2268     0.1947     0.2095
16         0.3235     0.1264     0.1818
17         0.3269     0.6018     0.4237
18         0.2128     0.0952     0.1316
19         0.5000     0.0891     0.1513
20         0.5185     0.5437     0.5308
21         0.2600     0.5361     0.3502
22         0.4000     0.1684     0.2370
23         0.4875     0.3786     0.4262
24         0.5385     0.2360     0.3281
25         0.1259     0.2099     0.1574
26         0.1339     0.1619     0.1466
27         0.1273     0.3146     0.1812
28         0.4409     0.4271     0.4339
29         0.2333     0.2333     0.2333
30         0.3143     0.2178     0.2573
31         0.1429     0.3542     0.2036
32         0.3673     0.1818     0.2432
33         0.1619     0.2152     0.1848
34         0.1304     0.0857     0.1034
35         0.1634     0.2475     0.1969
36         0.2103     0.4412     0.2848
37         0.2895     0.0991     0.1477
38         0.1299     0.2105     0.1606
39         0.2593     0.2258     0.2414
40         0.1509     0.1860     0.1667
41         0.3660     0.5385     0.4358
42         0.1488     0.2358     0.1825
43         0.1806     0.4149     0.2516
44         0.1746     0.1111     0.1358
45         0.2308     0.0698     0.1071
46         0.2258     0.0787     0.1167
47         0.4691     0.3486     0.4000
48         0.3516     0.3200     0.3351
49         0.6154     0.2330     0.3380
50         0.0926     0.1961     0.1258
51         0.2353     0.1684     0.1963
52         0.5412     0.4792     0.5083
53         0.3478     0.5000     0.4103
54         0.3529     0.3684     0.3605
55         0.3333     0.0538     0.0926
56         0.4909     0.3000     0.3724
57         0.3438     0.3235     0.3333
58         0.4308     0.2617     0.3256
59         0.2671     0.3451     0.3012
60         0.6981     0.6789     0.6884
61         0.2714     0.4270     0.3319
62         0.4598     0.3883     0.4211
63         0.2147     0.3942     0.2780
64         0.1044     0.1759     0.1310
65         0.1273     0.0707     0.0909
66         0.0932     0.1648     0.1190
67         0.2377     0.3258     0.2749
68         0.6739     0.5741     0.6200
69         0.5067     0.4086     0.4524
70         0.3478     0.2162     0.2667
71         0.5679     0.5000     0.5318
72         0.1449     0.0926     0.1130
73         0.4568     0.3190     0.3756
74         0.1951     0.2243     0.2087
75         0.4094     0.6306     0.4965
76         0.3279     0.4255     0.3704
77         0.1467     0.1100     0.1257
78         0.1383     0.1354     0.1368
79         0.2258     0.2143     0.2199
80         0.1818     0.0893     0.1198
81         0.2833     0.1735     0.2152
82         0.6026     0.5054     0.5497
83         0.2100     0.1944     0.2019
84         0.3125     0.0926     0.1429
85         0.2604     0.4717     0.3356
86         0.4257     0.3874     0.4057
87         0.2979     0.1628     0.2105
88         0.2308     0.1429     0.1765
89         0.3934     0.2264     0.2874
90         0.1905     0.1071     0.1371
91         0.4222     0.4130     0.4176
92         0.2432     0.0857     0.1268
93         0.2034     0.1188     0.1500
94         0.5194     0.5877     0.5514
95         0.4412     0.3093     0.3636
96         0.2414     0.3500     0.2857
97         0.1852     0.2336     0.2066
98         0.1429     0.2644     0.1855
99         0.0700     0.0667     0.0683
----------------------------------------
Macro Avg  0.2969     0.2715     0.2660


Epoch 33/100 | Time: 247.0s | Loss: 0.0227 | Train Acc: 99.30%
--- Evaluating on Epoch 33 Val ---

Overall Accuracy: 96.62% (11595/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9798     0.9773     0.9785
1          0.9882     0.9846     0.9864
2          0.9664     0.9664     0.9664
3          0.9699     0.9508     0.9603
4          0.9687     0.9695     0.9691
5          0.9555     0.9672     0.9613
6          0.9671     0.9845     0.9757
7          0.9835     0.9515     0.9672
8          0.9437     0.9582     0.9508
9          0.9352     0.9518     0.9434
----------------------------------------
Macro Avg  0.9658     0.9662     0.9659


Epoch 40/100 | Time: 205.1s | Loss: 2.5189 | Train Acc: 35.97%
--- Evaluating on Epoch 40 Val ---

Overall Accuracy: 28.18% (2818/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6071     0.3820     0.4690
1          0.2531     0.4409     0.3216
2          0.1548     0.2796     0.1992
3          0.1271     0.1685     0.1449
4          0.1154     0.1515     0.1310
5          0.2615     0.1604     0.1988
6          0.1538     0.1782     0.1651
7          0.2403     0.3229     0.2756
8          0.2569     0.3978     0.3122
9          0.6000     0.3667     0.4552
10         0.2083     0.1485     0.1734
11         0.7500     0.1000     0.1765
12         0.3068     0.2621     0.2827
13         0.3026     0.2255     0.2584
14         0.2232     0.2451     0.2336
15         0.2400     0.1062     0.1472
16         0.2241     0.1494     0.1793
17         0.5326     0.4336     0.4780
18         0.1970     0.1238     0.1520
19         0.2436     0.1881     0.2123
20         0.5422     0.4369     0.4839
21         0.3676     0.5155     0.4292
22         0.3235     0.1158     0.1705
23         0.4775     0.5146     0.4953
24         0.3209     0.4831     0.3857
25         0.1622     0.2222     0.1875
26         0.1341     0.1048     0.1176
27         0.1441     0.1910     0.1643
28         0.4352     0.4896     0.4608
29         0.1547     0.3111     0.2066
30         0.2824     0.3663     0.3190
31         0.2333     0.2188     0.2258
32         0.3922     0.2020     0.2667
33         0.1667     0.2785     0.2085
34         0.1413     0.1238     0.1320
35         0.2234     0.2079     0.2154
36         0.2846     0.3431     0.3111
37         0.1905     0.2883     0.2294
38         0.2273     0.1579     0.1863
39         0.3300     0.2661     0.2946
40         0.3333     0.1047     0.1593
41         0.3797     0.5769     0.4580
42         0.1546     0.3019     0.2045
43         0.2266     0.3085     0.2613
44         0.1062     0.1212     0.1132
45         0.1375     0.1279     0.1325
46         0.1957     0.1011     0.1333
47         0.3968     0.4587     0.4255
48         0.3333     0.4100     0.3677
49         0.4559     0.3010     0.3626
50         0.1628     0.1373     0.1489
51         0.1456     0.1579     0.1515
52         0.4727     0.5417     0.5049
53         0.3607     0.4583     0.4037
54         0.4458     0.3246     0.3756
55         0.1579     0.0323     0.0536
56         0.3223     0.4333     0.3697
57         0.4576     0.2647     0.3354
58         0.3727     0.3832     0.3779
59         0.3649     0.2389     0.2888
60         0.5970     0.7339     0.6584
61         0.3861     0.4382     0.4105
62         0.2882     0.4757     0.3590
63         0.2537     0.3269     0.2857
64         0.2021     0.1759     0.1881
65         0.0874     0.0909     0.0891
66         0.1250     0.0330     0.0522
67         0.2308     0.3708     0.2845
68         0.5175     0.6852     0.5896
69         0.5075     0.3656     0.4250
70         0.3093     0.2703     0.2885
71         0.4848     0.5217     0.5026
72         0.1194     0.0741     0.0914
73         0.3738     0.3448     0.3587
74         0.1786     0.1869     0.1826
75         0.3931     0.6126     0.4789
76         0.4308     0.2979     0.3522
77         0.1735     0.1700     0.1717
78         0.1951     0.1667     0.1798
79         0.1415     0.3061     0.1935
80         0.2647     0.0804     0.1233
81         0.1888     0.2755     0.2241
82         0.4043     0.6129     0.4872
83         0.2333     0.2593     0.2456
84         0.2056     0.2037     0.2047
85         0.3922     0.3774     0.3846
86         0.5660     0.2703     0.3659
87         0.1797     0.2674     0.2150
88         0.1807     0.2857     0.2214
89         0.3167     0.1792     0.2289
90         0.1860     0.0714     0.1032
91         0.3482     0.4239     0.3824
92         0.1525     0.1714     0.1614
93         0.2941     0.0990     0.1481
94         0.5526     0.5526     0.5526
95         0.3953     0.3505     0.3716
96         0.2696     0.3875     0.3179
97         0.2174     0.0935     0.1307
98         0.1395     0.0690     0.0923
99         0.1000     0.0476     0.0645
----------------------------------------
Macro Avg  0.2910     0.2818     0.2725

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 34/100 | Time: 256.6s | Loss: 0.0218 | Train Acc: 99.31%
--- Evaluating on Epoch 34 Val ---

Overall Accuracy: 96.43% (11572/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9876     0.9755     0.9815
1          0.9803     0.9883     0.9843
2          0.9522     0.9691     0.9606
3          0.9421     0.9730     0.9573
4          0.9826     0.9535     0.9678
5          0.9286     0.9756     0.9515
6          0.9841     0.9616     0.9727
7          0.9718     0.9674     0.9696
8          0.9646     0.9317     0.9479
9          0.9466     0.9450     0.9458
----------------------------------------
Macro Avg  0.9641     0.9641     0.9639


Epoch 41/100 | Time: 255.7s | Loss: 2.5027 | Train Acc: 36.31%
--- Evaluating on Epoch 41 Val ---

Overall Accuracy: 27.75% (2775/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3611     0.5843     0.4464
1          0.3261     0.3226     0.3243
2          0.1458     0.2258     0.1772
3          0.1053     0.1124     0.1087
4          0.1064     0.1515     0.1250
5          0.2411     0.3208     0.2753
6          0.2075     0.2178     0.2126
7          0.3966     0.2396     0.2987
8          0.3452     0.3118     0.3277
9          0.3590     0.4667     0.4058
10         0.1321     0.0693     0.0909
11         0.2436     0.1583     0.1919
12         0.4127     0.2524     0.3133
13         0.2875     0.2255     0.2527
14         0.1930     0.2157     0.2037
15         0.1942     0.1770     0.1852
16         0.3030     0.1149     0.1667
17         0.3254     0.6018     0.4224
18         0.1609     0.1333     0.1458
19         0.1887     0.1980     0.1932
20         0.5143     0.5243     0.5192
21         0.2970     0.5052     0.3740
22         0.3833     0.2421     0.2968
23         0.5256     0.3981     0.4530
24         0.4231     0.3708     0.3952
25         0.1684     0.1975     0.1818
26         0.2093     0.0857     0.1216
27         0.2308     0.1685     0.1948
28         0.3932     0.4792     0.4319
29         0.2472     0.2444     0.2458
30         0.3168     0.3168     0.3168
31         0.1882     0.3646     0.2482
32         0.2286     0.2424     0.2353
33         0.1731     0.2278     0.1967
34         0.1802     0.1905     0.1852
35         0.1935     0.0594     0.0909
36         0.2017     0.4608     0.2806
37         0.3673     0.1622     0.2250
38         0.1696     0.2000     0.1836
39         0.2368     0.2903     0.2609
40         0.1720     0.1860     0.1788
41         0.4522     0.5000     0.4749
42         0.1832     0.2264     0.2025
43         0.1468     0.3936     0.2139
44         0.2222     0.0808     0.1185
45         0.1364     0.0698     0.0923
46         0.1905     0.0899     0.1221
47         0.5190     0.3761     0.4362
48         0.4022     0.3700     0.3854
49         0.5435     0.2427     0.3356
50         0.1538     0.1569     0.1553
51         0.1554     0.2421     0.1893
52         0.5197     0.6875     0.5919
53         0.4151     0.4583     0.4356
54         0.3820     0.2982     0.3350
55         0.1538     0.0215     0.0377
56         0.4267     0.3556     0.3879
57         0.3596     0.3137     0.3351
58         0.3780     0.2897     0.3280
59         0.4857     0.1504     0.2297
60         0.6832     0.6330     0.6571
61         0.3896     0.3371     0.3614
62         0.3475     0.3981     0.3710
63         0.2434     0.3558     0.2891
64         0.1429     0.1944     0.1647
65         0.1562     0.0505     0.0763
66         0.1392     0.1209     0.1294
67         0.2793     0.3483     0.3100
68         0.6786     0.5278     0.5937
69         0.4000     0.5591     0.4664
70         0.2586     0.2703     0.2643
71         0.5053     0.5217     0.5134
72         0.1304     0.0833     0.1017
73         0.6000     0.2845     0.3860
74         0.1692     0.1028     0.1279
75         0.5248     0.4775     0.5000
76         0.3760     0.5000     0.4292
77         0.0921     0.1400     0.1111
78         0.1765     0.0625     0.0923
79         0.2982     0.1735     0.2194
80         0.1475     0.0804     0.1040
81         0.2708     0.1327     0.1781
82         0.4779     0.5806     0.5243
83         0.2400     0.1667     0.1967
84         0.1849     0.2037     0.1938
85         0.3158     0.3962     0.3515
86         0.3889     0.3784     0.3836
87         0.2258     0.2442     0.2346
88         0.1202     0.2952     0.1708
89         0.2260     0.3113     0.2619
90         0.1500     0.0804     0.1047
91         0.3667     0.3587     0.3626
92         0.1104     0.1619     0.1313
93         0.1515     0.0990     0.1198
94         0.4286     0.6053     0.5018
95         0.5333     0.2474     0.3380
96         0.3735     0.3875     0.3804
97         0.2049     0.2336     0.2183
98         0.1223     0.2644     0.1673
99         0.1154     0.0571     0.0764
----------------------------------------
Macro Avg  0.2883     0.2777     0.2706


Epoch 35/100 | Time: 287.4s | Loss: 0.0198 | Train Acc: 99.43%
--- Evaluating on Epoch 35 Val ---

Overall Accuracy: 96.42% (11571/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9642     0.9886     0.9762
1          0.9775     0.9890     0.9832
2          0.9645     0.9620     0.9633
3          0.9724     0.9533     0.9627
4          0.9483     0.9780     0.9629
5          0.9777     0.9465     0.9619
6          0.9739     0.9763     0.9751
7          0.9775     0.9560     0.9667
8          0.9556     0.9377     0.9466
9          0.9297     0.9509     0.9402
----------------------------------------
Macro Avg  0.9641     0.9638     0.9639


Epoch 42/100 | Time: 200.4s | Loss: 2.4850 | Train Acc: 36.67%
--- Evaluating on Epoch 42 Val ---

Overall Accuracy: 27.26% (2726/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4884     0.4719     0.4800
1          0.2955     0.4194     0.3467
2          0.0965     0.1183     0.1063
3          0.1528     0.1236     0.1366
4          0.2414     0.1414     0.1783
5          0.2047     0.3302     0.2527
6          0.1667     0.1485     0.1571
7          0.2353     0.3333     0.2759
8          0.3444     0.3333     0.3388
9          0.5000     0.3111     0.3836
10         0.1308     0.1683     0.1472
11         0.2647     0.1500     0.1915
12         0.2174     0.3398     0.2652
13         0.3014     0.2157     0.2514
14         0.3000     0.1471     0.1974
15         0.2308     0.1858     0.2059
16         0.1852     0.1724     0.1786
17         0.4044     0.4867     0.4418
18         0.1607     0.0857     0.1118
19         0.2800     0.0693     0.1111
20         0.3422     0.6214     0.4414
21         0.4512     0.3814     0.4134
22         0.3636     0.2105     0.2667
23         0.4545     0.3883     0.4188
24         0.3077     0.4494     0.3653
25         0.2558     0.1358     0.1774
26         0.1875     0.0857     0.1176
27         0.1587     0.2247     0.1860
28         0.5686     0.3021     0.3946
29         0.1392     0.3000     0.1901
30         0.2206     0.1485     0.1775
31         0.2593     0.2188     0.2373
32         0.2300     0.2323     0.2312
33         0.1159     0.3418     0.1731
34         0.1685     0.1429     0.1546
35         0.1733     0.1287     0.1477
36         0.2655     0.4608     0.3369
37         0.2233     0.2072     0.2150
38         0.1667     0.0842     0.1119
39         0.3966     0.1855     0.2527
40         0.0984     0.2907     0.1471
41         0.6066     0.3558     0.4485
42         0.2281     0.1226     0.1595
43         0.1800     0.3830     0.2449
44         0.1373     0.2121     0.1667
45         0.1392     0.1279     0.1333
46         0.1842     0.0787     0.1102
47         0.4891     0.4128     0.4478
48         0.4103     0.3200     0.3596
49         0.6667     0.1942     0.3008
50         0.1429     0.0980     0.1163
51         0.1455     0.1684     0.1561
52         0.4960     0.6458     0.5611
53         0.2917     0.6562     0.4038
54         0.4819     0.3509     0.4061
55         0.0694     0.0538     0.0606
56         0.4125     0.3667     0.3882
57         0.2638     0.4216     0.3245
58         0.4667     0.2617     0.3353
59         0.3097     0.3097     0.3097
60         0.6124     0.7248     0.6639
61         0.3750     0.3708     0.3729
62         0.4521     0.3204     0.3750
63         0.2534     0.3558     0.2960
64         0.1395     0.0556     0.0795
65         0.1061     0.1414     0.1212
66         0.0714     0.0440     0.0544
67         0.2700     0.3034     0.2857
68         0.4031     0.7130     0.5151
69         0.4364     0.5161     0.4729
70         0.3190     0.3333     0.3260
71         0.3515     0.6304     0.4514
72         0.1667     0.0463     0.0725
73         0.4286     0.2845     0.3420
74         0.2632     0.0935     0.1379
75         0.6022     0.5045     0.5490
76         0.3723     0.3723     0.3723
77         0.1130     0.1300     0.1209
78         0.2286     0.0833     0.1221
79         0.1786     0.2041     0.1905
80         0.2000     0.0536     0.0845
81         0.2676     0.1939     0.2249
82         0.5258     0.5484     0.5368
83         0.2028     0.2685     0.2311
84         0.1538     0.2778     0.1980
85         0.4839     0.2830     0.3571
86         0.4194     0.3514     0.3824
87         0.2877     0.2442     0.2642
88         0.1654     0.2000     0.1810
89         0.3415     0.2642     0.2979
90         0.1569     0.0714     0.0982
91         0.2763     0.4565     0.3443
92         0.1667     0.1048     0.1287
93         0.1429     0.1584     0.1502
94         0.3956     0.6316     0.4865
95         0.4242     0.2887     0.3436
96         0.3333     0.3000     0.3158
97         0.1761     0.2336     0.2008
98         0.1609     0.1609     0.1609
99         0.1204     0.1238     0.1221
----------------------------------------
Macro Avg  0.2841     0.2727     0.2638


Epoch 36/100 | Time: 259.0s | Loss: 0.0184 | Train Acc: 99.49%
--- Evaluating on Epoch 36 Val ---

Overall Accuracy: 96.33% (11559/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9773     0.9799     0.9786
1          0.9903     0.9758     0.9830
2          0.9434     0.9726     0.9578
3          0.9484     0.9648     0.9565
4          0.9653     0.9645     0.9649
5          0.9660     0.9587     0.9623
6          0.9740     0.9820     0.9780
7          0.9782     0.9507     0.9642
8          0.9224     0.9650     0.9432
9          0.9644     0.9179     0.9406
----------------------------------------
Macro Avg  0.9630     0.9632     0.9629


Epoch 43/100 | Time: 214.2s | Loss: 2.4706 | Train Acc: 36.98%
--- Evaluating on Epoch 43 Val ---

Overall Accuracy: 27.92% (2792/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3490     0.5843     0.4370
1          0.2951     0.3871     0.3349
2          0.1250     0.1505     0.1366
3          0.2308     0.0674     0.1043
4          0.1268     0.1818     0.1494
5          0.1880     0.2075     0.1973
6          0.2667     0.1188     0.1644
7          0.3077     0.2083     0.2484
8          0.3425     0.2688     0.3012
9          0.3636     0.3556     0.3596
10         0.1398     0.1287     0.1340
11         0.4062     0.1083     0.1711
12         0.3725     0.1845     0.2468
13         0.1658     0.3137     0.2169
14         0.2727     0.1765     0.2143
15         0.4091     0.0796     0.1333
16         0.1293     0.2184     0.1624
17         0.3252     0.5929     0.4201
18         0.1875     0.1714     0.1791
19         0.1944     0.1386     0.1618
20         0.4324     0.4660     0.4486
21         0.4545     0.4124     0.4324
22         0.2889     0.1368     0.1857
23         0.4563     0.4563     0.4563
24         0.3407     0.5169     0.4107
25         0.1553     0.1975     0.1739
26         0.1915     0.0857     0.1184
27         0.1159     0.2697     0.1622
28         0.3588     0.4896     0.4141
29         0.3194     0.2556     0.2840
30         0.3214     0.1782     0.2293
31         0.2577     0.2604     0.2591
32         0.2353     0.2424     0.2388
33         0.1311     0.2025     0.1592
34         0.1250     0.0762     0.0947
35         0.2917     0.0693     0.1120
36         0.2474     0.4706     0.3243
37         0.2113     0.1351     0.1648
38         0.1681     0.2105     0.1869
39         0.2967     0.2177     0.2512
40         0.1860     0.1860     0.1860
41         0.4554     0.4904     0.4722
42         0.2277     0.2170     0.2222
43         0.1833     0.3511     0.2409
44         0.2250     0.1818     0.2011
45         0.2121     0.0814     0.1176
46         0.2143     0.1011     0.1374
47         0.4490     0.4037     0.4251
48         0.3778     0.3400     0.3579
49         0.6136     0.2621     0.3673
50         0.1286     0.0882     0.1047
51         0.1957     0.1895     0.1925
52         0.4600     0.7188     0.5610
53         0.3158     0.5625     0.4045
54         0.4930     0.3070     0.3784
55         0.1905     0.0430     0.0702
56         0.3204     0.3667     0.3420
57         0.3623     0.2451     0.2924
58         0.4242     0.2617     0.3237
59         0.2566     0.2566     0.2566
60         0.6475     0.7248     0.6840
61         0.3554     0.4831     0.4095
62         0.3187     0.4951     0.3878
63         0.2312     0.4135     0.2966
64         0.1695     0.1852     0.1770
65         0.1237     0.1212     0.1224
66         0.0943     0.0549     0.0694
67         0.2000     0.4157     0.2701
68         0.4882     0.5741     0.5277
69         0.5233     0.4839     0.5028
70         0.3021     0.2613     0.2802
71         0.3173     0.7174     0.4400
72         0.1549     0.1019     0.1229
73         0.3600     0.3879     0.3734
74         0.1020     0.1869     0.1320
75         0.6100     0.5495     0.5782
76         0.3607     0.4681     0.4074
77         0.2034     0.1200     0.1509
78         0.1818     0.0833     0.1143
79         0.2593     0.1429     0.1842
80         0.2069     0.0536     0.0851
81         0.1910     0.1735     0.1818
82         0.5761     0.5699     0.5730
83         0.2941     0.1852     0.2273
84         0.2373     0.1296     0.1677
85         0.4583     0.3113     0.3708
86         0.3520     0.3964     0.3729
87         0.2093     0.3140     0.2512
88         0.1522     0.2000     0.1728
89         0.4848     0.1509     0.2302
90         0.2167     0.1161     0.1512
91         0.2043     0.5217     0.2936
92         0.2105     0.0762     0.1119
93         0.2167     0.1287     0.1615
94         0.3906     0.6579     0.4902
95         0.3511     0.4742     0.4035
96         0.2764     0.4250     0.3350
97         0.2268     0.2056     0.2157
98         0.2115     0.1264     0.1583
99         0.1146     0.1714     0.1374
----------------------------------------
Macro Avg  0.2847     0.2800     0.2656


Epoch 37/100 | Time: 262.2s | Loss: 0.0168 | Train Acc: 99.53%
--- Evaluating on Epoch 37 Val ---

Epoch 44/100 | Time: 209.7s | Loss: 2.4575 | Train Acc: 37.20%
--- Evaluating on Epoch 44 Val ---

Overall Accuracy: 27.85% (2785/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.6000     0.4719     0.5283
1          0.3333     0.3548     0.3438
2          0.1179     0.2473     0.1597
3          0.2063     0.1461     0.1711
4          0.1368     0.1313     0.1340
5          0.2658     0.1981     0.2270
6          0.1981     0.2079     0.2029
7          0.2520     0.3229     0.2831
8          0.1528     0.4731     0.2310
9          0.5238     0.3667     0.4314
10         0.1818     0.0990     0.1282
11         0.3611     0.1083     0.1667
12         0.3043     0.2039     0.2442
13         0.2727     0.2353     0.2526
14         0.2419     0.1471     0.1829
15         0.1639     0.1770     0.1702
16         0.1795     0.1609     0.1697
17         0.3575     0.6106     0.4510
18         0.2167     0.1238     0.1576
19         0.2268     0.2178     0.2222
20         0.3904     0.5534     0.4578
21         0.4773     0.4330     0.4541
22         0.2403     0.3263     0.2768
23         0.2933     0.5922     0.3923
24         0.3148     0.3820     0.3452
25         0.1683     0.2099     0.1868
26         0.1452     0.0857     0.1078
27         0.1866     0.2809     0.2242
28         0.4583     0.4583     0.4583
29         0.3509     0.2222     0.2721
30         0.2466     0.5446     0.3395
31         0.2400     0.1875     0.2105
32         0.2388     0.1616     0.1928
33         0.2456     0.1772     0.2059
34         0.1368     0.1524     0.1441
35         0.1721     0.2079     0.1883
36         0.1992     0.4804     0.2816
37         0.1930     0.0991     0.1310
38         0.1364     0.2211     0.1687
39         0.1881     0.3065     0.2331
40         0.1455     0.1860     0.1633
41         0.5909     0.3750     0.4588
42         0.1685     0.1415     0.1538
43         0.1988     0.3404     0.2510
44         0.2237     0.1717     0.1943
45         0.2250     0.1047     0.1429
46         0.1837     0.1011     0.1304
47         0.5667     0.3119     0.4024
48         0.4583     0.3300     0.3837
49         0.4512     0.3592     0.4000
50         0.1408     0.0980     0.1156
51         0.1818     0.1263     0.1491
52         0.5038     0.6875     0.5815
53         0.3620     0.6146     0.4556
54         0.3774     0.3509     0.3636
55         0.1667     0.0323     0.0541
56         0.3364     0.4111     0.3700
57         0.3721     0.3137     0.3404
58         0.3729     0.2056     0.2651
59         0.4762     0.1770     0.2581
60         0.7374     0.6697     0.7019
61         0.3150     0.4494     0.3704
62         0.3107     0.5340     0.3929
63         0.3778     0.3269     0.3505
64         0.1104     0.1574     0.1298
65         0.1081     0.0808     0.0925
66         0.0928     0.0989     0.0957
67         0.2706     0.2584     0.2644
68         0.5344     0.6481     0.5858
69         0.3723     0.5484     0.4435
70         0.3452     0.2613     0.2974
71         0.6429     0.3913     0.4865
72         0.0994     0.1481     0.1190
73         0.4833     0.2500     0.3295
74         0.1667     0.1402     0.1523
75         0.4925     0.5946     0.5388
76         0.3962     0.4468     0.4200
77         0.1481     0.1600     0.1538
78         0.1803     0.1146     0.1401
79         0.1818     0.1837     0.1827
80         0.1429     0.0714     0.0952
81         0.2338     0.1837     0.2057
82         0.5698     0.5269     0.5475
83         0.4138     0.1111     0.1752
84         0.2600     0.1204     0.1646
85         0.3793     0.4151     0.3964
86         0.3942     0.3694     0.3814
87         0.3333     0.2093     0.2571
88         0.2459     0.1429     0.1807
89         0.3607     0.2075     0.2635
90         0.2000     0.1518     0.1726
91         0.3393     0.4130     0.3725
92         0.1842     0.0667     0.0979
93         0.3000     0.1188     0.1702
94         0.6344     0.5175     0.5700
95         0.4364     0.2474     0.3158
96         0.4085     0.3625     0.3841
97         0.1287     0.4019     0.1950
98         0.1250     0.1609     0.1407
99         0.0899     0.0762     0.0825
----------------------------------------
Macro Avg  0.2936     0.2786     0.2718


Overall Accuracy: 96.69% (11603/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9782     0.9799     0.9790
1          0.9839     0.9890     0.9865
2          0.9597     0.9691     0.9644
3          0.9562     0.9672     0.9617
4          0.9424     0.9822     0.9619
5          0.9662     0.9662     0.9662
6          0.9780     0.9820     0.9800
7          0.9776     0.9598     0.9686
8          0.9593     0.9462     0.9527
9          0.9647     0.9247     0.9443
----------------------------------------
Macro Avg  0.9666     0.9666     0.9665


Epoch 45/100 | Time: 262.0s | Loss: 2.4430 | Train Acc: 37.30%
--- Evaluating on Epoch 45 Val ---

Overall Accuracy: 28.35% (2835/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3376     0.5955     0.4309
1          0.2906     0.3656     0.3238
2          0.1287     0.1398     0.1340
3          0.1932     0.1910     0.1921
4          0.1127     0.1616     0.1328
5          0.2288     0.2547     0.2411
6          0.2099     0.1683     0.1868
7          0.2906     0.3542     0.3192
8          0.2893     0.3763     0.3271
9          0.5333     0.3556     0.4267
10         0.1389     0.0990     0.1156
11         0.3019     0.1333     0.1850
12         0.2857     0.1748     0.2169
13         0.2167     0.2549     0.2342
14         0.2344     0.1471     0.1807
15         0.1696     0.1681     0.1689
16         0.1176     0.2069     0.1500
17         0.4298     0.4602     0.4444
18         0.2133     0.1524     0.1778
19         0.2033     0.2475     0.2232
20         0.4531     0.5631     0.5022
21         0.3860     0.4536     0.4171
22         0.1955     0.2737     0.2281
23         0.4132     0.4854     0.4464
24         0.3738     0.4494     0.4082
25         0.1518     0.2099     0.1762
26         0.1429     0.1143     0.1270
27         0.1195     0.3034     0.1714
28         0.4216     0.4479     0.4343
29         0.4634     0.2111     0.2901
30         0.2831     0.4653     0.3521
31         0.3188     0.2292     0.2667
32         0.6818     0.1515     0.2479
33         0.2022     0.2278     0.2143
34         0.1361     0.1905     0.1587
35         0.1818     0.1188     0.1437
36         0.2453     0.3824     0.2989
37         0.2444     0.2973     0.2683
38         0.1714     0.0632     0.0923
39         0.3137     0.2581     0.2832
40         0.1647     0.1628     0.1637
41         0.4128     0.4327     0.4225
42         0.2361     0.1604     0.1910
43         0.2816     0.3085     0.2944
44         0.2069     0.0606     0.0937
45         0.0896     0.0698     0.0784
46         0.1505     0.1573     0.1538
47         0.5432     0.4037     0.4632
48         0.3652     0.4200     0.3907
49         0.3571     0.4369     0.3930
50         0.1818     0.0588     0.0889
51         0.2545     0.1474     0.1867
52         0.5159     0.6771     0.5856
53         0.3459     0.5729     0.4314
54         0.3960     0.3509     0.3721
55         0.0926     0.0538     0.0680
56         0.4062     0.4333     0.4194
57         0.4133     0.3039     0.3503
58         0.3022     0.3925     0.3415
59         0.3889     0.1858     0.2515
60         0.6532     0.7431     0.6953
61         0.2045     0.5056     0.2913
62         0.2320     0.5631     0.3286
63         0.3365     0.3365     0.3365
64         0.2115     0.1019     0.1375
65         0.1778     0.0808     0.1111
66         0.1026     0.0879     0.0947
67         0.2102     0.4157     0.2792
68         0.6300     0.5833     0.6058
69         0.4679     0.5484     0.5050
70         0.3279     0.1802     0.2326
71         0.4495     0.5326     0.4876
72         0.0980     0.0463     0.0629
73         0.6346     0.2845     0.3929
74         0.1450     0.1776     0.1597
75         0.4437     0.6396     0.5240
76         0.4149     0.4149     0.4149
77         0.1176     0.2000     0.1481
78         0.2419     0.1562     0.1899
79         0.1783     0.2857     0.2196
80         0.2800     0.0625     0.1022
81         0.2593     0.2143     0.2346
82         0.4242     0.6022     0.4978
83         0.2615     0.1574     0.1965
84         0.1589     0.1574     0.1581
85         0.4141     0.3868     0.4000
86         0.4186     0.3243     0.3655
87         0.2190     0.2674     0.2408
88         0.2464     0.1619     0.1954
89         0.1824     0.2547     0.2126
90         0.2750     0.0982     0.1447
91         0.3857     0.2935     0.3333
92         0.0973     0.1048     0.1009
93         0.1923     0.0990     0.1307
94         0.4557     0.6316     0.5294
95         0.4750     0.1959     0.2774
96         0.3333     0.3875     0.3584
97         0.2235     0.1776     0.1979
98         0.1789     0.1954     0.1868
99         0.1591     0.0667     0.0940
----------------------------------------
Macro Avg  0.2885     0.2841     0.2725

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl

Epoch 38/100 | Time: 296.2s | Loss: 0.0153 | Train Acc: 99.60%
--- Evaluating on Epoch 38 Val ---

Overall Accuracy: 96.48% (11578/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9766     0.9851     0.9808
1          0.9867     0.9831     0.9849
2          0.9496     0.9664     0.9579
3          0.9396     0.9689     0.9540
4          0.9735     0.9636     0.9685
5          0.9419     0.9728     0.9571
6          0.9803     0.9771     0.9787
7          0.9633     0.9757     0.9695
8          0.9762     0.9112     0.9426
9          0.9578     0.9408     0.9492
----------------------------------------
Macro Avg  0.9646     0.9645     0.9643


Epoch 46/100 | Time: 190.7s | Loss: 2.4243 | Train Acc: 38.09%
--- Evaluating on Epoch 46 Val ---

Overall Accuracy: 25.95% (2595/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3643     0.5730     0.4454
1          0.2671     0.4624     0.3386
2          0.1364     0.0968     0.1132
3          0.1681     0.2247     0.1923
4          0.1182     0.1313     0.1244
5          0.1746     0.3113     0.2237
6          0.1920     0.2376     0.2124
7          0.2581     0.3333     0.2909
8          0.5208     0.2688     0.3546
9          0.4321     0.3889     0.4094
10         0.1290     0.0792     0.0982
11         0.2500     0.2000     0.2222
12         0.3582     0.2330     0.2824
13         0.2500     0.1078     0.1507
14         0.1739     0.2745     0.2129
15         0.1036     0.2566     0.1476
16         0.3704     0.1149     0.1754
17         0.3315     0.5310     0.4082
18         0.1395     0.1143     0.1257
19         0.1569     0.1584     0.1576
20         0.4818     0.5146     0.4977
21         0.3362     0.4021     0.3662
22         0.4800     0.1263     0.2000
23         0.3588     0.4563     0.4017
24         0.3663     0.4157     0.3895
25         0.1728     0.1728     0.1728
26         0.1310     0.1810     0.1520
27         0.1208     0.2809     0.1689
28         0.3707     0.4479     0.4057
29         0.2233     0.2556     0.2383
30         0.3654     0.1881     0.2484
31         0.1618     0.3438     0.2200
32         0.2209     0.1919     0.2054
33         0.1532     0.2152     0.1789
34         0.1321     0.1333     0.1327
35         0.1395     0.1188     0.1283
36         0.1746     0.5392     0.2638
37         0.1915     0.0811     0.1139
38         0.2154     0.1474     0.1750
39         0.5909     0.1048     0.1781
40         0.1429     0.1744     0.1571
41         0.5652     0.3750     0.4509
42         0.2157     0.1038     0.1401
43         0.1626     0.3511     0.2222
44         0.1392     0.1111     0.1236
45         0.1304     0.0698     0.0909
46         0.1507     0.1236     0.1358
47         0.4796     0.4312     0.4541
48         0.5600     0.2800     0.3733
49         0.4643     0.2524     0.3270
50         0.1096     0.0784     0.0914
51         0.1216     0.1895     0.1481
52         0.5833     0.5833     0.5833
53         0.3643     0.4896     0.4178
54         0.4889     0.1930     0.2767
55         0.1000     0.0538     0.0699
56         0.4217     0.3889     0.4046
57         0.4328     0.2843     0.3432
58         0.4565     0.1963     0.2745
59         0.3750     0.1062     0.1655
60         0.5852     0.7248     0.6475
61         0.4667     0.3146     0.3758
62         0.3672     0.4563     0.4069
63         0.2042     0.3750     0.2644
64         0.1111     0.1944     0.1414
65         0.0988     0.0808     0.0889
66         0.1905     0.0440     0.0714
67         0.2407     0.2921     0.2640
68         0.5221     0.5463     0.5339
69         0.4352     0.5054     0.4677
70         0.2262     0.3423     0.2724
71         0.4653     0.5109     0.4870
72         0.1231     0.0741     0.0925
73         0.6122     0.2586     0.3636
74         0.1818     0.1308     0.1522
75         0.4604     0.5766     0.5120
76         0.3362     0.4149     0.3714
77         0.0811     0.3000     0.1277
78         0.1200     0.0312     0.0496
79         0.3261     0.1531     0.2083
80         0.1212     0.0357     0.0552
81         0.2449     0.1224     0.1633
82         0.6164     0.4839     0.5422
83         0.2676     0.1759     0.2123
84         0.1024     0.1204     0.1106
85         0.3276     0.3585     0.3423
86         0.4500     0.2432     0.3158
87         0.2368     0.2093     0.2222
88         0.1887     0.0952     0.1266
89         0.4107     0.2170     0.2840
90         0.1176     0.0179     0.0310
91         0.3505     0.3696     0.3598
92         0.1463     0.0571     0.0822
93         0.2407     0.1287     0.1677
94         0.2959     0.7632     0.4265
95         0.7333     0.2268     0.3465
96         0.3906     0.3125     0.3472
97         0.2195     0.1682     0.1905
98         0.1296     0.2414     0.1687
99         0.1379     0.0762     0.0982
----------------------------------------
Macro Avg  0.2863     0.2600     0.2526


Epoch 39/100 | Time: 254.8s | Loss: 0.0147 | Train Acc: 99.58%
--- Evaluating on Epoch 39 Val ---

Overall Accuracy: 96.43% (11572/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9765     0.9816     0.9791
1          0.9846     0.9868     0.9857
2          0.9710     0.9487     0.9597
3          0.9422     0.9746     0.9581
4          0.9357     0.9848     0.9596
5          0.9741     0.9512     0.9625
6          0.9701     0.9828     0.9764
7          0.9753     0.9568     0.9659
8          0.9538     0.9513     0.9525
9          0.9602     0.9196     0.9395
----------------------------------------
Macro Avg  0.9644     0.9638     0.9639


Epoch 47/100 | Time: 13476.6s | Loss: 2.4133 | Train Acc: 38.11%
--- Evaluating on Epoch 47 Val ---

Overall Accuracy: 28.42% (2842/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4286     0.5393     0.4776
1          0.2927     0.3871     0.3333
2          0.1364     0.0968     0.1132
3          0.2500     0.1236     0.1654
4          0.1079     0.1515     0.1261
5          0.2222     0.1887     0.2041
6          0.1714     0.1782     0.1748
7          0.3333     0.3021     0.3169
8          0.2273     0.3763     0.2834
9          0.6579     0.2778     0.3906
10         0.1786     0.0990     0.1274
11         0.2524     0.2167     0.2332
12         0.2617     0.2718     0.2667
13         0.2794     0.1863     0.2235
14         0.2170     0.2255     0.2212
15         0.3250     0.1150     0.1699
16         0.2254     0.1839     0.2025
17         0.3929     0.4867     0.4348
18         0.2336     0.2381     0.2358
19         0.2603     0.1881     0.2184
20         0.4472     0.5340     0.4867
21         0.4054     0.4639     0.4327
22         0.3171     0.1368     0.1912
23         0.3701     0.5534     0.4436
24         0.2857     0.5618     0.3788
25         0.2025     0.1975     0.2000
26         0.2075     0.1048     0.1392
27         0.1474     0.2584     0.1878
28         0.3947     0.4688     0.4286
29         0.2796     0.2889     0.2842
30         0.3136     0.3663     0.3379
31         0.1884     0.2708     0.2222
32         0.1667     0.2929     0.2125
33         0.1875     0.2278     0.2057
34         0.1786     0.0952     0.1242
35         0.1654     0.2079     0.1842
36         0.3333     0.2843     0.3069
37         0.1875     0.1351     0.1571
38         0.1065     0.2421     0.1479
39         0.2667     0.2258     0.2445
40         0.1881     0.2209     0.2032
41         0.5122     0.4038     0.4516
42         0.1569     0.2264     0.1853
43         0.2661     0.3511     0.3028
44         0.1905     0.1212     0.1481
45         0.1905     0.0930     0.1250
46         0.1690     0.1348     0.1500
47         0.3960     0.5413     0.4574
48         0.3333     0.4300     0.3755
49         0.3011     0.5146     0.3799
50         0.1887     0.0980     0.1290
51         0.1765     0.2526     0.2078
52         0.5364     0.6146     0.5728
53         0.3945     0.4479     0.4195
54         0.3154     0.4123     0.3574
55         0.0833     0.0430     0.0567
56         0.3182     0.4667     0.3784
57         0.4079     0.3039     0.3483
58         0.3587     0.3084     0.3317
59         0.2927     0.2124     0.2462
60         0.6565     0.7890     0.7167
61         0.3471     0.4719     0.4000
62         0.4022     0.3592     0.3795
63         0.2426     0.3942     0.3004
64         0.2456     0.1296     0.1697
65         0.1238     0.1313     0.1275
66         0.1224     0.0659     0.0857
67         0.2178     0.2472     0.2316
68         0.5446     0.5648     0.5545
69         0.3312     0.5699     0.4190
70         0.3906     0.2252     0.2857
71         0.5102     0.5435     0.5263
72         0.1400     0.0648     0.0886
73         0.3814     0.3190     0.3474
74         0.1198     0.1869     0.1460
75         0.5470     0.5766     0.5614
76         0.3288     0.5106     0.4000
77         0.1267     0.1900     0.1520
78         0.1250     0.0104     0.0192
79         0.2179     0.1735     0.1932
80         0.2857     0.0714     0.1143
81         0.2963     0.1633     0.2105
82         0.6176     0.4516     0.5217
83         0.2083     0.1389     0.1667
84         0.1613     0.1389     0.1493
85         0.4524     0.3585     0.4000
86         0.3406     0.4234     0.3775
87         0.2683     0.2558     0.2619
88         0.2088     0.1810     0.1939
89         0.3818     0.1981     0.2609
90         0.2333     0.0625     0.0986
91         0.4568     0.4022     0.4277
92         0.1163     0.0952     0.1047
93         0.2157     0.1089     0.1447
94         0.3846     0.6579     0.4854
95         0.2941     0.3608     0.3241
96         0.3429     0.3000     0.3200
97         0.2055     0.2804     0.2372
98         0.1600     0.1839     0.1711
99         0.1446     0.1143     0.1277
----------------------------------------
Macro Avg  0.2828     0.2842     0.2726

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl
=== TESTING MODE (FULL DATASET) ===
[!] No weights loaded, starting fresh.
Loading dataset from data_1...
Found 10 classes: ['0', '1', '2', '3', '4'] ...

Epoch 40/100 | Time: 13591.3s | Loss: 0.0127 | Train Acc: 99.65%
--- Evaluating on Epoch 40 Val ---
Dataset loaded: 60000 images in 108.46 seconds.
--- Evaluating on Test (Full Dataset) ---

Overall Accuracy: 96.56% (11587/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9537     0.9904     0.9717
1          0.9824     0.9846     0.9835
2          0.9490     0.9699     0.9593
3          0.9486     0.9680     0.9582
4          0.9777     0.9628     0.9702
5          0.9706     0.9587     0.9646
6          0.9794     0.9722     0.9758
7          0.9697     0.9712     0.9705
8          0.9567     0.9445     0.9506
9          0.9657     0.9298     0.9474
----------------------------------------
Macro Avg  0.9653     0.9652     0.9652


Epoch 48/100 | Time: 278.9s | Loss: 2.3973 | Train Acc: 38.29%
--- Evaluating on Epoch 48 Val ---

Overall Accuracy: 27.04% (2704/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.2648     0.6517     0.3766
1          0.2963     0.3441     0.3184
2          0.1250     0.1290     0.1270
3          0.1176     0.2697     0.1638
4          0.1373     0.1414     0.1393
5          0.2277     0.2170     0.2222
6          0.1401     0.2178     0.1705
7          0.2170     0.2396     0.2277
8          0.4237     0.2688     0.3289
9          0.5439     0.3444     0.4218
10         0.2286     0.0792     0.1176
11         0.3462     0.1500     0.2093
12         0.2381     0.3883     0.2952
13         0.2830     0.1471     0.1935
14         0.2059     0.2059     0.2059
15         0.2188     0.0619     0.0966
16         0.2340     0.1264     0.1642
17         0.3669     0.4513     0.4048
18         0.1765     0.2286     0.1992
19         0.1980     0.1980     0.1980
20         0.5778     0.5049     0.5389
21         0.3905     0.4227     0.4059
22         0.4043     0.2000     0.2676
23         0.5263     0.3883     0.4469
24         0.3786     0.4382     0.4062
25         0.1550     0.2469     0.1905
26         0.2609     0.1143     0.1589
27         0.1667     0.2135     0.1872
28         0.5775     0.4271     0.4910
29         0.2500     0.2778     0.2632
30         0.3273     0.1782     0.2308
31         0.2069     0.3125     0.2490
32         0.3562     0.2626     0.3023
33         0.1091     0.2278     0.1475
34         0.2131     0.1238     0.1566
35         0.2069     0.1188     0.1509
36         0.3426     0.3627     0.3524
37         0.2157     0.0991     0.1358
38         0.1774     0.1158     0.1401
39         0.5000     0.0806     0.1389
40         0.2000     0.1395     0.1644
41         0.3623     0.4808     0.4132
42         0.1420     0.2264     0.1745
43         0.2147     0.3723     0.2724
44         0.1935     0.1212     0.1491
45         0.3043     0.0814     0.1284
46         0.1923     0.1124     0.1418
47         0.3814     0.4128     0.3965
48         0.4828     0.2800     0.3544
49         0.5208     0.2427     0.3311
50         0.1138     0.1373     0.1244
51         0.1195     0.4316     0.1872
52         0.4516     0.7292     0.5578
53         0.3737     0.3854     0.3795
54         0.4937     0.3421     0.4041
55         0.0769     0.0645     0.0702
56         0.2424     0.3556     0.2883
57         0.2356     0.4412     0.3072
58         0.4565     0.1963     0.2745
59         0.2373     0.2478     0.2424
60         0.6942     0.7706     0.7304
61         0.4483     0.2921     0.3537
62         0.3385     0.4272     0.3777
63         0.2228     0.3942     0.2847
64         0.1505     0.1296     0.1393
65         0.0909     0.0707     0.0795
66         0.0682     0.0330     0.0444
67         0.2273     0.3371     0.2715
68         0.4937     0.7222     0.5865
69         0.5873     0.3978     0.4744
70         0.3478     0.1441     0.2038
71         0.6056     0.4674     0.5276
72         0.1471     0.0926     0.1136
73         0.5814     0.2155     0.3145
74         0.1449     0.0935     0.1136
75         0.5702     0.5856     0.5778
76         0.3007     0.4894     0.3725
77         0.1436     0.2800     0.1898
78         0.1481     0.0417     0.0650
79         0.2342     0.2653     0.2488
80         0.0868     0.1875     0.1186
81         0.2222     0.2245     0.2234
82         0.4677     0.6237     0.5346
83         0.2381     0.1852     0.2083
84         0.2000     0.1111     0.1429
85         0.2075     0.4717     0.2882
86         0.4643     0.2342     0.3114
87         0.2212     0.2674     0.2421
88         0.2537     0.1619     0.1977
89         0.2321     0.2453     0.2385
90         0.1711     0.1161     0.1383
91         0.3810     0.3478     0.3636
92         0.2000     0.0667     0.1000
93         0.2586     0.1485     0.1887
94         0.3665     0.6140     0.4590
95         0.5349     0.2371     0.3286
96         0.2194     0.4250     0.2894
97         0.2333     0.1963     0.2132
98         0.2045     0.1034     0.1374
99         0.2000     0.1333     0.1600
----------------------------------------
Macro Avg  0.2904     0.2713     0.2626


Overall Accuracy: 8.94% (5362/60000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.0000     0.0000     0.0000
1          0.0000     0.0000     0.0000
2          0.0905     0.8422     0.1635
3          0.0953     0.0427     0.0590
4          0.0000     0.0000     0.0000
5          0.0000     0.0000     0.0000
6          0.1625     0.0078     0.0148
7          0.0000     0.0000     0.0000
8          0.0000     0.0000     0.0000
9          0.0236     0.0061     0.0096
----------------------------------------
Macro Avg  0.0372     0.0899     0.0247

Test Accuracy (Full): 8.94%

Epoch 41/100 | Time: 630.2s | Loss: 0.0119 | Train Acc: 99.69%
--- Evaluating on Epoch 41 Val ---

Overall Accuracy: 96.63% (11596/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9798     0.9773     0.9785
1          0.9790     0.9912     0.9851
2          0.9662     0.9611     0.9637
3          0.9700     0.9541     0.9620
4          0.9670     0.9670     0.9670
5          0.9506     0.9747     0.9625
6          0.9718     0.9845     0.9781
7          0.9812     0.9500     0.9653
8          0.9578     0.9488     0.9532
9          0.9360     0.9535     0.9447
----------------------------------------
Macro Avg  0.9659     0.9662     0.9660


Epoch 49/100 | Time: 587.7s | Loss: 2.3837 | Train Acc: 38.82%
--- Evaluating on Epoch 49 Val ---

Overall Accuracy: 28.36% (2836/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.4455     0.5506     0.4925
1          0.2927     0.3871     0.3333
2          0.0875     0.0753     0.0809
3          0.1351     0.1124     0.1227
4          0.1056     0.1919     0.1362
5          0.1447     0.2075     0.1705
6          0.2200     0.1089     0.1457
7          0.3176     0.2812     0.2983
8          0.2713     0.3763     0.3153
9          0.4211     0.3556     0.3855
10         0.1349     0.1683     0.1498
11         0.2326     0.1667     0.1942
12         0.1854     0.3689     0.2468
13         0.2105     0.2353     0.2222
14         0.2424     0.2353     0.2388
15         0.3077     0.1062     0.1579
16         0.1361     0.2989     0.1871
17         0.3795     0.5575     0.4516
18         0.2439     0.0952     0.1370
19         0.2679     0.1485     0.1911
20         0.5652     0.5049     0.5333
21         0.2644     0.5670     0.3607
22         0.3158     0.1895     0.2368
23         0.4364     0.4660     0.4507
24         0.3288     0.5393     0.4085
25         0.1733     0.1605     0.1667
26         0.1600     0.1143     0.1333
27         0.1204     0.1461     0.1320
28         0.4457     0.4271     0.4362
29         0.2155     0.2778     0.2427
30         0.2637     0.2376     0.2500
31         0.3115     0.1979     0.2420
32         0.1656     0.2727     0.2061
33         0.1786     0.1899     0.1840
34         0.2391     0.1048     0.1457
35         0.1618     0.1089     0.1302
36         0.3457     0.2745     0.3060
37         0.1905     0.1441     0.1641
38         0.2000     0.1368     0.1625
39         0.2826     0.3145     0.2977
40         0.1545     0.1977     0.1735
41         0.4109     0.5096     0.4549
42         0.2632     0.1415     0.1840
43         0.3000     0.3191     0.3093
44         0.1684     0.1616     0.1649
45         0.1522     0.0814     0.1061
46         0.1538     0.1348     0.1437
47         0.4464     0.4587     0.4525
48         0.3534     0.4100     0.3796
49         0.3793     0.3204     0.3474
50         0.1765     0.0882     0.1176
51         0.2174     0.2105     0.2139
52         0.4919     0.6354     0.5545
53         0.3846     0.5208     0.4425
54         0.3264     0.4123     0.3643
55         0.0574     0.0753     0.0651
56         0.3646     0.3889     0.3763
57         0.4328     0.2843     0.3432
58         0.2955     0.4860     0.3675
59         0.4035     0.2035     0.2706
60         0.7094     0.7615     0.7345
61         0.3980     0.4382     0.4171
62         0.2659     0.4466     0.3333
63         0.3580     0.2788     0.3135
64         0.1974     0.1389     0.1630
65         0.1304     0.0909     0.1071
66         0.1383     0.1429     0.1405
67         0.2632     0.2247     0.2424
68         0.6186     0.5556     0.5854
69         0.3953     0.5484     0.4595
70         0.3030     0.1802     0.2260
71         0.4109     0.5761     0.4796
72         0.1389     0.0463     0.0694
73         0.3554     0.3707     0.3629
74         0.1930     0.2056     0.1991
75         0.4497     0.6036     0.5154
76         0.4167     0.4787     0.4455
77         0.1897     0.1100     0.1392
78         0.2424     0.0833     0.1240
79         0.2200     0.2245     0.2222
80         0.4286     0.0536     0.0952
81         0.2346     0.1939     0.2123
82         0.5288     0.5914     0.5584
83         0.1968     0.3426     0.2500
84         0.1798     0.1481     0.1624
85         0.2919     0.4434     0.3521
86         0.4217     0.3153     0.3608
87         0.3239     0.2674     0.2930
88         0.2609     0.1714     0.2069
89         0.3235     0.2075     0.2529
90         0.1587     0.0893     0.1143
91         0.3304     0.4022     0.3627
92         0.1594     0.1048     0.1264
93         0.1600     0.1188     0.1364
94         0.4832     0.6316     0.5475
95         0.2390     0.5052     0.3245
96         0.2773     0.4125     0.3317
97         0.2143     0.1963     0.2049
98         0.1500     0.1724     0.1604
99         0.1852     0.0476     0.0758
----------------------------------------
Macro Avg  0.2802     0.2836     0.2709

=== TESTING MODE (FULL DATASET) ===
[!] Loaded weights from checkpoints\best_model_data_1.pkl
Loading dataset from data_1...
Found 10 classes: ['0', '1', '2', '3', '4'] ...

Epoch 50/100 | Time: 496.8s | Loss: 2.3664 | Train Acc: 39.05%
--- Evaluating on Epoch 50 Val ---

Epoch 42/100 | Time: 589.5s | Loss: 0.0115 | Train Acc: 99.70%
--- Evaluating on Epoch 42 Val ---

Overall Accuracy: 27.95% (2795/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3910     0.5843     0.4685
1          0.2193     0.4409     0.2929
2          0.1250     0.2581     0.1684
3          0.2143     0.0674     0.1026
4          0.1040     0.1313     0.1161
5          0.1631     0.3585     0.2242
6          0.2118     0.1782     0.1935
7          0.4231     0.1146     0.1803
8          0.2920     0.3548     0.3204
9          0.5000     0.3333     0.4000
10         0.1897     0.1089     0.1384
11         0.3235     0.1833     0.2340
12         0.2479     0.2913     0.2679
13         0.1342     0.3922     0.2000
14         0.2381     0.1961     0.2151
15         0.3000     0.0796     0.1259
16         0.2159     0.2184     0.2171
17         0.4298     0.4336     0.4317
18         0.2039     0.2000     0.2019
19         0.1885     0.2277     0.2063
20         0.6081     0.4369     0.5085
21         0.3054     0.5258     0.3864
22         0.2716     0.2316     0.2500
23         0.3986     0.5340     0.4564
24         0.3913     0.5056     0.4412
25         0.2308     0.1481     0.1805
26         0.1667     0.0762     0.1046
27         0.1273     0.1573     0.1407
28         0.6346     0.3438     0.4459
29         0.1832     0.2667     0.2172
30         0.3040     0.3762     0.3363
31         0.2407     0.2708     0.2549
32         0.2124     0.2424     0.2264
33         0.1538     0.2278     0.1837
34         0.2281     0.1238     0.1605
35         0.1429     0.0792     0.1019
36         0.2500     0.3235     0.2821
37         0.1981     0.1892     0.1935
38         0.1609     0.1474     0.1538
39         0.3934     0.1935     0.2595
40         0.2174     0.1744     0.1935
41         0.3333     0.5577     0.4173
42         0.1833     0.1038     0.1325
43         0.4328     0.3085     0.3602
44         0.2083     0.1010     0.1361
45         0.1493     0.1163     0.1307
46         0.1296     0.0787     0.0979
47         0.4464     0.4587     0.4525
48         0.4022     0.3700     0.3854
49         0.2989     0.5340     0.3833
50         0.1622     0.0588     0.0863
51         0.1982     0.2316     0.2136
52         0.4792     0.7188     0.5750
53         0.3400     0.5312     0.4146
54         0.3786     0.3421     0.3594
55         0.0750     0.0323     0.0451
56         0.2749     0.5222     0.3602
57         0.3896     0.2941     0.3352
58         0.3125     0.3271     0.3196
59         0.3049     0.2212     0.2564
60         0.6833     0.7523     0.7162
61         0.2933     0.4944     0.3682
62         0.3736     0.3301     0.3505
63         0.3438     0.3173     0.3300
64         0.1667     0.1296     0.1458
65         0.1515     0.1010     0.1212
66         0.0833     0.0879     0.0856
67         0.1987     0.3371     0.2500
68         0.5536     0.5741     0.5636
69         0.3750     0.5484     0.4454
70         0.3239     0.2072     0.2527
71         0.5301     0.4783     0.5029
72         0.1220     0.0463     0.0671
73         0.4167     0.3448     0.3774
74         0.1594     0.1028     0.1250
75         0.6125     0.4414     0.5131
76         0.2889     0.5532     0.3796
77         0.1884     0.1300     0.1538
78         0.2000     0.0208     0.0377
79         0.2716     0.2245     0.2458
80         0.2857     0.0357     0.0635
81         0.2283     0.2143     0.2211
82         0.4444     0.6022     0.5114
83         0.2295     0.2593     0.2435
84         0.1795     0.0648     0.0952
85         0.5714     0.2642     0.3613
86         0.4468     0.3784     0.4098
87         0.2439     0.2326     0.2381
88         0.1758     0.1524     0.1633
89         0.3108     0.2170     0.2556
90         0.1875     0.1339     0.1563
91         0.2662     0.4457     0.3333
92         0.1313     0.2000     0.1585
93         0.1905     0.0792     0.1119
94         0.5276     0.5877     0.5560
95         0.2832     0.3299     0.3048
96         0.2967     0.3375     0.3158
97         0.1985     0.2523     0.2222
98         0.1190     0.2874     0.1684
99         0.1571     0.1048     0.1257
----------------------------------------
Macro Avg  0.2824     0.2804     0.2669


Overall Accuracy: 96.38% (11565/12000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9868     0.9790     0.9829
1          0.9853     0.9853     0.9853
2          0.9562     0.9655     0.9608
3          0.9600     0.9631     0.9615
4          0.9826     0.9560     0.9691
5          0.9411     0.9747     0.9576
6          0.9795     0.9771     0.9783
7          0.9872     0.9325     0.9591
8          0.9622     0.9351     0.9485
9          0.8968     0.9704     0.9321
----------------------------------------
Macro Avg  0.9638     0.9639     0.9635

Dataset loaded: 60000 images in 198.67 seconds.
--- Evaluating on Test (Full Dataset) ---

Overall Accuracy: 98.77% (59259/60000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.9949     0.9931     0.9940
1          0.9910     0.9963     0.9936
2          0.9845     0.9924     0.9885
3          0.9955     0.9721     0.9837
4          0.9899     0.9878     0.9889
5          0.9832     0.9910     0.9870
6          0.9934     0.9914     0.9924
7          0.9786     0.9935     0.9860
8          0.9784     0.9824     0.9804
9          0.9869     0.9758     0.9813
----------------------------------------
Macro Avg  0.9876     0.9876     0.9876

Test Accuracy (Full): 98.77%

Epoch 51/100 | Time: 412.3s | Loss: 2.3568 | Train Acc: 39.17%
--- Evaluating on Epoch 51 Val ---

Overall Accuracy: 28.58% (2858/10000)
Class      Precision  Recall     F1-Score  
----------------------------------------
0          0.3712     0.5506     0.4434
1          0.3187     0.3118     0.3152
2          0.1333     0.1290     0.1311
3          0.1389     0.1124     0.1242
4          0.1707     0.1414     0.1547
5          0.2480     0.2925     0.2684
6          0.1818     0.1584     0.1693
7          0.3218     0.2917     0.3060
8          0.3211     0.3763     0.3465
9          0.4247     0.3444     0.3804
10         0.2133     0.1584     0.1818
11         0.2642     0.1167     0.1618
12         0.2698     0.3301     0.2969
13         0.2817     0.1961     0.2312
14         0.2169     0.1765     0.1946
15         0.2232     0.2212     0.2222
16         0.1452     0.2069     0.1706
17         0.4365     0.4867     0.4603
18         0.2222     0.1333     0.1667
19         0.2000     0.2178     0.2085
20         0.4211     0.5437     0.4746
21         0.3077     0.4536     0.3667
22         0.3011     0.2947     0.2979
23         0.4327     0.4369     0.4348
24         0.4270     0.4270     0.4270
25         0.2391     0.1358     0.1732
26         0.1379     0.1524     0.1448
27         0.1481     0.1798     0.1624
28         0.5333     0.4167     0.4678
29         0.2785     0.2444     0.2604
30         0.3367     0.3267     0.3317
31         0.2479     0.3125     0.2765
32         0.3684     0.1414     0.2044
33         0.1717     0.2152     0.1910
34         0.1724     0.1429     0.1562
35         0.1353     0.1782     0.1538
36         0.3017     0.3431     0.3211
37         0.2472     0.1982     0.2200
38         0.1548     0.2737     0.1977
39         0.2019     0.3387     0.2530
40         0.1538     0.2558     0.1921
41         0.4118     0.4712     0.4395
42         0.1585     0.1226     0.1383
43         0.2179     0.4149     0.2857
44         0.1833     0.2222     0.2009
45         0.1169     0.1047     0.1104
46         0.1364     0.1348     0.1356
47         0.5052     0.4495     0.4757
48         0.3488     0.4500     0.3930
49         0.5370     0.2816     0.3694
50         0.1500     0.0882     0.1111
51         0.2000     0.2526     0.2233
52         0.5591     0.5417     0.5503
53         0.3776     0.5625     0.4519
54         0.3796     0.3596     0.3694
55         0.0909     0.0323     0.0476
56         0.3358     0.5000     0.4018
57         0.4110     0.2941     0.3429
58         0.4262     0.2430     0.3095
59         0.3521     0.2212     0.2717
60         0.6385     0.7615     0.6946
61         0.3846     0.3933     0.3889
62         0.3451     0.4757     0.4000
63         0.3953     0.3269     0.3579
64         0.1791     0.1111     0.1371
65         0.1515     0.0505     0.0758
66         0.0807     0.1429     0.1032
67         0.2526     0.2697     0.2609
68         0.5565     0.6389     0.5948
69         0.3600     0.5806     0.4444
70         0.3333     0.2342     0.2751
71         0.4783     0.5978     0.5314
72         0.0980     0.0463     0.0629
73         0.5152     0.2931     0.3736
74         0.1524     0.1495     0.1509
75         0.3901     0.6396     0.4846
76         0.4625     0.3936     0.4253
77         0.2381     0.1000     0.1408
78         0.1200     0.1250     0.1224
79         0.2250     0.2755     0.2477
80         0.2667     0.0357     0.0630
81         0.2899     0.2041     0.2395
82         0.5111     0.4946     0.5027
83         0.2931     0.1574     0.2048
84         0.2791     0.1111     0.1589
85         0.4211     0.3774     0.3980
86         0.3043     0.4414     0.3603
87         0.4194     0.1512     0.2222
88         0.3091     0.1619     0.2125
89         0.2109     0.2925     0.2451
90         0.1655     0.2054     0.1833
91         0.2547     0.4457     0.3241
92         0.1538     0.0762     0.1019
93         0.1964     0.1089     0.1401
94         0.6162     0.5351     0.5728
95         0.4149     0.4021     0.4084
96         0.4000     0.2750     0.3259
97         0.1414     0.3925     0.2079
98         0.1496     0.2184     0.1776
99         0.1261     0.1429     0.1339
----------------------------------------
Macro Avg  0.2900     0.2855     0.2772

   [!] Model checkpoint saved to ./checkpoints\best_model_data_2.pkl
=== TESTING MODE (FULL DATASET) ===
[!] Loaded weights from checkpoints\best_model_data_2.pkl
Loading dataset from data_2...
Found 100 classes: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver'] ...

Epoch 43/100 | Time: 440.6s | Loss: 0.0093 | Train Acc: 99.79%
--- Evaluating on Epoch 43 Val ---
